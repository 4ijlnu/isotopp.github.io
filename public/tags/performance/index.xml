<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>performance on Die wunderbare Welt von Isotopp</title>
    <link>/tags/performance.html</link>
    <description>Recent content in performance on Die wunderbare Welt von Isotopp</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 08 Jun 2020 00:00:00 +0000</lastBuildDate><atom:link href="/tags/performance/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Waffle House Index of Tooling</title>
      <link>/2020/06/08/waffle-house-index-of-tooling.html</link>
      <pubDate>Mon, 08 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/06/08/waffle-house-index-of-tooling.html</guid>
      <description>Charity Majors was on fire and on target, again :
 What is a Waffle House Index ?
 The Waffle House Index is an informal metric named after the Waffle House restaurant chain and is used by the Federal Emergency Management Agency (FEMA) to determine the effect of a storm and the likely scale of assistance required for disaster recovery.
 A &amp;ldquo;Waffle House Index for Tooling&amp;rdquo; would be an indicator how bad the situation on the ground in an IT department is.</description>
    </item>
    
    <item>
      <title>Some latency numbers illustrated</title>
      <link>/2020/02/28/some-latency-numbers-illustrated.html</link>
      <pubDate>Fri, 28 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/02/28/some-latency-numbers-illustrated.html</guid>
      <description>These images are older than time itself. I picked them up while working as a consultant for MySQL AB, but I do not know the source.
Here are some important latency numbers. A pixel is a nanosecond (nano = 10^-9, a billionth of a second, 1 billion events/s = 1 GHz):
And below is the HDD disk seek latency in full at the same scale. An uncached index access can result in up to 5 disk seeks, worst case.</description>
    </item>
    
    <item>
      <title>MySQL Performance Limits</title>
      <link>/2019/09/06/mysql-performance-limits.html</link>
      <pubDate>Fri, 06 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/09/06/mysql-performance-limits.html</guid>
      <description>The last time I saw a MySQL server operating at a performance limit was in 2012. Back them we had a production master on (then) current hardware, running stable at about 21000 QPS. At 24000 QPS it tended to become unstable and fall over, dying in global locks on the InnoDB Adaptive Hash Index or other global locks.
I need to better understand how MySQL works today, and what the limits are on a box that is considered large in 2019.</description>
    </item>
    
    <item>
      <title>d = a*b&#43;c at scale</title>
      <link>/2017/11/25/d-abc-at-scale.html</link>
      <pubDate>Sat, 25 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/25/d-abc-at-scale.html</guid>
      <description>Introduction to GPUs (PDF)
So you already know how your CPU works, basically, and want to understand what your GPU does differently. Ofer Rosenberg has you covered: Introduction to GPUs does what it says on the tin.
The NVIDIA take on this can be found in An Introduction to Modern GPU Architecture by Ashu Rege, but because this is from 2008, it&amp;rsquo;s showing it&amp;rsquo;s age. The first 15 slides or so focus more on the gaming aspect and less on the technology, but are full of matching screenshots.</description>
    </item>
    
    <item>
      <title>Latency Numbers, visualised and memorised</title>
      <link>/2017/10/12/latency-numbers-visualised-and-memorised.html</link>
      <pubDate>Thu, 12 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/10/12/latency-numbers-visualised-and-memorised.html</guid>
      <description>There is a well known Github Gist &amp;ldquo;Latency Numbers Every Programmer Should Know &amp;rdquo;, which explains which things take how long.
 Scaled Latency Numbers If you scale these things down 3 billion times, a clock cycle (0.3ns) becomes a second. And suddenly things are relateable. (Tweet )
 Another attempt to visualize this , not entirely unlike this XKCD .</description>
    </item>
    
    <item>
      <title>What GPUs can do…</title>
      <link>/2017/10/12/what-gpus-can-do.html</link>
      <pubDate>Thu, 12 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/10/12/what-gpus-can-do.html</guid>
      <description>Pcgamer reports &amp;ldquo;Nvidia CEO says Moore’s Law is dead and GPUs wi replace CPUs &amp;rdquo;.
Now, Jensen Huang might be a bit biased here, but he reminded us that &amp;ldquo;GPUs are advancing at a much faster pace than CPUs&amp;rdquo; and &amp;ldquo;that GPUs will replace CPUs soon, adding that at this point, designers can hardly work out advanced parallel instruction architectures for CPUs.&amp;rdquo; So what can a modern GPU do? Well, apparently Font Rendering is still a hard problem for GPUs, and a bottleneck in modern browsers.</description>
    </item>
    
    <item>
      <title>Scaling, automatically and manually</title>
      <link>/2017/08/09/scaling-automatically-and-manually.html</link>
      <pubDate>Wed, 09 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/08/09/scaling-automatically-and-manually.html</guid>
      <description>There is an interesting article by Brendan Gregg out there, about the actual data that goes into the Load Average metrics of Linux. The article has a few funnily contrasting lines. Brendan Gregg states
 Load averages are an industry-critical metric – my company spends millions auto-scaling cloud instances based on them and other metrics […]
 but in the article we find Matthias Urlichs saying
 The point of &amp;ldquo;load average&amp;rdquo; is to arrive at a number relating how busy the system is from a human point of view.</description>
    </item>
    
    <item>
      <title>An abundance of IOPS and Zero Jitter</title>
      <link>/2017/07/26/an-abundance-of-iops-and-zero-jitter.html</link>
      <pubDate>Wed, 26 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/07/26/an-abundance-of-iops-and-zero-jitter.html</guid>
      <description>Two weeks ago, I wrote about [The Data Center in the Age of Abundance]({% link _posts/2017-07-07-the-data-center-in-the-age-of-abundance.md %}) and claimed that IOPS are - among other things - a solved problem.
What does a solved problem look like?
Here is a benchmark running 100k random writes of 4K per second, with zero Jitter, at 350µs end-to-end write latency across six switches. Databases really like reliably timed writes like these. Maximum queue depth would be 48, the system is not touching that.</description>
    </item>
    
    <item>
      <title>On cache problems, and what they mean for the future</title>
      <link>/2017/06/23/on-cache-problems-and-what-they-mean-for-the-future.html</link>
      <pubDate>Fri, 23 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/06/23/on-cache-problems-and-what-they-mean-for-the-future.html</guid>
      <description>This is a disk utilization graph on a heavily loaded Graphite box. In this case, a Dell with a MegaRAID, but that actually does not matter too much.
Go-carbon was lagging and buffering on the box, because the SSD was running at its IOPS limit. At 18:10, the write-back cache and the &amp;ldquo;intelligent read-ahead&amp;rdquo; are being disabled, that is, the MegaRAID is being force-dumbed down to a regular non-smart controller. The effect is stunning.</description>
    </item>
    
    <item>
      <title>&#34;Usage Patterns and the Economics of the Public Cloud&#34;</title>
      <link>/2017/06/12/usage-patterns-and-the-economics-of-the-public-cloud.html</link>
      <pubDate>Mon, 12 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/06/12/usage-patterns-and-the-economics-of-the-public-cloud.html</guid>
      <description>The paper (PDF ) is, to say it in the words of Sascha Konietzko, eine ausgesprochene Verbindung von Schlau und Dumm (&amp;ldquo;a very special combination of smart and stupid&amp;rdquo;).
The site mcafee.cc is not related to the corporation of the same name, but the site of one of the authors, R. Preston McAfee.
The paper looks at the utilization data from a number of public clouds, and tries to apply some dynamic price finding logic to it.</description>
    </item>
    
    <item>
      <title>The cost of winning…</title>
      <link>/2017/03/10/the-cost-of-winning.html</link>
      <pubDate>Fri, 10 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/03/10/the-cost-of-winning.html</guid>
      <description>Tech.co has an article titled Artificial Intelligence Startups Are Winning the Cybersecurity Race . The claim is basically first that old, pattern and signature based malware recognition is useless, and second, that new, behavior based malware recognition employing mystery AI technologies fixes things. The article closes with
 In the near future, we predict that AI will be able to effectively fight against hackers by easily detecting repacked viruses. It’s just a matter of time.</description>
    </item>
    
    <item>
      <title>OMG, our cybervaccines are failing</title>
      <link>/2017/02/17/omg-our-cybervaccines-are-failing.html</link>
      <pubDate>Fri, 17 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/02/17/omg-our-cybervaccines-are-failing.html</guid>
      <description>Dark Reading is scared: All new malware is &amp;ldquo;zero-day&amp;rdquo;, for an interesting and wrong definition of zero-day, because then the article reads much more impressive.
The actual definition of a Zero Day is a previously unknown exploit that is being used by some party to compromise a machine. In the article, the term is used differently, meaning a file that is a known malware, but has changed itself so that it has a checksum that is not in currently distributed signature catalogs of known malware.</description>
    </item>
    
    <item>
      <title>Load, Load Testing and Benchmarking</title>
      <link>/2017/02/16/load-load-testing-and-benchmarking.html</link>
      <pubDate>Thu, 16 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/02/16/load-load-testing-and-benchmarking.html</guid>
      <description>(This article also available in [german language]({% link _posts/2012-08-28-load-load-testing-und-benchmarks.md %}).)
So you have a new system and want to know what the load limits are. For that you want to run a benchmark.
Basic Benchmarking   The main plan looks like this:
The basic idea: Find a box, offer load, see what happens, learn.
You grab a box and find a method to generate load. Eventually the box will be fully loaded and you will notice this somehow.</description>
    </item>
    
    <item>
      <title>Hipsterdoom with Mongobingo</title>
      <link>/2017/02/10/hipsterdoom-at-mongobingo.html</link>
      <pubDate>Fri, 10 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/02/10/hipsterdoom-at-mongobingo.html</guid>
      <description>Felix Gessert does a postmortem of the failed Parse startup and product: &amp;ldquo;The AWS and MongoDB Infrastructure of Parse: Lessons Learned &amp;rdquo;.
 Technical problem II: the real problem and bottleneck was not the API servers but almost always the shared MongoDB database cluster.
 And that was with MongoRocks (Mongo on RocksDB) and replacing the initial app in Ruby with a Go implementation of said thing, with WriteConcern = 1, and other horrible presets.</description>
    </item>
    
    <item>
      <title>Dude, where is my memory?</title>
      <link>/2012/11/12/dude-where-is-my-memory.html</link>
      <pubDate>Mon, 12 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/11/12/dude-where-is-my-memory.html</guid>
      <description>&amp;ldquo;Kris, bitte schau Dir mal unsere Datenbank an. Wir haben hier einen Generator für unsere Materialized Views, und auf einer Datenbank von 6 GB Größe werden 40 GB Speicher gefüllt und wir kommen sogar ins Swappen.&amp;rdquo;
Na, das ist mal interessant. The fragliche Kiste hat 48 GB RAM, und in der Tat kaum 6 GB Daten.
mysql&amp;gt; select -&amp;gt; sum(data_length+index_length)/1024/1024/1024 as gb -&amp;gt; from tables -&amp;gt; where table_schema not in (&amp;#39;information_schema&amp;#39;, &amp;#39;performance_schema&amp;#39;, &amp;#39;mysql&amp;#39;); +----------------+ | gb | +----------------+ | 5.</description>
    </item>
    
    <item>
      <title>Enemy Action</title>
      <link>/2012/10/31/enemy-action.html</link>
      <pubDate>Wed, 31 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/10/31/enemy-action.html</guid>
      <description>&amp;ldquo;Kris, guck mal, connection surge auf $WICHTIGER_MASTER, davor kurzer Activity drop. Alle anderen Graphen sehen normal aus.&amp;rdquo;
![Graph: Connection Surge]({{ site.baseurl }}/uploads/screenshot-kris-20121031-1.png)
und
![Graph: QPS Drop]({{ site.baseurl }}/uploads/screenshot-kris-20121031-2.png)
Ich gucke.
Alle anderen Graphen sehen in der Tat normal aus. Aber um 13:20 kommt für kurze Zeit alles Processing zum Stillstand.
Wir haben ja log_processlist.pl. Falls es sich also um irgendein wildgewordenes Lock handeln sollte, würde ich das also in den 13_20 und 13_21 Dateien sehen.</description>
    </item>
    
    <item>
      <title>MySQL Replication Load Monitor</title>
      <link>/2012/09/28/mysql-replication-load-monitor.html</link>
      <pubDate>Fri, 28 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/09/28/mysql-replication-load-monitor.html</guid>
      <description>Mein Kollege Dennis Kaarsemaker hat jetzt einen Artikel zu dem Replication Load Monitor von Booking.com gebloggt. Der Monitor basiert auf Arbeiten von Mark Leith .
Möge er Euch allen nützen.</description>
    </item>
    
    <item>
      <title>House und Heisenberg revisited</title>
      <link>/2012/09/25/house-und-heisenberg-revisited.html</link>
      <pubDate>Tue, 25 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/09/25/house-und-heisenberg-revisited.html</guid>
      <description>Ich habe heute an dem Problem weiter geforscht und wir haben etabliert, dass die Ursache nicht der Quelltext des betreffenden Diamond-Collectors sein kann.
Auf allen betroffenen Kisten habe ich dann gesehen, daß die entsprechenden Queries gegen Performance-Schema ein
mysql&amp;gt; select \* from performance_schema.threads; Empty set (0.01 sec) zurück liefern.
Weitere Untersuchung stellt heraus: P_S ist aber an. Jedoch:
mysql&amp;gt; select \* from performance_schema.setup_instruments; Empty set (0.03 sec) mysql&amp;gt; select \* from performance_schema.</description>
    </item>
    
    <item>
      <title>Der Herr House und der Herr Heisenberg haben Replication Delay</title>
      <link>/2012/09/24/der-herr-house-und-der-herr-heisenberg-haben-replication-delay.html</link>
      <pubDate>Mon, 24 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/09/24/der-herr-house-und-der-herr-heisenberg-haben-replication-delay.html</guid>
      <description>Heute erreicht mich eine Mail, in der ein DBA sich über steigende Replication Delay in einer bestimmten Replikationshierarchie beschwert.
Das ist schlecht, denn die betreffende Hierarchie ist wichtig. Also die &amp;lsquo;Wenn die nicht geht schlafen Leute unter Brücken&amp;rsquo;-Art von wichtig.
Die Theorie war, daß die Änderungsrate in dieser Hierarchie so hoch ist, daß die Schreiblast von MySQL Replikation, die ja Single Threaded ist, nicht mehr bewältigt werden kann. Für diese Theorie sprach nach dem ersten Augenschein, daß alle betroffenen Kisten keine lokalen Platten hatten, sondern auf einem Filer lagen, und Filer sterben wegen der hohen Kommunikationslatenz im SAN bei uns in der Regel weit vor lokalen Platten, wenn es um Replikation geht: Filer sind mehr so beim parallelen Schreiben mit mehreren Threads gut.</description>
    </item>
    
    <item>
      <title>Load, Load Testing und Benchmarks</title>
      <link>/2012/08/28/load-load-testing-und-benchmarks.html</link>
      <pubDate>Tue, 28 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/08/28/load-load-testing-und-benchmarks.html</guid>
      <description>(Diesen Artikel gibt es auch in [englischer Sprache]({% link _posts/2017-02-16-load-load-testing-and-benchmarking.md %}).)
So. Du willst also wissen, was genau die Leistungsgrenzen Deines Systems sind. Und dazu möchtest Du einen Lasttest fahren, um Ergebnisse zu ermitteln.
Die Grundidee Deines Plans sieht so aus:
Du nimmt Deine Kiste und findest eine Methode, um Last zu generieren. Dann wirst Du schon merken, wie weit das geht und wann die Kiste ausgelastet ist.
Der erste Fehler: Den Lastgenerator auf der zu testenden Kiste laufen lassen.</description>
    </item>
    
    <item>
      <title>MySQL vs. Gigabit Network</title>
      <link>/2012/08/22/mysql-vs-gigabit-network.html</link>
      <pubDate>Wed, 22 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/08/22/mysql-vs-gigabit-network.html</guid>
      <description>Wir generieren eine neue Art von [Materialized View]({% link _posts/2012-08-15-materialized-view.md %}) mit dem bekannten Generator-Setup:
Das neue Setup unterscheidet sich in der Logik von denen, die wir bisher verwendet haben, und so kommt es beim Testlauf zu einem ungewöhnlichen und unerwarteten Ereignis:
Um 14:30: Ein Gigabit-Netzwerk mit 125 MB/sec ausgelastet.
Bei einem Probelauf gehen die Alarme los, weil der Gigabit-Netzwerkstrang zur Datenbank mit 125 MB/sec (Ein Gigabit/sec) vollständig ausgelastet ist. Wie man sehen kann, ist die Datenbank zu diesem Zeitpunkt nicht besonders beschäftigt:</description>
    </item>
    
    <item>
      <title>MySQL hakt...</title>
      <link>/2012/08/21/mysql-hakt.html</link>
      <pubDate>Tue, 21 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/08/21/mysql-hakt.html</guid>
      <description>&amp;ldquo;Hey, Kris! Wir haben zwischen 16:20 und 17:20 CEST einen Lasttest durchgeführt und kurz vor 17:00 Uhr einen unerklärlichen Spike und einen Leistungsabfall festgestellt. Kannst Du mal gucken?&amp;rdquo;
Klar kann ich. Wo ich arbeite machen wir etwas, das wir [Testing in Production]({% link _posts/2011-12-02-testing-in-production.md %}) nennen.
Für Lasttests bedeutet das, daß wir einzelne Systeme im Loadbalancer so lange relativ höher gewichten bis sie Probleme bekommen und umfallen. Zur Kontrolle legen wir mit Apache Siege eine Reihe von Sensor-Requests in das zu testende System, nicht zur Lastgenerierung, sondern um zu sehen, wann die Latenz nach oben geht, also um Sättigung des zu testenden Systems zu bemerken bevor es Fehler zu generieren beginnt.</description>
    </item>
    
    <item>
      <title>Statifizierung für S9Y - eine Blaupause</title>
      <link>/2010/05/11/statifizierung-f-r-s9y-eine-blaupause.html</link>
      <pubDate>Tue, 11 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/11/statifizierung-f-r-s9y-eine-blaupause.html</guid>
      <description>An anderer Stelle gab es in einem komplett anderen Kontext eine Diskussion (1 , 2 , 3 ) in der es auch schon mal um die Statifizierung von Seiten ging.
In dem ersten Artikel ging es mir darum zu verdeutlichen, wie viel Mehrarbeit die Auslieferung einer Seite ist, wenn sie durch den Codepath des Webservers erfolgt statt durch den Fastpath - und das Beispiel bezieht sich noch auf die Auslieferung einer Bilddatei, also nur das Schaufeln von Daten statt die Seite zu berechnen.</description>
    </item>
    
    <item>
      <title>Zehn Zentimeter</title>
      <link>/2007/08/11/zehn-zentimeter.html</link>
      <pubDate>Sat, 11 Aug 2007 00:00:00 +0000</pubDate>
      
      <guid>/2007/08/11/zehn-zentimeter.html</guid>
      <description>Kristian, wenn Du über Performance redest, dann redest Du immer von [verteilten, asynchronen Systemen]({% link _posts/2006-07-30-leben-mit-fehlern-der-schl-ssel-zum-scaleout.md %}). Verteilte, asynchrone Systeme sind doof, schwer zu programmieren und laufen der Theorie zuwider, die ich an der Uni gelernt habe. Ich warte glaube ich lieber auf schnellere Prozessoren.
 Viel Spaß beim Warten. Godot wird Dir Deine neue CPU bestimmt bald bringen.
Ein Gigahertz ist ein Takt pro Nanosekunde. Bei Lichtgeschwindigkeit kommt das Signal in einer Nanosekunde in etwa 30cm weit.</description>
    </item>
    
    <item>
      <title>MySQL Performanceprobleme mit einem Profiler analysieren</title>
      <link>/2006/10/14/mysql-performanceprobleme-mit-einem-profiler-analysieren.html</link>
      <pubDate>Sat, 14 Oct 2006 00:00:00 +0000</pubDate>
      
      <guid>/2006/10/14/mysql-performanceprobleme-mit-einem-profiler-analysieren.html</guid>
      <description>Oprofile ist ein Profiler. Und zwar einer, der die Performance Measurement Instrumentation verwendet, die in moderne CPUs eingebaut ist, wenn diese vorhanden ist. Der Profiler braucht also keine speziell für Profiling compilierten Binaries, sondern zieht sich statische Samples des Programmzählers aus dem laufenden System und analysiert diese: Es findet heraus, welcher Prozeß gerade aktiv ist, welche Bibliothek in diesem Prozeß gerade verwendet wird und wenn Symboltabellen vorhanden sind (Kein &amp;ldquo;strip&amp;rdquo; auf die Bibliothek oder das Programm angewendet), dann weiß Oprofile sogar, welche Funktion oder Methode gerade aktiv ist.</description>
    </item>
    
    <item>
      <title>Leben mit Fehlern - der Schlüssel zum Scaleout</title>
      <link>/2006/07/30/leben-mit-fehlern-der-schl-ssel-zum-scaleout.html</link>
      <pubDate>Sun, 30 Jul 2006 00:00:00 +0000</pubDate>
      
      <guid>/2006/07/30/leben-mit-fehlern-der-schl-ssel-zum-scaleout.html</guid>
      <description>Scaling Patterns
In 2004 habe ich auf dem Linuxtag einen kleinen Vortrag zum Thema Skalierbarkeit gehalten. Schon damals war die Message an verschiedenen Stellen im Vortrag &amp;ldquo;Jedes Readproblem ist ein Caching-Problem, jedes Schreibproblem ist ein Verteilungs- und Batchproblem&amp;rdquo;:
Zum Skalieren muß man seine Anwendung in Teilanwendungen unterteilen und die Daten replizieren. Die Replikation muß asynchron erfolgen, ohne Two Phase Commit (2PC), sonst gewinnt man wenig bis nichts. Schreibzugriffe müssen verzögert und gebatched werden, damit sie effizienter abgewickelt werden können.</description>
    </item>
    
  </channel>
</rss>
