<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
<meta http-equiv="x-ua-compatible" content="ie=edge">
<title>Die wunderbare Welt von Isotopp - Testing in Production</title>
<meta name="description" content="">
<meta name="viewport" content="width=device-width, initial-scale=1">

<link rel="manifest" href="site.webmanifest">
<link rel="apple-touch-icon" href="icon.png">
<link rel="favicon.ico" rel="icon" type="image/ico">





	



<link rel="stylesheet" href="/style.min.c5e5cd61f54911f9aafd1dbe09c2f90667957bfe1002126c87aace57759f3446.css">


    </head>
    <body>
        

        <nav class="navbar navbar-expand-lg navbar-light bg-light">
    <div class="container-fluid">
	<a class="navbar-brand" href="" rel="home" title=".Site.Title">
	    Die wunderbare Welt von Isotopp
	</a>
	<button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
	</button>

	<div class="collapse navbar-collapse" id="navbarSupportedContent">
            <ul class="navbar-nav mr-auto">
		
		
		<li class="nav-item ">
                    <a class="nav-link" href="/about/">
			
			<span>About</span>
			<span class="visually-hidden">(Current)</span>
		    </a>
		    
		</li>
            </ul>
            
	</div>
    </div>
</nav>


        <main role="main" class="container-fluid">

            


<div class="page">
    <article class="testing-in-production-page">
	<h1 class="title">
            Testing in Production
	</h1>

	<p>Mitte November ist auf The Testing Planet ein Artikel von Seth Eliot
(Microsoft) erschienen mit dem Titel
<a href="http://www.thetestingplanet.com/2011/11/the-future-of-software-testing-part-one-testing-in-production/" target="_blank" rel="noopener">Testing in Production</a>

.
Eliot schreibt über Software Services, also Dienste, die auf einer Website
laufen, sodaß die User keine Anwendungen installieren müssen (Wir erinnern
uns: Microsoft ist noch immer ganz groß darin, Software auf physikalischen
read-only Medien an Benutzer zu verschicken, auch wenn diese Software seit
einer Dekade kaum mehr als ein Loader für Updates über das Internet ist und
nach der Installation vom Medium erst einmal alle eben installierten Dateien
durch das heruntergeladene Update durch neuere Versionen ersetzt werden).</p>
<p>In Software Services hat der Anbieter jedenfalls die Kontrolle darüber,
welche Version der Software welchem Kunden präsentiert wird, und er hat in
der Regel Zugriff und Meßmöglichkeiten im Data Center, auf dem die Software
läuft, kann also auf der Serverseite diagnostizieren, was wann wie und warum
schief geht.</p>
<p>Eliot behauptet nun, daß User seltsamer sind als Tester sich vorstellen
können und man daher besser so früh als möglich mit echten Benutzern testet
(Testing in Production = TIP).  Vorhergehende synthetische Tests (Up Front
Testing = UFT) können gemacht werden, sollten aber nur so weit gemacht
werden, daß man sicher in der Produktion testen kann.</p>
<p>Eliot weiter:</p>
<blockquote>
<p>For some TiP methodologies we can reduce risk by reducing the exposure of
the new code under test.  This technique is called “Exposure Control” and
limits risk by limiting the user base potentially impacted by the new
code.</p>
</blockquote>
<p>Was er damit meint, wird weiter unten klar, wenn er erläutert, welche Klassen von TIP er unterscheidet.</p>
<ul>
<li>
<p><em>Ramped Deployment</em></p>
<ul>
<li>
<p>Der zu testende Code wird ausgerollt, ist aber zunächst nicht aktiv.  Er
wird für einen Subset der Benutzer aktiviert und überwacht.  Dabei
können unterschiedliche Aspekte des Codes untersucht werden - wie er
sich auf die Geschäftsprozesse auswirkt, ob er technisch funktioniert
oder wie er skaliert etwa.  Benutzer können automatisch oder
handselektiert sein, und wissen entweder, daß die mit experimentellem
Code arbeiten oder nicht.</p>
<p>Entscheidend ist, daß das Deployment von neuem Code und seine
Aktivierung voneinander getrennt werden.  Dies erlaubt es, Features
graduell einzuführen und schnell zu deaktivieren, wenn sich Probleme
entwickeln.</p>
</li>
</ul>
</li>
<li>
<p><em>Controlled Test Flight</em></p>
<ul>
<li>ein a/b-Experiment, in der alte und der neue Code parallel für
unterschiedliche Benutzer aktiviert wird und die Benutzer nicht wissen,
in welcher Kategorie sie sich befinden.  Eine Unterkategorie von Ramped
Deployment.</li>
</ul>
</li>
<li>
<p><em>Experimentation for Design</em></p>
<ul>
<li>eine weitere Verfeinerung von Controlled Test Flight ist, die neue und
die alte User Experience parallel für unterschiedliche, repräsentative
Benutzergruppen zu aktivieren, um den Einfluß der neuen UX auf das
Geschäftsmodell zu prüfen.</li>
</ul>
</li>
<li>
<p><em>Dogfood/Beta</em></p>
<ul>
<li>wissen die Benutzer um die Tatsache, daß sie neuen Code testen, handelt
es sich nicht um Experimentation, sondern um eine Beta.  Sind die
Benutzer Mitarbeiter oder Freunde der Firma, handelt es sich um
Dogfooding.  Hier ist es oft zulässig, mit dem Wissen und Einverständnis
der Benutzer zusätzliche Telemetrie zu installieren und auszuwerten.</li>
</ul>
</li>
<li>
<p><em>Synthetic Test in Production</em></p>
<ul>
<li>das Anwenden von automatisierten UFT-Systemen auf Produktionssysteme.
Sie können verwenden werden, um das Produktionssystem oder sein
Monitoring zu validieren.</li>
</ul>
</li>
<li>
<p><em>Load/Capacity Test in Production</em></p>
<ul>
<li>
<p>Last und Kapazitätstest in der Produktion, bei Eliot unter Verwendung
synthetischer Last gegen Produktionssysteme, meistens zusätzlich zur
existierenden Last durch reale Benutzer, um die Kapazität des Systems zu
bestimmen.
<!-- raw HTML omitted --><!-- raw HTML omitted -->
Die mir bekannten Anwender solcher Verfahren spielen stattdessen eher
mit den Gewichten an ihren Load Balancern, um die externe Last durch
reale User auf weniger und weniger Backends zu konzentrieren.
<!-- raw HTML omitted --><!-- raw HTML omitted --></p>
<p>Synthetische Last wird dabei lediglich als Meßsonde verwendet, um die Latenz
von Requests zu überwachen - kommt zur typischen Think Time des Benchmarks
eine Wait Time hinzu, ist die den getesteten Frontends angebotene Load
größer als ihre Kapazität und es baut sich eine Queue auf.  Lastsättigung
ist erreicht und die Kapazität des Gesamtsystems kann durch einfache
Dreisätze bestimmt werden.  Bricht man den Test hier ab, ist die UX für die
realen User nicht destruktiv beeinflußt: Das System mag einigen Benutzern
für kurze Zeit langsam erscheinen, ist aber zu allen Zeiten normal
Funktionsfähig.
<!-- raw HTML omitted --><!-- raw HTML omitted --></p>
<p>Bricht man den Test nicht ab, sondern erhöht die Last vorsichtig weiter,
kann man den Failure Mode des Systems verifizieren: Art und Lage der
begrenzenden Ressource im Gesamtsystem wird offensichtlich, Qualität des
Monitorings und Prozesse im Operating werden mitgeprüft.  Diese Phase des
Tests erfordert schnelle Reaktion, um den Einfluß auf die UX der realen
Benutzer zu minimieren.</p>
</li>
</ul>
</li>
<li>
<p><em>Outside-in load /performance testing</em></p>
<ul>
<li>ein Lasttest mit synthetischer Load, die von einer externen Quelle in
die Produktionsumgebung injeziert wird, also denselben Weg nach drinnen
nimmt wie die realen Benutzer.</li>
</ul>
</li>
<li>
<p><em>User Scenario Execution</em></p>
<ul>
<li>Ausführung von Endbenutzer-Szenarien gegen ein Produktionssystem von den
Endpunkten echter Benutzer.  Kann manuelles Testen beinhalten.  Diese
Tests können regional unterschiedliche UX sichtbar machen (&ldquo;Das System
ist schnell genug in Europa, von Asien aus aber kaum benutzbar.&quot;)</li>
</ul>
</li>
<li>
<p><em>Data Mining</em></p>
<ul>
<li>
<p>Die Logdaten echter Benutzer werden nach Problemen oder Testfällen
durchsucht, die spezifische Szenarien darstellen.  Die Fälle, die
auftreten, werden automatisch als Bugtickets eingetragen.  Das kann in
Echtzeit passieren.  <!-- raw HTML omitted --><!-- raw HTML omitted --></p>
<p>Echtzeitmonitoring kann auf viele verschiedene Weisen nützlich sein.
Insbesondere in den o.a.  Lasttests ist ein Echtzeit-Errormonitor
notwendig, um die Saturierung von der Überlast des Systems trennen zu
können, und um Lage und Failure Mode der überlasteten Komponente im
Produktionsweg schnell erkennen zu können.  Ohne ein solches
Echtzeitmonitoring ist diese Art von Test nicht sicher durchführbar.</p>
</li>
</ul>
</li>
<li>
<p><em>Destructive Testing</em></p>
<ul>
<li>Injektion von Fehlern in Produktionssysteme, um Servicekontinuität im
Fehlerfall zu validieren (
<a href="http://www.codinghorror.com/blog/2011/04/working-with-the-chaos-monkey.html" target="_blank" rel="noopener">Chaos Monkey</a>


).</li>
</ul>
</li>
<li>
<p><em>Production Validation</em></p>
<ul>
<li>Echtzeitmonitore, die die verschiedenen Phasen der Produktion auf
Businessebene, Contentebene, Technischer Ebene, Netzwerkebene und so
weiter überwachen und visualisieren.</li>
</ul>
</li>
</ul>
<p>Eliot bringt dann verschiedene Beispiel für TIP: Googles und Bings
a/b-Experimente und 1% Launches werden genannt, sie sind Beispiele für
Experimentation for Design.  Controlled Test Flights werden dort ebenfalls
verwendet, dabei werden kritische Änderungen ausgerollt und parallel zu
getestetem Code betrieben - oft werden dabei Daten zweimal geschrieben: Der
alte Code führt das alte System weiter, der neue Code arbeitet im neuen
System mit anderen Dateien oder Datenbanktabellen.</p>
<p>Chaosmonkey war der Vorläufer eines Systems für Destructive Testing, das
jetzt die
<a href="http://techblog.netflix.com/2011/07/netflix-simian-army.html" target="_blank" rel="noopener">Simian Army</a>


darstellt: Neben Chaos Monkey, der Komponenten zufällig aus dem System
entfernt gibt es nun Latency Monkey, der Dienste zufällig verzögert,
Conformity Monkey, der Systeme aus dem Dienst kippt, die nicht auf dem
erwarteten Stand sind und viele andere Dienstprüfer und Killer mehr.</p>
<p>Eliot weist darauf hin, daß Tests in der Produktion gefährlich sein können
und sie deswegen so aufgebaut werden müssen, daß sie keine Produktionsdaten
verändern können und nur mit funktionierendem und schnellem Monitoring
durchgeführt werden können.</p>
<p>Korrekt ausgeführt eröffnen sie aber eine Menge Lernmöglichkeiten, die
traditionellem Testen nicht zur Verfügung stehen.</p>


	
    </article>
</div>



            <footer>
    <p>
	&copy; Copyright 2021 Someone or something
    </p>
</footer>


        </main>

	





<script src="/js/bootstrap.js"></script>




<script src="/js/lunr.js"></script>





<script src="/js/app.js"></script>


    </body>
</html>
