<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>mysql on Die wunderbare Welt von Isotopp</title>
    <link>https://blog.koehntopp.info/tags/mysql.html</link>
    <description>Recent content in mysql on Die wunderbare Welt von Isotopp</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 28 Oct 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://blog.koehntopp.info/tags/mysql/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>MySQL: Python and WHERE ... IN ()</title>
      <link>https://blog.koehntopp.info/2021/10/28/python-where-in.html</link>
      <pubDate>Thu, 28 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2021/10/28/python-where-in.html</guid>
      <description>As a developer using Python, I want to be able to hand a list to an SQL statement with a WHERE id IN (…) clause, and it should do the right thing.
 Well, that is not how it started, because it was asked on the internal no-work-channel, so it kind of escalated more.
A question   The original question was:
 Dev&amp;gt; Why is it 2021, and SQL prepared statements still can&amp;rsquo;t deal with IN?</description>
    </item>
    
    <item>
      <title>MySQL: Our MySQL in 2010, a hiring interview question</title>
      <link>https://blog.koehntopp.info/2021/09/27/mysql-booking-2010-a-hiring-interview-question.html</link>
      <pubDate>Mon, 27 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2021/09/27/mysql-booking-2010-a-hiring-interview-question.html</guid>
      <description>I ranted about hiring interviews, and the canned questions that people have to answer. One of the interviews we do is a systems design interview, where we want to see how (senior) people use components and patterns to design a system for reliability and scale-out.
A sample question (based on a Twitter thread in German):
 It is 2010, and the company has a database structure where a fixed number front end machines form a cell.</description>
    </item>
    
    <item>
      <title>MySQL: Binding the ORM</title>
      <link>https://blog.koehntopp.info/2021/09/17/binding-the-orm.html</link>
      <pubDate>Fri, 17 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2021/09/17/binding-the-orm.html</guid>
      <description>My task is to collect performance data about a single query, using PERFORMANCE_SCHEMA (P_S for short) in MySQL, to ship it elsewhere for integration with other data.
In a grander scheme of things, I will need to define what performance data from a query I am actually interested in. I will also need to find a way to attribute the query (as seen on the server) to a point in the codebase of the client, which is not always easy when an ORM or other SQL generator is being used.</description>
    </item>
    
    <item>
      <title>MySQL: Tracing a single query with PERFORMANCE_SCHEMA</title>
      <link>https://blog.koehntopp.info/2021/09/15/mysql-tracing-a-single-query-with-performanceschema.html</link>
      <pubDate>Wed, 15 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2021/09/15/mysql-tracing-a-single-query-with-performanceschema.html</guid>
      <description>My task is to collect performance data about a single query, using PERFORMANCE_SCHEMA (P_S for short) in MySQL, to ship it elsewhere for integration with other data.
In a grander scheme of things, I will need to define what performance data from a query I am actually interested in. I will also need to find a way to attribute the query (as seen on the server) to a point in the codebase of the client, which is not always easy when an ORM or other SQL generator is being used.</description>
    </item>
    
    <item>
      <title>MySQL: Page compression revisited</title>
      <link>https://blog.koehntopp.info/2021/09/14/mysql-page-compression-revisited.html</link>
      <pubDate>Tue, 14 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2021/09/14/mysql-page-compression-revisited.html</guid>
      <description>Like I said, I never had much reason to use table compression, and only recently looked into the topic. MySQL Page Compression looks a lot easier at the database end of things, but relies on hole punching support in the file system. Let&amp;rsquo;s have a look at what that means.
Files, Inodes and Arrays of Blocks   The original Unix filesystem saw the disk as a sea of blocks, which were represented in a free map as an array of bits.</description>
    </item>
    
    <item>
      <title>MySQL: CREATE IF NOT EXISTS TABLE, but CREATE OR REPLACE VIEW</title>
      <link>https://blog.koehntopp.info/2021/09/10/create-if-not-exists.html</link>
      <pubDate>Fri, 10 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2021/09/10/create-if-not-exists.html</guid>
      <description>For the MySQL Million Challenge, I was going through the server syntax in order to understand what things can be created in the server. And now my OCD triggered. DDL is a mess.
Creation    As a database developer, I want to be able to create server objects using the CREATE thing syntax.
 The server gives you that for the following things:
 DATABASE EVENT FUNCTION (and FUNCTION SONAME) INDEX LOGFILE GROUP (NDB only, not going to look at this) PROCEDURE RESOURCE GROUP ROLE SERVER SPATIAL REFERENCE SYSTEM TABLE TABLESPACE TRIGGER USER VIEW  Safe creation    As a database developer I want to be able to script things safely, so I need IF NOT EXISTS clauses in my CREATE syntax.</description>
    </item>
    
    <item>
      <title>MySQL: The Million Challenge</title>
      <link>https://blog.koehntopp.info/2021/09/10/mysql-million-challenge.html</link>
      <pubDate>Fri, 10 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2021/09/10/mysql-million-challenge.html</guid>
      <description>A long-standing idea that I have is to test the servers limits: How does it fail and break if there are very many of a thing? Previously that was too easy, because many structures were constructed in a way that it was obvious they would not scale. But with MySQL 8 many things were overhauled, so let&amp;rsquo;s see what we can make many of and see how the server fares.</description>
    </item>
    
    <item>
      <title>MySQL: The table &#39;../tmp/#sql…&#39; is full</title>
      <link>https://blog.koehntopp.info/2021/09/09/tmp-file-full.html</link>
      <pubDate>Thu, 09 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2021/09/09/tmp-file-full.html</guid>
      <description>We observe a large number of messages of the kind
The table &amp;#39;../tmp/#sql…&amp;#39; is full Before MySQL 8   In older Versions of MySQL, implied temporary tables are being created, whenever your EXPLAIN contained the phrase using temporary.
In this case, MySQL would create an in-memory temporary table to materialize an intermediate query result, and then continue to process the data from there. If that temporary table was larger than some configurable limit, the temporary table would instead be converted to a MyISAM table on disk, streamed out, and then work would continue with this.</description>
    </item>
    
    <item>
      <title>MySQL: Two kinds of compression</title>
      <link>https://blog.koehntopp.info/2021/09/09/mysql-two-kinds-of-compression.html</link>
      <pubDate>Thu, 09 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2021/09/09/mysql-two-kinds-of-compression.html</guid>
      <description>I never had much reason to use table compression, so I largely ignored the topic in MySQL. I knew that MySQL had table compression since 5.1, but I also knew the implementation was horribly complicated and double stored all data. There is also page compression, a feature introduced with 5.7, which replaces table compression and works much better.
Table Compression   Table Compression is available in MySQL 5.1 and newer.</description>
    </item>
    
    <item>
      <title>MySQL: A job queue in Python</title>
      <link>https://blog.koehntopp.info/2021/07/13/mysql-a-job-queue-in-python.html</link>
      <pubDate>Tue, 13 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2021/07/13/mysql-a-job-queue-in-python.html</guid>
      <description>Somebody needed a job queue in Python: Multiple writers insert into it in random order, and the jobs are written into the MySQL table jobs. From the jobs table, multiple consumers claim jobs in batches of n or smaller (n=100), and process them. After processing, the consumers delete the jobs. We need concurrent job generation and consumption, with proper and efficient locking.
The full source for this example can be seen in mysql-dev-examples in mysql-claim-jobs.</description>
    </item>
    
    <item>
      <title>A MySQL flight recorder</title>
      <link>https://blog.koehntopp.info/2021/04/22/a-mysql-flight-recorder.html</link>
      <pubDate>Thu, 22 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2021/04/22/a-mysql-flight-recorder.html</guid>
      <description>Sometimes things go wrong, and it surely would be nice if you at least knew afterwards what happened. Where I work, we are running a shell script older than time itself, once a minute. The script writes files to /var/log/mysql_pl, into a directory named after the current weekday and named after the current hour and minute.
So when a box crashes on Thursday at 22:09, as long as I can login to it, I still can try to look at /var/log/mysql_pl/Thu/22_0?</description>
    </item>
    
    <item>
      <title>MySQL and UUIDs</title>
      <link>https://blog.koehntopp.info/2021/04/06/mysql-and-uuids.html</link>
      <pubDate>Tue, 06 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2021/04/06/mysql-and-uuids.html</guid>
      <description>In ALTER TABLE for UUID we discuss currently proper way to store and handle UUID in MySQL. Currently it works, even in a performant way, but it still hurts. It should not.
Definition of UUID   The RFC 4122 defines various types of UUID, and how they are being formatted for presentation and as a bit field on the wire. As this document was written bei Leach and Salz, among others, RFC 4122 UUIDs are also called &amp;ldquo;Leach-Salz UUIDs&amp;rdquo; (for example in the Java Documentation ).</description>
    </item>
    
    <item>
      <title>Making an unexpected leap with interval syntax</title>
      <link>https://blog.koehntopp.info/2021/04/02/making-an-unexpected-leap-with-interval-syntax.html</link>
      <pubDate>Fri, 02 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2021/04/02/making-an-unexpected-leap-with-interval-syntax.html</guid>
      <description>(based on a find by Ruud van Tol, and several Twitter contributions)
Ruud commented on our DST discussion with
mysql&amp;gt;SELECT&amp;#39;2019-02-28 12:34:56&amp;#39;+INTERVAL1YEAR+INTERVAL1DAYasa,&amp;#39;2019-02-28 12:34:56&amp;#39;+INTERVAL1DAY+INTERVAL1YEARasb\Ga:2020-02-2912:34:56b:2020-03-0112:34:562019 is a year before a leap year. Adding (left to right) a year brings us to 2020-02-28, and then adding a day makes this 2020-02-29, because it&amp;rsquo;s a leap year.
On the other hand, adding a day first makes it 2019-03-01, and then adding a year makes it 2020-03-01, a different result.</description>
    </item>
    
    <item>
      <title>Things you didn&#39;t know about MySQL and Date and Time and DST</title>
      <link>https://blog.koehntopp.info/2021/03/29/mysql-date-time-dst.html</link>
      <pubDate>Mon, 29 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2021/03/29/mysql-date-time-dst.html</guid>
      <description>(based on a conversation with a colleague, and a bit of Twitter )
A Conundrum   A developer colleague paged me with this:
mysql&amp;gt;selectUNIX_TIMESTAMP(&amp;#34;2021-03-26 03:07:00&amp;#34;+INTERVAL2YEAR)-UNIX_TIMESTAMP(&amp;#34;2021-03-26 02:07:00&amp;#34;+INTERVAL2YEAR)asdelta\Gdelta:420It is obviously wrong, and weirdly so. It only works for &amp;ldquo;2 year&amp;rdquo;, not with other values:
mysql&amp;gt;selectUNIX_TIMESTAMP(&amp;#34;2021-03-26 03:07:00&amp;#34;+INTERVAL1-11year_month)-UNIX_TIMESTAMP(&amp;#34;2021-03-26 02:07:00&amp;#34;+INTERVAL1-11year_month)asdelta\Gdelta:3600mysql&amp;gt;selectUNIX_TIMESTAMP(&amp;#34;2021-03-26 03:07:00&amp;#34;+INTERVAL1-12year_month)-UNIX_TIMESTAMP(&amp;#34;2021-03-26 02:07:00&amp;#34;+INTERVAL1-12year_month)asdelta\Gdelta:3600mysql&amp;gt;selectUNIX_TIMESTAMP(&amp;#34;2021-03-26 03:07:00&amp;#34;+INTERVAL1-13year_month)-UNIX_TIMESTAMP(&amp;#34;2021-03-26 02:07:00&amp;#34;+INTERVAL1-13year_month)asdelta\Gdelta:3600It has to be exactly 730 days (2 * 365 days, 2 years):
mysql&amp;gt;selectUNIX_TIMESTAMP(&amp;#34;2021-03-26 03:07:00&amp;#34;+INTERVAL729day)-UNIX_TIMESTAMP(&amp;#34;2021-03-26 02:07:00&amp;#34;+interval729day)asdelta\Gdelta:3600mysql&amp;gt;selectUNIX_TIMESTAMP(&amp;#34;2021-03-26 03:07:00&amp;#34;+INTERVAL730day)-UNIX_TIMESTAMP(&amp;#34;2021-03-26 02:07:00&amp;#34;+interval730day)asdelta\Gdelta:420mysql&amp;gt;selectUNIX_TIMESTAMP(&amp;#34;2021-03-26 03:07:00&amp;#34;+INTERVAL731day)-UNIX_TIMESTAMP(&amp;#34;2021-03-26 02:07:00&amp;#34;+interval731day)asdelta\Gdelta:3600The Reason   In our math, we have two expressions mixing MySQL Timestamp data types with UNIX Timestamp Integers.</description>
    </item>
    
    <item>
      <title>That&#39;s a lot of databases</title>
      <link>https://blog.koehntopp.info/2021/03/24/a-lot-of-mysql.html</link>
      <pubDate>Wed, 24 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2021/03/24/a-lot-of-mysql.html</guid>
      <description>Where I work, we are using MySQL a lot. The databases are being organized in replication hierarchies, and each hierarchy is a tree topology with a single primary and a number of intermediate replicas.
Replication is a tree managed by Orchestrator   We are using MySQL orchestrator to manage the replication topology.
MySQL Orchestrator shows a typical replication hierarchy. Each color indicates a different data center/availability zone. Replication is a tree, from the primary to per-AZ intermediate replicas for fan-out to leaf replicas.</description>
    </item>
    
    <item>
      <title>Memory saturated MySQL</title>
      <link>https://blog.koehntopp.info/2021/03/12/memory-saturated-mysql.html</link>
      <pubDate>Fri, 12 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2021/03/12/memory-saturated-mysql.html</guid>
      <description>»If at all possible, we build databases so that the working set of the database fits into memory.« What does that even mean?
Working Set   In computer science, the “Working Set” of a program is the set of things it will be accessing in the near future. Because computer science has not yet solved looking into the future, we are looking at the set of things we accessed most recently and hope for The Best™.</description>
    </item>
    
    <item>
      <title>MySQL from Below</title>
      <link>https://blog.koehntopp.info/2021/02/25/mysql-from-below.html</link>
      <pubDate>Thu, 25 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2021/02/25/mysql-from-below.html</guid>
      <description>When you insert data into a database and run COMMIT you expect things to be there: Atomically, Consistent, Isolated and Durable , like Codd commanded us 40 years ago, but also quickly. There is a surprising amount of sophistication being poured into this, but since I do not want to shame MongoDB and Redis developers in this post, I am not going to talk about that much in this place.</description>
    </item>
    
    <item>
      <title>Validating storage</title>
      <link>https://blog.koehntopp.info/2021/02/24/validating-storage.html</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2021/02/24/validating-storage.html</guid>
      <description>Where I work, we try to run databases in a memory saturated way. That is, we try to provide so much memory that the working set of the database is memory resident, or in other words, the number of disk reads after an initial warmup is no longer dependent on the database load.
Workload Intelligence Analytics showing &amp;ldquo;IOPS over time&amp;rdquo; for a mixed read/write benchmark on Datera iSCSI.
We can validate and prove that with automated load testing: For each replication chain we single out a production host, and increase the hosts weight in the load balancer until the system load1 becomes critical.</description>
    </item>
    
    <item>
      <title>Database as a Queue</title>
      <link>https://blog.koehntopp.info/2021/01/28/database-as-a-queue.html</link>
      <pubDate>Thu, 28 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2021/01/28/database-as-a-queue.html</guid>
      <description>The DBA experience at work suggests that every single schema at some point in its lifecycle holds a queue table. These are tables in which some processes (the “producers”) put rows, which a swarm of other processes (the “consumers”) lock and consume.
A variation on that theme is the state machine, in which jobs are placed by producers. Consumers do not immediately delete them, but update them a few times to indicate processing progress, before the rows are ultimately being deleted.</description>
    </item>
    
    <item>
      <title>SQL Clause is coming to town</title>
      <link>https://blog.koehntopp.info/2020/12/26/sql-clause-is-coming-to-town.html</link>
      <pubDate>Sat, 26 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/12/26/sql-clause-is-coming-to-town.html</guid>
      <description>Olya Kudriavtseva has an ugly christmas sweater :
 &amp;ldquo;He&amp;rsquo;s making a table. He&amp;rsquo;s sorting it twice. SELECT * FROM contacts WHERE behavior = &amp;ldquo;nice&amp;rdquo;; SQL Clause is coming town! (buy here )
Katie Bauer observes :
 I mean, except for the fact that sorting something twice is TERRIBLY optimized
 So how bad is this? Let&amp;rsquo;s find out.
Some test data   We are defining a table santa, where we store peoples names (GDPR, EU Regulation 2016/679 applies!</description>
    </item>
    
    <item>
      <title>Not JOINing on PERFORMANCE_SCHEMA</title>
      <link>https://blog.koehntopp.info/2020/12/01/not-joining-on-performance-schema.html</link>
      <pubDate>Tue, 01 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/12/01/not-joining-on-performance-schema.html</guid>
      <description>The tables in PERFORMANCE_SCHEMA (P_S) are not actually tables. You should not think of them as tables, even if your SQL works on them. You should not JOIN them, and you should not GROUP or ORDER BY them.
Unlocked memory buffers without indexes   The stuff in P_S has been created with &amp;ldquo;keep the impact on production small&amp;rdquo; in mind. That is, from a users point of view, you can think of them as unlocked memory buffers - the values in there change as you look at them, and there are precisely zero stability guarantees.</description>
    </item>
    
    <item>
      <title>Backups and Replication</title>
      <link>https://blog.koehntopp.info/2020/11/27/backups-and-replication.html</link>
      <pubDate>Fri, 27 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/11/27/backups-and-replication.html</guid>
      <description>There was a question at work about MySQL backups and restore. I needed to explain more.
We use databases to make state persistent. That is: As a developer you can think of your database as a single giant, structured global variable with a weird access method, and to make things worse, concurrent access.
 A database is just a global variable to your code
 We can log statements that change the state of our database in a log.</description>
    </item>
    
    <item>
      <title>MySQL: Ecosystem fragmentation</title>
      <link>https://blog.koehntopp.info/2020/10/28/mysql-ecosystem-fragmentation.html</link>
      <pubDate>Wed, 28 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/10/28/mysql-ecosystem-fragmentation.html</guid>
      <description>Sometimes things change in a way that is hard to put a finger on, but I am doing this MySQL thing since 3.23, and commercially since 2005, and the environment is changing. These days, when you talk to people in need of MySQL, the first thing you have to ask them is &amp;ldquo;Which MySQL&amp;rdquo;. And by that I do not mean a version number in the first place.
The answer may be:</description>
    </item>
    
    <item>
      <title>An unexpected pool size increase</title>
      <link>https://blog.koehntopp.info/2020/10/07/an-unexpeced-pool-size-increase.html</link>
      <pubDate>Wed, 07 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/10/07/an-unexpeced-pool-size-increase.html</guid>
      <description>At work, replication chains have a single primary database node, to which you write, and then multiple replicas, in multiple AZs.
Here is what the one sample chain looks like in Orchestrator:
instance-918d is the current primary, in the blue AZ. Replicas in orange and green are in other AZs. Blue badges indicate multiple replicas, eg (38) means 38 machines.
When you talk to a database, you get two database handles:</description>
    </item>
    
    <item>
      <title>What are the problems with POSIX?</title>
      <link>https://blog.koehntopp.info/2020/10/05/what-are-the-problems-with-posix.html</link>
      <pubDate>Mon, 05 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/10/05/what-are-the-problems-with-posix.html</guid>
      <description>Every once in a while there is the IT news article that kind of triggers me. This time it was &amp;ldquo;Object-Storage-Protokoll könnte Posix ablösen&amp;rdquo; in german computer news site Golem . The article speaks about mmap(), NVMEoF and object storage and how it could revolutionize or complete object storages, but does not link to an original article, names no persons and no paper. Also, what do these things - mmap, NVMEoF, object storage and Posix, even have in common?</description>
    </item>
    
    <item>
      <title>MySQL: Import CSV, not using LOAD DATA</title>
      <link>https://blog.koehntopp.info/2020/09/28/mysql-import-csv-not-using-load-data.html</link>
      <pubDate>Mon, 28 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/09/28/mysql-import-csv-not-using-load-data.html</guid>
      <description>All over the Internet people are having trouble getting LOAD DATA and LOAD DATA LOCAL to work. Frankly, do not use them, and especially not the LOCAL variant. They are insecure, and even if you get them to work, they are limited and unlikely to do what you want. Write a small data load program as shown below.
Not using LOAD DATA LOCAL   The fine manual says :</description>
    </item>
    
    <item>
      <title>Importing account statements and building a data warehouse</title>
      <link>https://blog.koehntopp.info/2020/09/26/my-private-data-warehouse.html</link>
      <pubDate>Sat, 26 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/09/26/my-private-data-warehouse.html</guid>
      <description>This is an update and translation of a much older article , which I wrote in German Language back then. I was experimenting with importing the account statements from my German Sparkasse, which at that time were being made available as a CSV.
The initial data load   The data looked like this:
$ head -2 /home/kris/Documents/banking/umsatz-22758031-29122004.csv &amp;#34;Local Account&amp;#34;;&amp;#34;Book Date&amp;#34;;&amp;#34;Valuta Date&amp;#34;;&amp;#34;Transaction Type&amp;#34;; &amp;#34;Purpose&amp;#34;; &amp;#34;Remote Party&amp;#34;;&amp;#34;Remote Account&amp;#34;;&amp;#34;Bank Code&amp;#34;; &amp;#34;Amount&amp;#34;;&amp;#34;Currency&amp;#34;;&amp;#34;Info&amp;#34; &amp;#34;08154711&amp;#34;;&amp;#34;30.12&amp;#34;;&amp;#34;30.12.05&amp;#34;;&amp;#34;Direct Debit&amp;#34;; &amp;#34;DRP 08154711 040441777 INKL.</description>
    </item>
    
    <item>
      <title>MySQL: automatic partitions surely would be nice</title>
      <link>https://blog.koehntopp.info/2020/09/25/mysql-dynamic-partitions-suck.html</link>
      <pubDate>Fri, 25 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/09/25/mysql-dynamic-partitions-suck.html</guid>
      <description>In Deleting data we have been looking at a process that loads data into MySQL, leveraging partitions to make it easier and faster to later get rid of the data again. For this, we created three processes, a data loader process, and two observers - one for creating partitions, and one for deleting them.
The observer processes have been running ANALYZE TABLES and then polling INFORMATION_SCHEMA.PARTITIONS every 1/10th of a second to check if intervention is needed.</description>
    </item>
    
    <item>
      <title>MySQL: Deleting data</title>
      <link>https://blog.koehntopp.info/2020/09/24/mysql-deleting-data.html</link>
      <pubDate>Thu, 24 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/09/24/mysql-deleting-data.html</guid>
      <description>Completing the data lifecycle is often harder than originally expected: Deleting data can cost sometimes way more than inserting it in the first place. MySQL Partitions can offer a way out. We have an earlier post on the subject.
A sample table, and a problem statement   Let&amp;rsquo;s define a kind of log table, to which data is added with an auto_increment id value and some data.
#! /usr/bin/env python3 from time import sleep from random import randint from multiprocessing import Process import click import MySQLdb import MySQLdb.</description>
    </item>
    
    <item>
      <title>MySQL: Provisioning .mylogin.cnf</title>
      <link>https://blog.koehntopp.info/2020/09/23/mylogin-cnf.html</link>
      <pubDate>Wed, 23 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/09/23/mylogin-cnf.html</guid>
      <description>MySQL uses connection and config parameters from a number of possible sources. The easiest way to find out where it is looking for config files is to run
$ mysql --help | grep cnf order of preference, my.cnf, $MYSQL_TCP_PORT, /etc/my.cnf /etc/mysql/my.cnf /Users/kkoehntopp/homebrew/etc/my.cnf ~/.my.cnf As can be seen, my version of the MySQL client checks in this order
 /etc/my.cnf /etc/mysql/my.cnf /Users/kkoehntopp/homebrew/etc/my/cnf ~/.my.cnf  The cnf file is a file in dot-ini syntax, so you have [groups] and each group contains lines with key = value pairs.</description>
    </item>
    
    <item>
      <title>MySQL: ALTER TABLE for UUID</title>
      <link>https://blog.koehntopp.info/2020/09/22/alter-table-for-uuid.html</link>
      <pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/09/22/alter-table-for-uuid.html</guid>
      <description>A question to the internal #DBA channel at work: »Is it possible to change a column type from BIGINT to VARCHAR ? Will the numbers be converted into a string version of the number or will be it a byte-wise transition that will screw the values?«
Further asking yielded more information: »The use-case is to have strings, to have UUIDs.«
So we have two questions to answer:
 Is ALTER TABLE t CHANGE COLUMN c lossy?</description>
    </item>
    
    <item>
      <title>MySQL: Encoding fields for great profit.</title>
      <link>https://blog.koehntopp.info/2020/09/18/mysql-encoding-fields-for-great-profit.html</link>
      <pubDate>Fri, 18 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/09/18/mysql-encoding-fields-for-great-profit.html</guid>
      <description>Iterating schemas over time is not an uncommon thing. Often requirements emerge only after you have data, and then directed action is possible. Consequently, working on existing data, and structuring and cleaning it up is a common task.
In todays example we work with a log table that logged state transitions of things in freeform VARCHAR fields. After some time the log table grew quite sizeable, and the log strings are repeated rather often, contributing to the overall size of the table considerably.</description>
    </item>
    
    <item>
      <title>Feeds tagged, and a MySQL feed</title>
      <link>https://blog.koehntopp.info/2020/09/09/feeds-tagged-and-a-mysql-feed.html</link>
      <pubDate>Wed, 09 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/09/09/feeds-tagged-and-a-mysql-feed.html</guid>
      <description>I have made changes to the RSS Feed of this blog:
 Each &amp;lt;item/&amp;gt; does now contain a container &amp;lt;tags/&amp;gt;, inside a sequence of &amp;lt;tag/&amp;gt; containers, with each posts tags. There is now a second RSS feed for posts tagged #mysql, because of demand. You can find it at https://blog.koehntopp.info/feed_mysql.xml .  Example for the tags:
&amp;lt;channel&amp;gt; &amp;lt;title&amp;gt;Die wunderbare Welt von Isotopp&amp;lt;/title&amp;gt; ... &amp;lt;item&amp;gt; &amp;lt;title&amp;gt;A post title&amp;lt;/title&amp;gt; &amp;lt;link&amp;gt;https://blog.koehntopp.info/2020/09/...&amp;lt;/link&amp;gt; &amp;lt;guid isPermalink=&amp;#34;false&amp;#34;&amp;gt;/2020/09/...&amp;lt;/guid&amp;gt; &amp;lt;tags&amp;gt;&amp;lt;tag&amp;gt;lang_en&amp;lt;/tag&amp;gt;&amp;lt;tag&amp;gt;mysql&amp;lt;/tag&amp;gt;&amp;lt;tag&amp;gt;database&amp;lt;/tag&amp;gt;&amp;lt;/tags&amp;gt; &amp;lt;description&amp;gt;blah blah blah&amp;lt;/description&amp;gt; &amp;lt;/item&amp;gt; &amp;lt;/channel&amp;gt; So if you want only the MySQL content, subscribe to this feed , if you want all the content, subscribe to the original feed .</description>
    </item>
    
    <item>
      <title>MySQL from a Developers Perspective</title>
      <link>https://blog.koehntopp.info/2020/09/07/mysql-from-a-developers-perspective.html</link>
      <pubDate>Mon, 07 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/09/07/mysql-from-a-developers-perspective.html</guid>
      <description>So this has turned into a small series, explaining how to work with MYSQL from a developers perspective. This post is intended as a directory for the individual articles. It will be amended and re-dated as necessary.
The code for the series is also available in isotopp/mysql-dev-examples on GitHub.
The Tag #mysqldev will reference all articles from this series.
  MySQL Transactions - the physical side . Looking at how MySQL InnoDB handles transactions on the physical media, enabling rollback and commit.</description>
    </item>
    
    <item>
      <title>MySQL: Generated Columns and virtual indexes</title>
      <link>https://blog.koehntopp.info/2020/09/07/mysql-generated-columns-and-virtual-indexes.html</link>
      <pubDate>Mon, 07 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/09/07/mysql-generated-columns-and-virtual-indexes.html</guid>
      <description>We have had a look at how MySQL 8 handles JSON recently, but with all those JSON functions and expressions it is clear that many JSON accesses cannot be fast. To grab data from a JSON column, you will use a lot of $-&amp;gt;&amp;gt;field expressions and similar, and without indexes nothing of this will be fast.
JSON cannot be indexed.
But MySQL 8 offers another feature that comes in handy: Generated columns and indexes on those.</description>
    </item>
    
    <item>
      <title>MySQL: Basic usage of the JSON data type</title>
      <link>https://blog.koehntopp.info/2020/09/04/mysql-json-data-type.html</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/09/04/mysql-json-data-type.html</guid>
      <description>MySQL 8 provides solid support for the JSON data type. The manual has an overview of the data type , a JSON function reference , an an overview on generated column indexes , and explains multi-values indexes .
Creating JSON columns   Creating JSON columns is easy: Make the column of the JSON data type, fill in valid JSON data.
mysql&amp;gt;createtablet(idintegernotnullprimarykeyauto_increment,jjson);QueryOK,0rowsaffected(0.11sec)mysql&amp;gt;insertintot(j)values-&amp;gt;(&amp;#39;null&amp;#39;),-&amp;gt;(&amp;#39;true&amp;#39;),-&amp;gt;(&amp;#39;false&amp;#39;),-&amp;gt;(&amp;#39;1&amp;#39;),-&amp;gt;(&amp;#39;&amp;#34;keks&amp;#34;&amp;#39;),-&amp;gt;(&amp;#39;[&amp;#34;eins&amp;#34;, &amp;#34;zwei&amp;#34;]&amp;#39;),-&amp;gt;(&amp;#39;{&amp;#34;eins&amp;#34;: &amp;#34;one&amp;#34;, &amp;#34;zwei&amp;#34;: &amp;#34;two&amp;#34;}&amp;#39;);QueryOK,5rowsaffected(0.02sec)mysql&amp;gt;selectjson_type(j)astype,json_valid(j)asvalid,isnull(j)assqlnull,j,idfromt;+---------+-------+---------+--------------------------------+----+ |type|valid|sqlnull|j|id|+---------+-------+---------+--------------------------------+----+ |NULL|NULL|1|NULL|1||NULL|1|0|null|2||BOOLEAN|1|0|true|3||BOOLEAN|1|0|false|4||INTEGER|1|0|1|5||STRING|1|0|&amp;#34;keks&amp;#34;|6||ARRAY|1|0|[&amp;#34;eins&amp;#34;,&amp;#34;zwei&amp;#34;]|7||OBJECT|1|0|{&amp;#34;eins&amp;#34;:&amp;#34;one&amp;#34;,&amp;#34;zwei&amp;#34;:&amp;#34;two&amp;#34;}|8|+---------+-------+---------+--------------------------------+----+ 8rowsinset(0.00sec)mysql&amp;gt;insertintot(j)values(&amp;#39;[&amp;#34;incomplete&amp;#34;, &amp;#34;array&amp;#34;, &amp;#34;closing bracket&amp;#34;&amp;#39;);ERROR3140(22032):InvalidJSONtext:&amp;#34;Missing a comma or &amp;#39;]&amp;#39; after an array element.</description>
    </item>
    
    <item>
      <title>MySQL: NULL is NULL</title>
      <link>https://blog.koehntopp.info/2020/08/25/null-is-null.html</link>
      <pubDate>Tue, 25 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/08/25/null-is-null.html</guid>
      <description>Question: Hey, I got a UNIQUE INDEX, but I can store multiple rows with the same value, NULL. That is surprising. Is that a bug?
 This is a rewrite of the same in German from 9 years ago .
 root@localhost[kris]&amp;gt;createtablet(ainteger,binteger,unique(a,b));QueryOK,0rowsaffected(0.09sec)root@localhost[kris]&amp;gt;insertintotvalues(1,2);QueryOK,1rowaffected(0.01sec)root@localhost[kris]&amp;gt;insertintotvalues(1,2);ERROR1062(23000):Duplicateentry&amp;#39;1-2&amp;#39;forkey&amp;#39;t.a&amp;#39;This does not work, as expected. But this does:
root@localhost[kris]&amp;gt;truncatetablet;QueryOK,0rowsaffected(0.16sec)root@localhost[kris]&amp;gt;insertintotvalues(1,NULL);QueryOK,1rowaffected(0.02sec)root@localhost[kris]&amp;gt;insertintotvalues(1,NULL);QueryOK,1rowaffected(0.03sec)root@localhost[kris]&amp;gt;select*fromt;+------+------+ |a|b|+------+------+ |1|NULL||1|NULL|+------+------+ 2rowsinset(0.00sec)Why is that?
This is usually where I point people at SQL for Smarties: Advanced SQL Programming .</description>
    </item>
    
    <item>
      <title>MySQL: Some Character Set Basics</title>
      <link>https://blog.koehntopp.info/2020/08/18/mysql-character-sets.html</link>
      <pubDate>Tue, 18 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/08/18/mysql-character-sets.html</guid>
      <description>This is the updated and english version of some older posts of mine in German. It is likely still incomplete, and will need information added to match current MySQL, but hopefully it is already useful.
Old source articles in German: 1 , 2 and 3 .
Some vocabulary   Symbol, Font, Encoding and Collation - what do they even mean?
A character set is a collection of symbols that belong together.</description>
    </item>
    
    <item>
      <title>MySQL Foreign Key Constraints and Locking</title>
      <link>https://blog.koehntopp.info/2020/08/04/mysql-foreign-key-constraints-and-locking.html</link>
      <pubDate>Tue, 04 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/08/04/mysql-foreign-key-constraints-and-locking.html</guid>
      <description>Since we now know how to look at the state of locking in a live database, let&amp;rsquo;s look at what happens when we run a normal insert or update and an insert or update with foreign key relationships defined, and compare.
We will be using the tables and structures from our previous examples, a simple 1:n relationship between a and b:
CREATETABLEa(a_idintNOTNULLAUTO_INCREMENT,PRIMARYKEY(a_id));INSERTINTOaVALUES(10),(20),(30),(40);CREATETABLEb(b_idintNOTNULLAUTO_INCREMENT,a_idintNOTNULL,PRIMARYKEY(b_id),KEY`a_id`(a_id),CONSTRAINTa_id_existsFOREIGNKEY(a_id)REFERENCESa(a_id)ONDELETERESTRICTONUPDATERESTRICT);INSERTINTObVALUES(10,10),(40,40);or the same definition for b without the constraint.</description>
    </item>
    
    <item>
      <title>MySQL Foreign Keys and Foreign Key Constraints</title>
      <link>https://blog.koehntopp.info/2020/08/03/mysql-foreign-keys-and-foreign-key-constraints.html</link>
      <pubDate>Mon, 03 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/08/03/mysql-foreign-keys-and-foreign-key-constraints.html</guid>
      <description>Foreign Keys are what links tables together and turns a set of tables into a model. Foreign Key Constraints are conditions that must be true for the content of the tables to be an internally consistent model. Foreign Key Constraints can be defined and enforced in InnoDB, but this comes at a considerable price, and for some it may hurt more than it is worth.
A very simple shop as a ER-model.</description>
    </item>
    
    <item>
      <title>MySQL Deadlocks with INSERT</title>
      <link>https://blog.koehntopp.info/2020/08/02/mysql-deadlocks-with-insert.html</link>
      <pubDate>Sun, 02 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/08/02/mysql-deadlocks-with-insert.html</guid>
      <description>Support Channel. &amp;ldquo;Hi, I am getting deadlocks in the database and they occur when I have to rollback the transactions but if we don&amp;rsquo;t have to roll back all transactions get executed.&amp;rdquo; Wait, what? After some back and forth it becomes clear that the Dev experiences deadlocks and has data:
mysql&amp;gt;pagerlessmysql&amp;gt;showengineinnodbstatus\G...MySQLthreadid142531,OSthreadhandle139990258222848,queryid4799571somehost.somedomainsomeuserupdateINSERTintosometable(identifier_id,currency,balance)VALUES(&amp;#39;d4e84cb1-4d56-4d67-9d16-1d548fd26b55&amp;#39;,&amp;#39;EUR&amp;#39;,&amp;#39;0&amp;#39;)***(2)HOLDSTHELOCK(S):RECORDLOCKSspaceid3523pageno1106463nbits224indexPRIMARYoftable`somedb`.`sometable`trxid9843342279lockmodeSlocksgapbeforerecand that is weird because of the lock mode S locks gap in the last line. We get the exact same statement with the exact same value on the second thread, but with lock mode X locks gap.</description>
    </item>
    
    <item>
      <title>MySQL: Locks and Deadlocks</title>
      <link>https://blog.koehntopp.info/2020/08/01/mysql-locks-and-deadlocks.html</link>
      <pubDate>Sat, 01 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/08/01/mysql-locks-and-deadlocks.html</guid>
      <description>In a previous article we wrote data to the database using atomic update statements, and then using transactions with SELECT ... FOR UPDATE. In this article we will look at what happens when we continue doing this, in a more complicated way. Source code for this article is also available on github.com .
A simple row lock   But first let&amp;rsquo;s do things manually: We create a table kris with an integer primary key column and a secondary unindexed data column.</description>
    </item>
    
    <item>
      <title>MySQL Transactions - writing data</title>
      <link>https://blog.koehntopp.info/2020/07/30/mysql-transactions-writing-data.html</link>
      <pubDate>Thu, 30 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/07/30/mysql-transactions-writing-data.html</guid>
      <description>Using the framework for testing we created in earlier articles, let&amp;rsquo;s try to modify some data. We are writing a small program that increments a counter. Our table looks like this, and contains 10 counters:
CREATETABLE`demo`(`id`bigintunsignedNOTNULLAUTO_INCREMENT,`counter`intNOTNULLDEFAULT&amp;#39;0&amp;#39;,UNIQUEKEY`id`(`id`))INSERTINTO`demo`VALUES(1,0);INSERTINTO`demo`VALUES(2,0);...INSERTINTO`demo`VALUES(10,0);We are using some very simple programming to increment a counter:
@sql.command() @click.option(&amp;#34;--name&amp;#34;, default=&amp;#34;demo&amp;#34;, help=&amp;#34;Table name to count in&amp;#34;) @click.option(&amp;#34;--id&amp;#34;, default=0, help=&amp;#34;Counter to use&amp;#34;) @click.option(&amp;#34;--count&amp;#34;, default=1000, help=&amp;#34;Number of increments&amp;#34;) def count(name, id, count): &amp;#34;&amp;#34;&amp;#34; Increment counter --id by --count many steps in table --name &amp;#34;&amp;#34;&amp;#34; for i in range(0, count): cmd = f&amp;#34;update {name}set counter=counter+1 where id = {id}&amp;#34; c = db.</description>
    </item>
    
    <item>
      <title>MySQL Transactions - the logical side</title>
      <link>https://blog.koehntopp.info/2020/07/29/mysql-transactions-the-logical-view.html</link>
      <pubDate>Wed, 29 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/07/29/mysql-transactions-the-logical-view.html</guid>
      <description>After having a look how MySQL handles transactions physically , let&amp;rsquo;s have a look at what is going on from a logical point of view.
We are using a test table called demo with an id and a counter field, both integer. In it we have 10 counters, all set to 0.
CREATETABLE`demo`(`id`bigintunsignedNOTNULLAUTO_INCREMENT,`counter`intNOTNULLDEFAULT&amp;#39;0&amp;#39;,UNIQUEKEY`id`(`id`))INSERTINTO`demo`VALUES(1,0);INSERTINTO`demo`VALUES(2,0);...INSERTINTO`demo`VALUES(10,0);In one session, we start a transaction and modify a counter value. We do not commit anything.
Session1&amp;gt;starttransactionreadwrite;Session1&amp;gt;updatedemosetcounter=10whereid=3;Isolation   In a second session, we check the data and notice a few things:</description>
    </item>
    
    <item>
      <title>MySQL Connection Scoped State</title>
      <link>https://blog.koehntopp.info/2020/07/28/mysql-connection-scoped-state.html</link>
      <pubDate>Tue, 28 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/07/28/mysql-connection-scoped-state.html</guid>
      <description>MySQL speaks its own proprietary protocol. It cannot be routed by a HTTP proxy, and a MySQL connection is entire unlike a HTTP connection. Specifically, a lot of state and configuration is tied to a MySQL connection, and it cannot be recovered on disconnect.
What state is tied to a connection?   Transactions   A disconnect implies a ROLLBACK. So if you are in a transaction, all changes to the database that you attempted are lost, rolled back, as if they never happened.</description>
    </item>
    
    <item>
      <title>MySQL Commit Size and Speed</title>
      <link>https://blog.koehntopp.info/2020/07/27/mysql-commit-size-and-speed.html</link>
      <pubDate>Mon, 27 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/07/27/mysql-commit-size-and-speed.html</guid>
      <description>When writing data to disk, for small transactions the cost of writing the commit out do disk dominates the execution time of the script. In order to show that, I wrote a little bit of Python.
The script creates a test table in a database and writes 10.000 rows of test data into it, in commit sizes of 1, 2, 4, &amp;hellip;, 1024 rows.
$ ./mysql.py --help Usage: mysql.py [OPTIONS] COMMAND [ARGS].</description>
    </item>
    
    <item>
      <title>MySQL Transactions - the physical side</title>
      <link>https://blog.koehntopp.info/2020/07/27/mysql-transactions.html</link>
      <pubDate>Mon, 27 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/07/27/mysql-transactions.html</guid>
      <description>So you talk to a database, doing transactions. What happens actually, behind the scenes? Let’s have a look.
There is a test table and we write data into it inside a transaction:
CREATETABLEt(idserial,datavarbinary(255))STARTTRANSACTIONREADWRITEINSERTINTOt(id,data)VALUES(NULL,RANDOM_BYTES(255))COMMITThe MySQL test instance we are talking to is running on a Linux machine, and otherwise idle to make observation easier. Also, we configured it with innodb_use_native_aio = false because observing actual physical asynchronous I/O and attributing it to the statement that caused it is really hard.</description>
    </item>
    
    <item>
      <title>MySQL Window Functions</title>
      <link>https://blog.koehntopp.info/2020/06/21/mysql-window-functions.html</link>
      <pubDate>Sun, 21 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/06/21/mysql-window-functions.html</guid>
      <description>Two questions from Reddit&amp;rsquo;s /r/mysql related to Window Functions: How do I make row.numbers happen and Get the difference between two values in different recordings .
One of the new things in MySQL is the implementation of Window Functions. They are related to aggregates, but do not actually lump values together.
To better understand what goes on, let&amp;rsquo;s create some fake data to work with:
#! /usr/bin/env python3 # -*- coding: utf-8 -*- import MySQLdb as mdb import MySQLdb.</description>
    </item>
    
    <item>
      <title>Export the entire database to CSV</title>
      <link>https://blog.koehntopp.info/2020/06/20/export-the-entire-database-to-csv.html</link>
      <pubDate>Sat, 20 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/06/20/export-the-entire-database-to-csv.html</guid>
      <description>A question from Reddit&amp;rsquo;s /r/mysql:
 Really new to MySQL and had a request to export an entire database to csv for review. I can manually export each table using workbench but there are 10+ tables and 10+ databases so I was looking to export the entire database to csv.
 It is likely that you have additional requirements on top of this, so it would be best to script this in a way that would allow for customization.</description>
    </item>
    
    <item>
      <title>Optimistic locking</title>
      <link>https://blog.koehntopp.info/2020/06/04/optimistic-locking.html</link>
      <pubDate>Thu, 04 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/06/04/optimistic-locking.html</guid>
      <description>A question from Reddit&amp;rsquo;s /r/mysql:
 Hey, I was planning to make a dashboard, where Users are subjected to make edits on their profiles every now and then, and I expect a high volume of requests to the database.
Having worked previously with MySQL for another Dashboard, I encountered errors for:
  Maximum user connections - when I connected to the database only while query was to be executed</description>
    </item>
    
    <item>
      <title>MySQL store_result and use_result</title>
      <link>https://blog.koehntopp.info/2020/06/01/mysql-storeresult-and-useresult.html</link>
      <pubDate>Mon, 01 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/06/01/mysql-storeresult-and-useresult.html</guid>
      <description>A question from Reddit’s /r/mysql led to a longer discussion of cursors and how they are implemented in MySQL, and what the advantages and drawbacks are.
The OP probably had a slow query, but was misphrasing the question:
 I am having performance problems where my cursor is taking 6-8 seconds to go through a hundred rows. I think this is because I am also using while loops to loop through JSON objects to pull information.</description>
    </item>
    
    <item>
      <title>Deleting data from MySQL</title>
      <link>https://blog.koehntopp.info/2020/05/13/deleting-data-from-mysql.html</link>
      <pubDate>Wed, 13 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/05/13/deleting-data-from-mysql.html</guid>
      <description>I have been pointed at the following question: »Has anyone ever used mySQL events to auto-delete rows from a table after set period? Wondering your experience of doing this.«
 There are two ends to this question:
 expiring data from a MySQL table doing this with the event scheduler  Mass-deleting data from InnoDB   You can of course delete data from a table using the SQL DELETE statement with an arbitrary WHERE-clause at any time:</description>
    </item>
    
    <item>
      <title>The lack of developer centric MySQL monitoring - a rant</title>
      <link>https://blog.koehntopp.info/2020/03/18/the-lack-of-developer-centric-mysql-monitoring.html</link>
      <pubDate>Wed, 18 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/03/18/the-lack-of-developer-centric-mysql-monitoring.html</guid>
      <description>So where I work we have a large number of MySQL instances. They are organized in a slightly smaller number of replication hierarchies, which tend to cross region boundaries.
Structure of a large database setup   A rough sketch of the setup we have. Variants of this exist in various sizes - from 6 replicas in 3 regions to hundreds of replicas per region, with Group Replication at the top and per Region Intermedia Master.</description>
    </item>
    
    <item>
      <title>Some rules for primary keys</title>
      <link>https://blog.koehntopp.info/2020/01/28/some-rules-for-primary-keys.html</link>
      <pubDate>Tue, 28 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/01/28/some-rules-for-primary-keys.html</guid>
      <description>On Twitter, @CaptainEyesight asked a question:
 »Database architecture question: For deleting records, instead of a DELETE, UPDATE the id to the negative (i.e. 1 becomes -1) and then add AND id &amp;gt; 0 to every query. Great idea? or Greatest idea?«
I was honestly a bit confused, because this idea is so weird that I took this question for a joke. But then I decided that this is a case for XKCD 1053 : »You are one of today&amp;rsquo;s lucky 10.</description>
    </item>
    
    <item>
      <title>A blast from the past</title>
      <link>https://blog.koehntopp.info/2019/11/18/a-blast-from-the-past.html</link>
      <pubDate>Mon, 18 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2019/11/18/a-blast-from-the-past.html</guid>
      <description>TL:DR: If you have long running transactions, MySQL does not deal well with this, and it will slow down the box. That&amp;rsquo;s okay as long as you are basically alone on your box, but if you aren&amp;rsquo;t, the others will hate you.
The database machine &amp;lsquo;somehierarchy-02&amp;rsquo; in a general purpose load balancer pool for somehierarchy had replication delay.
It&amp;rsquo;s a MySQL replica and is receiving the same write workload than all the other boxen in that pool.</description>
    </item>
    
    <item>
      <title>MySQL Does Disk I/O</title>
      <link>https://blog.koehntopp.info/2019/09/27/mysql-does-disk-io.html</link>
      <pubDate>Fri, 27 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2019/09/27/mysql-does-disk-io.html</guid>
      <description>We had a discussion at work about MySQL doing Disk I/O to a NVME disk, and if it is valid to turn off the doublewrite buffer when using XFS.
TL;DR: It&amp;rsquo;s not, you can turn off the doublewrite buffer only on filesystems that never do in-place updates (ZFS, btrfs), or that have their own doublewrite buffer (ext4 with journal=data). A flash layer underneath the actual filesystem is likely not going to help you without additional measures.</description>
    </item>
    
    <item>
      <title>MySQL Performance Limits</title>
      <link>https://blog.koehntopp.info/2019/09/06/mysql-performance-limits.html</link>
      <pubDate>Fri, 06 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2019/09/06/mysql-performance-limits.html</guid>
      <description>The last time I saw a MySQL server operating at a performance limit was in 2012. Back them we had a production master on (then) current hardware, running stable at about 21000 QPS. At 24000 QPS it tended to become unstable and fall over, dying in global locks on the InnoDB Adaptive Hash Index or other global locks.
I need to better understand how MySQL works today, and what the limits are on a box that is considered large in 2019.</description>
    </item>
    
    <item>
      <title>Using MySQL Partitions (a Python example)</title>
      <link>https://blog.koehntopp.info/2017/07/09/using-mysql-partitions-a-python-example.html</link>
      <pubDate>Sun, 09 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2017/07/09/using-mysql-partitions-a-python-example.html</guid>
      <description>Today somebody had a problem with expiring a large table (a Serendipity Blog table).
In MySQL InnoDB, tables are physically ordered by primary key (InnoDB data is a B+ tree, a balanced tree where the data pages are the leaves of the tree). If you are expiring old data from such a log table, you are deleting from the left hand side of the tree, and since it is a balanced tree, that triggers a lot of rebalancing - hence it is very slow.</description>
    </item>
    
    <item>
      <title>Good Riddance to the Query Cache</title>
      <link>https://blog.koehntopp.info/2017/05/31/good-riddance-to-the-query-cache.html</link>
      <pubDate>Wed, 31 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2017/05/31/good-riddance-to-the-query-cache.html</guid>
      <description>MySQL 8.0 will be retiring support for the Query Cache . The MySQL Query cache is a result cache: The MySQL server will record all result sets that are small enough to keep in the cache, and a hash of the query that produced it.
If a query meets certain requirements, and the hash of the same query string is ever seen again, the query will not be actually parsed and executed, but the same result set will be replayed.</description>
    </item>
    
    <item>
      <title>Post like it is 2015</title>
      <link>https://blog.koehntopp.info/2017/02/14/post-like-its-2015.html</link>
      <pubDate>Tue, 14 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2017/02/14/post-like-its-2015.html</guid>
      <description>Following a great idea from their friends at GitLab, Soup.io loses all postings since 2015 because of malfunctioning backups. They write :
 We had a big database crash, and the backups we had were corrupted. The only working backup was from 2015.
 Also, TIL soup.io still exists.
Meanwhile, Gitlab posted a blameless postmortem . You can read it online , and they write:
 Improving Recovery Procedures […] 9.</description>
    </item>
    
    <item>
      <title>PHP 7: mysql extension deprecated</title>
      <link>https://blog.koehntopp.info/2017/01/23/php-7-mysql-extension-deprecated.html</link>
      <pubDate>Mon, 23 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2017/01/23/php-7-mysql-extension-deprecated.html</guid>
      <description>In mysql() nach PHP 7 retten , Charly Kühnast explains how you can get the deprecated and disabled mysql extension back in PHP 7. You shouldn&amp;rsquo;t. There are many reasons for this.
One of them being that none of the newer features in MySQL can be used with the old mysql extensions. There is an overview in the PHP documentation that explains exactly what you are missing.
One of the things that you are missing is support for prepared statements.</description>
    </item>
    
    <item>
      <title>Dude, where is my memory?</title>
      <link>https://blog.koehntopp.info/2012/11/12/dude-where-is-my-memory.html</link>
      <pubDate>Mon, 12 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2012/11/12/dude-where-is-my-memory.html</guid>
      <description>&amp;ldquo;Kris, bitte schau Dir mal unsere Datenbank an. Wir haben hier einen Generator für unsere Materialized Views, und auf einer Datenbank von 6 GB Größe werden 40 GB Speicher gefüllt und wir kommen sogar ins Swappen.&amp;rdquo;
Na, das ist mal interessant. The fragliche Kiste hat 48 GB RAM, und in der Tat kaum 6 GB Daten.
mysql&amp;gt;select-&amp;gt;sum(data_length+index_length)/1024/1024/1024asgb-&amp;gt;fromtables-&amp;gt;wheretable_schemanotin(&amp;#39;information_schema&amp;#39;,&amp;#39;performance_schema&amp;#39;,&amp;#39;mysql&amp;#39;);+----------------+ |gb|+----------------+ |5.832778930664|+----------------+ 1rowinset(0.00sec)Aber in &amp;ldquo;top&amp;rdquo; sieht das so aus, und wächst:
7552 mysql 15 0 55.</description>
    </item>
    
    <item>
      <title>Enemy Action</title>
      <link>https://blog.koehntopp.info/2012/10/31/enemy-action.html</link>
      <pubDate>Wed, 31 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2012/10/31/enemy-action.html</guid>
      <description>&amp;ldquo;Kris, guck mal, connection surge auf $WICHTIGER_MASTER, davor kurzer Activity drop. Alle anderen Graphen sehen normal aus.&amp;rdquo;
![Graph: Connection Surge]({{ site.baseurl }}/uploads/screenshot-kris-20121031-1.png)
und
![Graph: QPS Drop]({{ site.baseurl }}/uploads/screenshot-kris-20121031-2.png)
Ich gucke.
Alle anderen Graphen sehen in der Tat normal aus. Aber um 13:20 kommt für kurze Zeit alles Processing zum Stillstand.
Wir haben ja log_processlist.pl. Falls es sich also um irgendein wildgewordenes Lock handeln sollte, würde ich das also in den 13_20 und 13_21 Dateien sehen.</description>
    </item>
    
    <item>
      <title>.mylogin.cnf Passworte wiederherstellen</title>
      <link>https://blog.koehntopp.info/2012/10/03/mylogin-cnf-passworte-wiederherstellen.html</link>
      <pubDate>Wed, 03 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2012/10/03/mylogin-cnf-passworte-wiederherstellen.html</guid>
      <description>Wie Todd Farmer in Understanding mysql_config_editor’s security aspects richtig beobachtet, speichert die neue .mylogin.cnf, die von mysql_config_editor erzeugt wird, Paßworte nicht sicher ab. Sie verschleiert sie nur.
Das Format der Datei ist wie folgt (am Beispiel von MySQL 5.6.7-RC):
 4 Bytes Zero (Version Information) 20 Bytes Key Generation Matter Wiederholend:  4 Bytes Länge Länge Bytes Ciphertext. Die Verschlüsselung erfolgt mit AES Encrypt , und diese Funktion ist selbst auch nicht sicher: Es handelt sich um einen aes-128-ecb mit einem NULL IV.</description>
    </item>
    
    <item>
      <title>MySQL 5.6.7-RC: GTID vs. MyISAM</title>
      <link>https://blog.koehntopp.info/2012/10/02/mysql-5-6-7-rc-gtid-vs-myisam.html</link>
      <pubDate>Tue, 02 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2012/10/02/mysql-5-6-7-rc-gtid-vs-myisam.html</guid>
      <description>So we tested the 5.6.7-RC. And ran into a strange problem:
Because of a test, a preexisting configuration with GTID enabled existed, and suddenly we did not have properly initialized grants in mysql.* created for a new installation. Turns out: GTID and non-transactional tables are no friends, and that is even documented .
 When using GTIDs, updates to tables using nontransactional storage engines such as MyISAM are not supported. This is because updates to such tables mixed with updates to tables that use a transactional storage engine such as InnoDB can result in multiple GTIDs being assigned to the same transaction.</description>
    </item>
    
    <item>
      <title>MySQL Replication Load Monitor</title>
      <link>https://blog.koehntopp.info/2012/09/28/mysql-replication-load-monitor.html</link>
      <pubDate>Fri, 28 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2012/09/28/mysql-replication-load-monitor.html</guid>
      <description>Mein Kollege Dennis Kaarsemaker hat jetzt einen Artikel zu dem Replication Load Monitor von Booking.com gebloggt. Der Monitor basiert auf Arbeiten von Mark Leith .
Möge er Euch allen nützen.</description>
    </item>
    
    <item>
      <title>House und Heisenberg revisited</title>
      <link>https://blog.koehntopp.info/2012/09/25/house-und-heisenberg-revisited.html</link>
      <pubDate>Tue, 25 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2012/09/25/house-und-heisenberg-revisited.html</guid>
      <description>Ich habe heute an dem Problem weiter geforscht und wir haben etabliert, dass die Ursache nicht der Quelltext des betreffenden Diamond-Collectors sein kann.
Auf allen betroffenen Kisten habe ich dann gesehen, daß die entsprechenden Queries gegen Performance-Schema ein
mysql&amp;gt;select\*fromperformance_schema.threads;Emptyset(0.01sec)zurück liefern.
Weitere Untersuchung stellt heraus: P_S ist aber an. Jedoch:
mysql&amp;gt;select\*fromperformance_schema.setup_instruments;Emptyset(0.03sec)mysql&amp;gt;select\*fromperformance_schema.setup_timers;Emptyset(0.01sec)mysql&amp;gt;select\*fromperformance_schema.setup_consumers;Emptyset(0.02sec)und das bleibt auch so, sogar über Server-Restarts hinweg. Warum ist das so?
# cd /mysql/\*/data/performance_schema/ # ls -l total 1840 -rw-rw---- 1 mysql mysql 8624 Oct 6 2011 cond_instances.</description>
    </item>
    
    <item>
      <title>Der Herr House und der Herr Heisenberg haben Replication Delay</title>
      <link>https://blog.koehntopp.info/2012/09/24/der-herr-house-und-der-herr-heisenberg-haben-replication-delay.html</link>
      <pubDate>Mon, 24 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2012/09/24/der-herr-house-und-der-herr-heisenberg-haben-replication-delay.html</guid>
      <description>Heute erreicht mich eine Mail, in der ein DBA sich über steigende Replication Delay in einer bestimmten Replikationshierarchie beschwert.
Das ist schlecht, denn die betreffende Hierarchie ist wichtig. Also die &amp;lsquo;Wenn die nicht geht schlafen Leute unter Brücken&amp;rsquo;-Art von wichtig.
Die Theorie war, daß die Änderungsrate in dieser Hierarchie so hoch ist, daß die Schreiblast von MySQL Replikation, die ja Single Threaded ist, nicht mehr bewältigt werden kann. Für diese Theorie sprach nach dem ersten Augenschein, daß alle betroffenen Kisten keine lokalen Platten hatten, sondern auf einem Filer lagen, und Filer sterben wegen der hohen Kommunikationslatenz im SAN bei uns in der Regel weit vor lokalen Platten, wenn es um Replikation geht: Filer sind mehr so beim parallelen Schreiben mit mehreren Threads gut.</description>
    </item>
    
    <item>
      <title>Zu Besuch bei Redis</title>
      <link>https://blog.koehntopp.info/2012/09/23/zu-besuch-bei-redis.html</link>
      <pubDate>Sun, 23 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2012/09/23/zu-besuch-bei-redis.html</guid>
      <description>&lt;p&gt;Hier ist eine wichtige Zahl: Ein Coredump von einem MySQL auf einer Maschine
mit knapp unter 200G Speicher dauert 15 Minuten.  Auf SSD.  Auf eine
Festplatte dauert der gleiche Coredump dann knapp über 30 Minuten.&lt;/p&gt;
&lt;p&gt;Warum ist das eine wichtige Zahl?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Load, Load Testing und Benchmarks</title>
      <link>https://blog.koehntopp.info/2012/08/28/load-load-testing-und-benchmarks.html</link>
      <pubDate>Tue, 28 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2012/08/28/load-load-testing-und-benchmarks.html</guid>
      <description>(Diesen Artikel gibt es auch in englischer Sprache .)
So. Du willst also wissen, was genau die Leistungsgrenzen Deines Systems sind. Und dazu möchtest Du einen Lasttest fahren, um Ergebnisse zu ermitteln.
Die Grundidee Deines Plans sieht so aus:
Du nimmt Deine Kiste und findest eine Methode, um Last zu generieren. Dann wirst Du schon merken, wie weit das geht und wann die Kiste ausgelastet ist.
Der erste Fehler: Den Lastgenerator auf der zu testenden Kiste laufen lassen.</description>
    </item>
    
    <item>
      <title>MySQL vs. Gigabit Network</title>
      <link>https://blog.koehntopp.info/2012/08/22/mysql-vs-gigabit-network.html</link>
      <pubDate>Wed, 22 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2012/08/22/mysql-vs-gigabit-network.html</guid>
      <description>Wir generieren eine neue Art von Materialized View mit dem bekannten Generator-Setup:
Das neue Setup unterscheidet sich in der Logik von denen, die wir bisher verwendet haben, und so kommt es beim Testlauf zu einem ungewöhnlichen und unerwarteten Ereignis:
Um 14:30: Ein Gigabit-Netzwerk mit 125 MB/sec ausgelastet.
Bei einem Probelauf gehen die Alarme los, weil der Gigabit-Netzwerkstrang zur Datenbank mit 125 MB/sec (Ein Gigabit/sec) vollständig ausgelastet ist. Wie man sehen kann, ist die Datenbank zu diesem Zeitpunkt nicht besonders beschäftigt:</description>
    </item>
    
    <item>
      <title>MySQL hakt...</title>
      <link>https://blog.koehntopp.info/2012/08/21/mysql-hakt.html</link>
      <pubDate>Tue, 21 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2012/08/21/mysql-hakt.html</guid>
      <description>&amp;ldquo;Hey, Kris! Wir haben zwischen 16:20 und 17:20 CEST einen Lasttest durchgeführt und kurz vor 17:00 Uhr einen unerklärlichen Spike und einen Leistungsabfall festgestellt. Kannst Du mal gucken?&amp;rdquo;
Klar kann ich. Wo ich arbeite machen wir etwas, das wir Testing in Production nennen.
Für Lasttests bedeutet das, daß wir einzelne Systeme im Loadbalancer so lange relativ höher gewichten bis sie Probleme bekommen und umfallen. Zur Kontrolle legen wir mit Apache Siege eine Reihe von Sensor-Requests in das zu testende System, nicht zur Lastgenerierung, sondern um zu sehen, wann die Latenz nach oben geht, also um Sättigung des zu testenden Systems zu bemerken bevor es Fehler zu generieren beginnt.</description>
    </item>
    
    <item>
      <title>MySQL Testcases</title>
      <link>https://blog.koehntopp.info/2012/08/20/mysql-testcases.html</link>
      <pubDate>Mon, 20 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2012/08/20/mysql-testcases.html</guid>
      <description>In Entwickler kritisieren Oracles Umgang mit MySQL berichtet Heise über die Entdeckung von Sergei, daß Oracle zu einigen Bugs keine Tests mehr ins Open Source Repository von MySQL stellt.
Damit man die Vorgänge ein bischen besser versteht, muß man den Hintergrund ein wenig erläutern: Die meiste Open Source Software, die Datenbanken benutzt, verwendet MySQL als primäre Datenbanken. Der Support für Varianten von MySQL, PostgreSQL oder gar kommerzielle Datenbanken ist in der Regel schlecht bis nicht vorhanden.</description>
    </item>
    
    <item>
      <title>Materialized View</title>
      <link>https://blog.koehntopp.info/2012/08/15/materialized-view.html</link>
      <pubDate>Wed, 15 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2012/08/15/materialized-view.html</guid>
      <description>Daten in einer SQL-Datenbank werden in einer Tabelle abgelegt, also einer Struktur mit Spalten, die Namen und in vielen Fällen auch einen Datentyp haben. Eine Tabelle besteht dann aus 0 oder mehr Zeilen, die in dieses Spaltenschema passen.
Für das Schreiben von Daten möchte man diese dann Normalform bringen, um Anomalien bei Änderungen von Daten zu verhindern und um die Datenmenge kompakt zu halten. Kompakte Daten haben den Vorteil, daß sie von der Datenbank ganz oder in wesentlichen Teilen im Speicher gehalten werden können, sodaß lediglich tatsächliche Schreibzugriffe irgendwann die Platte treffen.</description>
    </item>
    
    <item>
      <title>Logging</title>
      <link>https://blog.koehntopp.info/2012/05/28/logging.html</link>
      <pubDate>Mon, 28 May 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2012/05/28/logging.html</guid>
      <description>&amp;ldquo;Kris&amp;rdquo;, fragt man mich, &amp;ldquo;Kris, gibt es außer &amp;lsquo;Volltextsuche&amp;rsquo; noch andere Gründe, für neue Anwendungen noch MyISAM zu verwenden? Im konkreten Fall geht es um eine verhältnismäßig einfache Datenstruktur, in die nur streng sequenziell geschrieben wird, nie gelöscht wird und viel und kreativ gelesen wird.&amp;rdquo; Na, das ist doch mal ein weites Feld.
Teile davon habe ich in Ein paar Gedanken zu Zeitreihendaten und Wie man einen Graph plottet ja schon beackert.</description>
    </item>
    
    <item>
      <title>Grundsätze verteilter Datenbanken</title>
      <link>https://blog.koehntopp.info/2012/03/15/grunds-tze-verteilter-datenbanken.html</link>
      <pubDate>Thu, 15 Mar 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2012/03/15/grunds-tze-verteilter-datenbanken.html</guid>
      <description>Wonka&amp;gt; Die Toppoint z.B. wird vermutlich nie was haben, was in nennenswerte Last-Regionen kommt, aber ich will - akademisches Interesse und so - schon wissen, wie man das da am besten täte. Was mich auch für die Toppoint interessiert: irgendeine Sorte Redundant Array of Inexpensive Databases :)
Lalufu&amp;gt; MySQL mit Replication? Alternativ mit DRBD?
Isotopp&amp;gt; Mit DRBD. Nicht mit Replikation.
Wonka&amp;gt; Lalufu: Hm, Master-Master-Replication geht ja nur mit Zweien. Wenn man nun mehr als das haben will, kann man zwar Ringe bauen, aber nur einfach verkettete.</description>
    </item>
    
    <item>
      <title>Wie man einen Graph plottet</title>
      <link>https://blog.koehntopp.info/2012/03/12/wie-man-einen-graph-plottet.html</link>
      <pubDate>Mon, 12 Mar 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2012/03/12/wie-man-einen-graph-plottet.html</guid>
      <description>Ein total kaputtes Stück Graph.
Das da ist das, was ich bekomme, wenn ich mir eine Woche Daten in dem Datenbank-Monitoringprodukt meiner Wahl anschaue. Aber das spielt keine Rolle. Ich kann mir so ziemlich jeden Zeitreihengraphen anschauen, aus so ungefähr jedem Stück Software, das mir zur Installation zur Verfügung steht, und falls es nicht rrdtools ist, ist es genau so kaputt.
Das ist bemerkenswert, weil der Plot wahrscheinlich von einem Rudel Diplom- oder Master-Abgänger gebaut worden ist.</description>
    </item>
    
    <item>
      <title>FAQ: Mein mysqldump zerstört meine Umlaute</title>
      <link>https://blog.koehntopp.info/2012/02/10/faq-mein-mysqldump-zerstoert-meine-umlaute.html</link>
      <pubDate>Fri, 10 Feb 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2012/02/10/faq-mein-mysqldump-zerstoert-meine-umlaute.html</guid>
      <description>In den letzten Tagen habe ich das mehrmals erklären müssen, daher jetzt einmal im Blog, damit ich das verlinken kann. Dieser Artikel ist, anders als der Rest des Blogs, CC-BY-SA .
Der Fragesteller:
 Ich habe Daten in meiner Datenbank, die ich erfolgreich mit meiner Anwendung einlesen und wieder auslesen kann. Wenn ich jedoch einen mysqldump mache, um die Daten auf ein neues System zu portieren, bekomme ich zerstörte Umlaute.</description>
    </item>
    
    <item>
      <title>NULL is NULL</title>
      <link>https://blog.koehntopp.info/2011/11/04/null-is-null.html</link>
      <pubDate>Fri, 04 Nov 2011 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2011/11/04/null-is-null.html</guid>
      <description>Q&amp;gt; Sag mal, NULL zählt nicht bei einem UNIQUE INDEX? Zum Beispiel ein UNIQUE INDEX auf (a,b) und dann
ab1212Das geht nicht, da Duplikate Key. Aber
ab1NULL1NULLwird zugelassen.
Kris&amp;gt; Du kaufst bitte mal SQL für Smarties: Advanced SQL Programming und ißt das dann auf.
mysql&amp;gt;select*fromt;+----+------+ |id|d|+----+------+ |1|NULL||2|2||3|3||4|NULL|+----+------+ 4rowsinset(0.00sec)mysql&amp;gt;selectcount(*)asa,count(d)asb,count(coalesce(d,0))ascfromt;+---+---+---+ |a|b|c|+---+---+---+ |4|2|4|+---+---+---+ 1rowinset(0.00sec)mysql&amp;gt;selectd,coalesce(d,0)asdcfromt;+------+------+ |d|dc|+------+------+ |NULL|0||2|2||3|3||NULL|0|+------+------+ 4rowsinset(0.00sec)Kris&amp;gt; Und außerdem
mysql&amp;gt;select0=0,1=1,0=1,NULL=0,NULL=1,NULL=NULL;+-----+-----+-----+--------+--------+-----------+ |0=0|1=1|0=1|NULL=0|NULL=1|NULL=NULL|+-----+-----+-----+--------+--------+-----------+ |1|1|0|NULL|NULL|NULL|+-----+-----+-----+--------+--------+-----------+ 1rowinset(0.00sec)Q&amp;gt; Ah, es liegt also daran, daß NULL kein Wert ist, sondern einfach NICHTS.</description>
    </item>
    
    <item>
      <title>Checkpoint Blues</title>
      <link>https://blog.koehntopp.info/2011/09/19/checkpoint-blues.html</link>
      <pubDate>Mon, 19 Sep 2011 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2011/09/19/checkpoint-blues.html</guid>
      <description>Wer dies und dies gelesen hat, versteht mehr.
InnoDB ist eine Storage Engine, die mit Hilfe von MVCC Transaktionen implementiert. Transaktionen zu implementieren bedeutet, daß man in der Lage ist, mehrere Änderungen zusammenzufassen und als eine Einheit als gültig zu markieren oder zurück zu nehmen. Damit das Ganze trotzdem schnell ist, muß man ein wenig herumtricksen.
Angenommen, wir wollen eine Spalte in einer Zeile in der Tabelle t ändern:
UPDATEtSETx=17WHEREid=3Dann muß InnoDB das zunächst einmal in eine Zeilennummer in einer Speicherseite übersetzen: InnoDB speichert Daten in Seiten von 16 KB (Defaultgröße) ab, und macht allen I/O in Richtung Tablespace immer nur in ganzen Seiten.</description>
    </item>
    
    <item>
      <title>Neue Releases im Datenbankland</title>
      <link>https://blog.koehntopp.info/2011/09/13/neue-releases-im-datenbankland.html</link>
      <pubDate>Tue, 13 Sep 2011 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2011/09/13/neue-releases-im-datenbankland.html</guid>
      <description>MongoDB 2.0 ist draußen, und implementiert eine Reihe interessanter neuer Dinge, die ich anderswo gerne hätte, insbesondere im Bereich Replica Sets .
Postgres hat das Release 9.1 draußen. Die versprochene synchrone Replikation ist jetzt verfügbar, sie ist grob vergleichbar mit der Semisynchronen Replikation in MySQL 5.5. Ein wesentlicher Unterschied ist, daß man bei Postgres einzelne, bestimmte Server als synchrone Slaves benennen kann, während MySQL nur garantiert, daß es mindestens einen (wechselnden) Slave gibt, der synchron repliziert hat.</description>
    </item>
    
    <item>
      <title>Namensregeln für Schemadesign</title>
      <link>https://blog.koehntopp.info/2011/05/20/namensregeln-f-r-schemadesign.html</link>
      <pubDate>Fri, 20 May 2011 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2011/05/20/namensregeln-f-r-schemadesign.html</guid>
      <description>Ein Freund fragte mich nach Konventionen für die Benennung von Tabellen bei der Entwicklung von Schemata für MySQL Datenbanken. Es begann damit, daß er mich fragte, wie man denn wohl eine Relation benennen soll, also eine Hilfstabelle, die zwei Tabellen in einer n:m-Beziehung miteinander verbindet.
In einem alten Job hatten wir die unten stehenden Regeln. Sie sind recht willkürlich und man kann sich anders entscheiden, aber wir hatten das so gemacht und es hat gut für uns funktioniert.</description>
    </item>
    
    <item>
      <title>MySQL Undo Log</title>
      <link>https://blog.koehntopp.info/2011/04/28/mysql-undo-log.html</link>
      <pubDate>Thu, 28 Apr 2011 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2011/04/28/mysql-undo-log.html</guid>
      <description>&amp;ldquo;Kris, kannst Du bitte mal gucken?&amp;rdquo;
Seit heute morgen, 10:00 Uhr, wächst das Undo Log immer weiter an.
Immer wenn InnoDB Daten schreibt wird die alte Version einer Zeile aus der Tabelle in das Undo-Log verschoben, also physikalisch von der ibd-Datei der Tabelle in die ibdata1 im Datadir von MySQL. In der Tabelle wird in der veränderten Zeile ein Zeiger von der neuen Version auf die alte Version der Zeile im Undo-Log installiert, der Roll(back)-Pointer.</description>
    </item>
    
    <item>
      <title>Zusammenfassung &#39;Schemaless&#39;</title>
      <link>https://blog.koehntopp.info/2011/04/20/zusammenfassung-schemaless.html</link>
      <pubDate>Wed, 20 Apr 2011 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2011/04/20/zusammenfassung-schemaless.html</guid>
      <description>Die Antwort: ALTER TABLE vs. Schemaless   ALTER TABLE in MySQL nervt. Das tut es in erster Linie, weil es die Tabellen, die es verändert, mit einem exklusiven Lock (Write Lock) belegt, während es die Änderung durchführt, und weil es die Änderung durch Umkopieren der Daten und Indices durchführt, was bei einer großen bestehenden Datenmenge doch recht lange dauern kann.
Es gibt inzwischen eine Reihe von Verbesserungen in MySQL 5.</description>
    </item>
    
    <item>
      <title>Schemaless?</title>
      <link>https://blog.koehntopp.info/2011/04/19/schemaless.html</link>
      <pubDate>Tue, 19 Apr 2011 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2011/04/19/schemaless.html</guid>
      <description>Die Frage:   Ich brauche einmal Hilfe. Von Euch. Ich verstehe nämlich ein Konzept nicht. Es geht um den Begriff &amp;ldquo;Schemaless&amp;rdquo;, der im Zusammenhang mit einigen NoSQL-Datenbanken verwendet wird.
Ich kann verstehen, daß für einige Leute ein ALTER TABLE wie in MySQL ein Problem ist, weil es Tabellen während der Schemaänderung lockt. Da ALTER TABLE in vielen Fällen die Daten zur Durchführung der Änderung umkopieren muß, kann dieses Lock entsprechend lange bestehen bleiben, wenn die Daten nur hinreichend groß sind.</description>
    </item>
    
    <item>
      <title>Automatisierung und Skalierung - Teil 2</title>
      <link>https://blog.koehntopp.info/2011/02/18/automatisierung-und-skalierung-teil-2.html</link>
      <pubDate>Fri, 18 Feb 2011 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2011/02/18/automatisierung-und-skalierung-teil-2.html</guid>
      <description>Dies ist der 2. Teil zum Thema Automatisierung von Systemverwaltungsaufgaben. Den ersten Teil gibt es hier .
In jenem Text habe ich mit dem Beispiel eines Installationsservers gearbeitet und ich schrieb darüber:
 Was also wie ein wenig Gescripte aussieht, ist in Wirklichkeit die Definition und Realisierung eines Prozesses - genau genommen die Formalisierung eines Prozesses &amp;ldquo;Server aufsetzen&amp;rdquo; in der Firma. Das Ziel des Prozesses ist die Produktion einer neuen Maschine, die einer gewissen Spezifikation möglichst gut entsprechen soll.</description>
    </item>
    
    <item>
      <title>Automatisierung und Skalierung</title>
      <link>https://blog.koehntopp.info/2011/02/17/automatisierung-und-skalierung.html</link>
      <pubDate>Thu, 17 Feb 2011 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2011/02/17/automatisierung-und-skalierung.html</guid>
      <description>Ich hatte im Vorfeld der OSDC 2011 eine interessante Unterhaltung mit Julian Hein zum Thema Automatisierung. Er wollte, daß ich einmal erkläre, warum man das eigentlich tut - und was man da eigentlich tut.
Die Antwort ist ein wenig länger, und weil ich dieses Jahr nicht zur OSDC fahren kann und dort auch nicht reden kann, will ich einmal versuchen, meinen Text zumindest in groben Zügen hier aufzuschreiben.
 Die Zusammenfassung ist jedenfalls, daß Automatisierung kein technisches Problem ist.</description>
    </item>
    
    <item>
      <title>Ein paar Gedanken zum Thema NoSQL</title>
      <link>https://blog.koehntopp.info/2010/11/05/ein-paar-gedanken-zum-thema-nosql.html</link>
      <pubDate>Fri, 05 Nov 2010 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2010/11/05/ein-paar-gedanken-zum-thema-nosql.html</guid>
      <description>Beim Durchstöbern der verschiedenen NoSQL-Datenspeicher stellt sich mir die Frage, wieso man das alles überhaupt will. Genauer: Was genau ist das Problem, das man mit NoSQL lösen möchte?
Diejenigen Leute, die NoSQL-Lösungen einsetzen, haben in der Regel die Schwierigkeit, daß ihre Datenmenge größer wird, als man auf einer einzelnen Maschine mit der geforderten Servicequalität handhaben kann.
Im Webbereich sind die Anforderungen für interaktives Browsen oft so, daß man die gewünschten Antwortzeiten nur dann erreichen kann, wenn die dabei verwendeten Datenbanken ihre Daten und Indices zum allergrößten Teil im RAM halten können.</description>
    </item>
    
    <item>
      <title>Red vs Blue at Oracle, und ein paar Gedanken zu Postgres</title>
      <link>https://blog.koehntopp.info/2010/11/04/red-vs-blue-at-oracle-und-ein-paar-gedanken-zu-postgres.html</link>
      <pubDate>Thu, 04 Nov 2010 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2010/11/04/red-vs-blue-at-oracle-und-ein-paar-gedanken-zu-postgres.html</guid>
      <description>Ich schrieb :
 heretic666 schrieb am 4. November 2010 12:11
&amp;hellip;das man nicht auch wahlweise mit PostgreSQL oder MS SQL erschlagen kann?
Mir fällt da im Moment kein Punkt ein&amp;hellip;
 Postgres ist ein Repräsentant der klassischen Datenbanken und fällt in dieselbe Kategorie wie Oracle, MS SQL oder DB/2. MySQL ist eine Datenbank, die sich in vielen Punkten an den Erfordernissen des Webs orientiert und ganz andere Schwerpunkte als Postgres oder Oracle setzt.</description>
    </item>
    
    <item>
      <title>&#39;a&#39; = &#39;b&#39; = &#39;c&#39;</title>
      <link>https://blog.koehntopp.info/2010/09/10/a-b-c.html</link>
      <pubDate>Fri, 10 Sep 2010 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2010/09/10/a-b-c.html</guid>
      <description>Kurzer SQL WTF von heute:
mysql&amp;gt;SELECT&amp;#39;a&amp;#39;=&amp;#39;b&amp;#39;;0mysql&amp;gt;SELECT&amp;#39;a&amp;#39;=&amp;#39;b&amp;#39;=&amp;#39;c&amp;#39;;1Warum ist das so?
Im MySQL Sourcecode ist in sql/sql_yacc.yy definiert:
%left EQ EQUAL_SYM GE GT_SYM LE LT NE IS LIKE REGEXP IN_SYM Damit ist der Operator EQ (das Vergleichheitszeichen) als links-assoziativ definiert. Vergleiche von Vergleichen sind also zugelassen,
1 = 2 = 3 ist also ein zulässiges Konstrukt und es wird als ( 1 = 2 ) = 3 evaluiert.
Statt links-assoziativ könnte es auch als rechts-assoziativ 1 = (2 = 3) oder als nicht-assoziativ (ein Mehrfachvergleich ist unzulässig) definiert sein.</description>
    </item>
    
    <item>
      <title>Covering indexes und MVCC</title>
      <link>https://blog.koehntopp.info/2010/09/09/covering-indexes-und-mvcc.html</link>
      <pubDate>Thu, 09 Sep 2010 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2010/09/09/covering-indexes-und-mvcc.html</guid>
      <description>Für viele MySQL-Anwendungen sind Covering Indexes eine wichtige Sache. Domas hat einen Artikel darüber Wie Wikipedia von Covering Indexes profitiert , und auch sonst sind solche Indices für viele MySQLer ein täglicher Bestandteil der Optimierungsarbeit.
Nun las ich neulich in einem Artikel eine Seitenbemerkung, daß Postgres keine Covering Indices unterstützt und das scheint tatsächlich der Fall zu sein , auch wenn ich in der Doku selber keine Hinweise darauf gefunden habe.</description>
    </item>
    
    <item>
      <title>Verteilte Datenbanken: Der Sonderfall Filialsysteme</title>
      <link>https://blog.koehntopp.info/2010/08/18/verteilte-datenbanken-der-sonderfall-filialsysteme.html</link>
      <pubDate>Wed, 18 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2010/08/18/verteilte-datenbanken-der-sonderfall-filialsysteme.html</guid>
      <description>In einem Kommentar zu Master-Master schrieb ich:
 Für den von Dir genannten Sonderfall der Filialsysteme habe ich noch einen deutschen Artikel in der Warteschlange, ich muß nur Zeit finden ihn zu schreiben.
 Normalerweise sieht MySQL Replikation so aus:
MySQL Replikation - Architekturübersicht
Master Binlog   Auf dem Master ist mit der Konfigurationsanweisung log_bin das Binlog aktiviert.
Das Binlog loggt bei Statement Based Replication (SBR) alle Anweisungen, die Daten verändern (also quasi alles außer SELECT).</description>
    </item>
    
    <item>
      <title>Ein Ring mit zwei MySQL-Servern und auto_increment_increment</title>
      <link>https://blog.koehntopp.info/2010/08/17/ein-ring-mit-zwei-mysql-servern-und-auto-increment-increment.html</link>
      <pubDate>Tue, 17 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2010/08/17/ein-ring-mit-zwei-mysql-servern-und-auto-increment-increment.html</guid>
      <description>Lalufu fragte in den Kommentaren von Master-Master :
 Ich habe eine MM-Replikation mit zwei Servern.
Beide haben auto_increment_increment=10,
Server A hat auto_increment_offset=0 und Server B hat auto_increment_offset=1.
Ich lege mir eine Tabelle mit einem auto_increment-Feld (id) an und mache auf Server A einen INSERT, dann kriegt die row id=0, und wird auf B repliziert, richtig?
Dann noch einen INSERT auf A, die row kriegt id=10, und wird auf B repliziert.</description>
    </item>
    
    <item>
      <title>Master-Master und Distributed Transactions</title>
      <link>https://blog.koehntopp.info/2010/08/16/master-master-und-distributed-transactions.html</link>
      <pubDate>Mon, 16 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2010/08/16/master-master-und-distributed-transactions.html</guid>
      <description>Immer mal wieder kommt jemand im Internet auf die Idee, wie man Master-Master und verteilte Transaktionen ganz einfach realisieren kann. MySQL verteilte Daten von Okami ist ein gutes Beispiel für diese Idee:
 Wir nutzen dabei aus, dass MySQL bei zusammengesetzten Indizes einen AUTO_INCREMENT-Wert pro distinktem Schlüsselpräfix zählt. Das heißt ganz konkret: Wir legen einen Primär-Schlüssel aus zwei Spalten zusammen. In der ersten Spalte verwenden wir einen sehr kleinen Wert, der die Quelle der Daten kennzeichnet: Source tinyint unsigned NOT NULL; Den zweiten Teil legen wir als einfache ID int unsigned NOT NULL AUTO_INCREMENT an.</description>
    </item>
    
    <item>
      <title>Die relationale Datenbank wird 40.</title>
      <link>https://blog.koehntopp.info/2010/06/08/die-relationale-datenbank-wird-40.html</link>
      <pubDate>Tue, 08 Jun 2010 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2010/06/08/die-relationale-datenbank-wird-40.html</guid>
      <description>Nicht nur wird PHP im Juni 15 Jahre alt, sondern ein anderer, älterer Begleiter von PHP feiert ebenfalls ein Jubiläum:
Im Juni 1970 erschien in den Communications of the ACM der Artikel &amp;ldquo;A Relational Model of Data for Large Shared Data Banks &amp;rdquo; von E.F.Codd. Dieser Artikel ist die theoretische Grundlage für das, was später SQL und relationale Datenbanken werden sollte.
Seitdem MySQL und PHP vor 15 Jahren ausgezogen sind, das Web zu revolutionieren, ist SQL eine Haushaltssprache geworden - es ist inzwischen echt schwierig, Webspace zu kaufen, bei dem man nicht auch Zugriff auf eine MySQL-Datenbank hat, und entsprechend gehen HTML-, PHP- und SQL-Kenntnisse inzwischen einher.</description>
    </item>
    
    <item>
      <title>Was bedeutet eigentlich &#39;Relationale Algebra&#39;?</title>
      <link>https://blog.koehntopp.info/2010/04/28/was-bedeutet-eigentlich-relationale-algebra.html</link>
      <pubDate>Wed, 28 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2010/04/28/was-bedeutet-eigentlich-relationale-algebra.html</guid>
      <description>SQL ist eine Abfragesprache, die als mathematischen Unterbau die Relationenalgebra hat. Was genau ist das?
Da ist einmal der Begriff der &amp;ldquo;Algebra&amp;rdquo;. In der Wikipedia findet man die mathematische Definition der algebraischen Struktur, und sie ist, weil sie mathematischen Formalismen genügen muß, für den ungeübten ein wenig unhandlich zu lesen.
Dort steht aber nix anderes als &amp;lsquo;Wir haben eine Grundmenge A und einen definierten Satz von erlaubten Operationen auf A, und wir garantieren, das das Ergebnis jeder Operation wieder in A liegt.</description>
    </item>
    
    <item>
      <title>Zählen von Aktionen</title>
      <link>https://blog.koehntopp.info/2010/04/21/z-hlen-von-aktionen.html</link>
      <pubDate>Wed, 21 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2010/04/21/z-hlen-von-aktionen.html</guid>
      <description>Hier ist noch ein dreckiges kleines MySQL-Problem. Matthias Fiedler fragt:
 Ich möchte in einer Tabelle bestimmte Werte bzw. Datensätze ändern. Das läuft in einer Schleife und ich möchte mitzählen, wie viele Datensätze wirklich geändert wurden….
Wenn ich nur Update benutze und der Datensatz in der Tabelle ist identisch mit dem neuen, dann wird kein Update ausgeführt. Somit kann ich hier mit mysql_affected_rows() die Menge zählen. Das hat aber einen Nachteil: Manche Datensätze sind ja noch gar nicht in der Tabelle.</description>
    </item>
    
    <item>
      <title>Spatial Indices</title>
      <link>https://blog.koehntopp.info/2010/04/11/spatial-indices.html</link>
      <pubDate>Sun, 11 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2010/04/11/spatial-indices.html</guid>
      <description>On 2010-04-06 12:26:49 +0200, Egon Schmid said:
 Ich hab eine 60 MB grosse SQL-Datei von der OpenGeoDB (-&amp;gt;http://fa-technik.adfc.de/code/opengeodb/) runtergeladen, wo sämtliche Informationen der Deutschlandkarte vorhanden sind, und werde es damit mal testen.Das Ausführen der INSERTs dauert allerdings einige Stunden :) Es läuft derzeit immer noch&amp;hellip;
 InnoDB, AUTOCOMMIT = 1. Vor dem source von DE.sql ein BEGIN WORK machen, danach ein COMMIT. Dann geht es sehr viel schneller.
Mit diesen Daten und einem Beispielort kann man experimentieren.</description>
    </item>
    
    <item>
      <title>Über ENUM (und Fast Alter Table)</title>
      <link>https://blog.koehntopp.info/2010/04/09/ber-enum-und-fast-alter-table.html</link>
      <pubDate>Fri, 09 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2010/04/09/ber-enum-und-fast-alter-table.html</guid>
      <description>On 2010-04-08 13:40:57 +0200,
Karsten Wutzke said :
 gibt es ein sinnvolles Maximum für die Anzahl von Elementen in einem ENUM?
 ENUM hat in MySQL 5.1 einige Eigenschaften, die überraschend sind. Zum Beispiel
root@localhost[kris]&amp;gt;createtablet(idintegerunsignednotnullprimarykey,eenum(&amp;#39;a&amp;#39;,&amp;#39;b&amp;#39;,&amp;#39;c&amp;#39;)notnull)engine=innodb;QueryOK,0rowsaffected(0.21sec)root@localhost[kris]&amp;gt;insertintotvalues(1,&amp;#39;&amp;#39;);QueryOK,1rowaffected,1warning(0.00sec)Warning(Code1265):Datatruncatedforcolumn&amp;#39;e&amp;#39;atrow1root@localhost[kris]&amp;gt;insertintotvalues(2,&amp;#39;c&amp;#39;);QueryOK,1rowaffected(0.00sec)root@localhost[kris]&amp;gt;selectid,e,hex(e),e+0fromt;+----+---+--------+-----+ |id|e|hex(e)|e+0|+----+---+--------+-----+ |1|||0||2|c|63|3|+----+---+--------+-----+ 2rowsinset(0.00sec)Obwohl t.e ein ENUM ist, das per Definition keinen Wert &#39;&#39; zuläßt, hat MySQL den Wert &#39;&#39; abspeichern können, wenn auch mit einer Warnung.
Bei der Kontrollausgabe sieht man bei der Konvertierung nach INTEGER, daß ein ENUM intern Zahl gespeichert wird, wobei dem ersten Wert die Zahl 1, dem nächsten die Zahl 2 und so weiter zugeordnet wird.</description>
    </item>
    
    <item>
      <title>Gruppenweises TOP N in MySQL: Der Tabellengrößenreport</title>
      <link>https://blog.koehntopp.info/2010/03/09/gruppenweises-top-n-in-mysql-der-tabellengr-enreport.html</link>
      <pubDate>Tue, 09 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2010/03/09/gruppenweises-top-n-in-mysql-der-tabellengr-enreport.html</guid>
      <description>Jeder Datenbankserver bei uns hat ein Script laufen, daß den Inhalt von information_schema.tables jede Nacht einmal in eine Systemdatenbank in das DBA Schema kopiert. Dort haben wir dba.table_sizes:
root@sysmdb[dba]&amp;gt;showcreatetabletable_sizes\GTable:table_sizesCreateTable:CREATETABLE`table_sizes`(`hostname`varchar(64)NOTNULL,`datadir`varchar(64)CHARACTERSETlatin1COLLATElatin1_binNOTNULL,`report_date`dateNOTNULL,`table_schema`varchar(64)CHARACTERSETlatin1COLLATElatin1_binNOTNULL,`table_name`varchar(64)CHARACTERSETlatin1COLLATElatin1_binNOTNULL,`engine`varchar(64)NOTNULL,`data_length`bigint(20)NOTNULL,`index_length`bigint(20)NOTNULL,`table_rows`bigint(20)NOTNULL,UNIQUEKEY`hostname`(`hostname`,`datadir`,`report_date`,`table_schema`,`table_name`))ENGINE=InnoDBDEFAULTCHARSET=latin11rowinset(0.00sec)Gesucht war nun eine Query, die für jeden Sonntag eine Liste der 10 größten Tabellen eines bestimmten Servers &amp;lsquo;master&amp;rsquo; für 2010 produziert.
Die Lösung ist fragil insofern, als daß sie eine undokumentierte Eigenschaft des Servers ausnutzt. Aber sie ist auch schnell.
set@old:=&amp;#34;&amp;#34;,@count:=0;select\*from(select@count:=if(@old&amp;lt;=&amp;gt;report_date,@count+1,0)asc,@old:=report_dateasreport_date,hostname,table_name,(data_length+index_length)/1024/1024/1024asgbfromtable_sizeswheredate_format(report_date,&amp;#39;%W&amp;#39;)=&amp;#39;Sunday&amp;#39;andreport_date&amp;gt;&amp;#39;2010-01-01&amp;#39;andhostname=&amp;#39;master&amp;#39;anddatadir=&amp;#39;/mysql/bp/data/&amp;#39;andtable_schema=&amp;#39;bp&amp;#39;orderbyreport_date,gbdesc)astwheret.c&amp;lt;10;Wir definieren einen Zustandsspeicher @old, der das report_date der folgenden Zeile speichert und einen Zähler @count.</description>
    </item>
    
    <item>
      <title>INSERT  ON DUPLICATE KEY UPDATE</title>
      <link>https://blog.koehntopp.info/2010/03/09/insert-on-duplicate-key-update.html</link>
      <pubDate>Tue, 09 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2010/03/09/insert-on-duplicate-key-update.html</guid>
      <description>Auf Yourhelpcenter.de gibt es einen Artikel mit dem irreführenden Titel Update if exists else insert record , der sich mit INSERT ON DUPLICATE KEY UPDATE beschäftigt.
Dieses Kommando macht genau nicht das, was der Titel des Artikels suggeriert und wünschenswert wäre, sondern er macht genau das, was der SQL-Text des Kommandos sagt und leider nervt. Es wäre schön, wenn der Artikel auf Yourhelpcenter auch auf diese Probleme eingegangen wäre - da er es nicht tut hole ich es hier gerade mal nach.</description>
    </item>
    
    <item>
      <title>MySQL, Sun, Oracle - und die EU</title>
      <link>https://blog.koehntopp.info/2009/11/12/mysql-sun-oracle-und-die-eu.html</link>
      <pubDate>Thu, 12 Nov 2009 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2009/11/12/mysql-sun-oracle-und-die-eu.html</guid>
      <description>Am 20. April 2009 hat Sun verkündet, daß sie von Oracle gekauft werden. Das hätte MySQL mit eingeschlossen. Am 10. November hat die EU dann mitgeteilt, daß sie diesem Kauf widerspricht und zwar ausschließlich wegen MySQL.
Groklaw hat Hintergründe dazu , die ein wenig komisch erscheinen. Ausgerechnet Monty und Florian Müller argumentieren gegen diesen Verkauf und verwenden in den Texten, die sie öffentlich gemacht haben noch dazu die GPL: Diese verhindere nämlich kommerzielle Spinoffs und Forks von MySQL.</description>
    </item>
    
    <item>
      <title>Ein paar Gedanken zu Zeitreihendaten</title>
      <link>https://blog.koehntopp.info/2009/10/28/ein-paar-gedanken-zu-zeitreihendaten.html</link>
      <pubDate>Wed, 28 Oct 2009 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2009/10/28/ein-paar-gedanken-zu-zeitreihendaten.html</guid>
      <description>Ich sitze hier auf der Open Source Monitoring Conference und unterhalte mich mit ein paar Nagios bzw. Icinga Entwicklern. Dabei hörte ich einen Haufen Flüche über NDO - Nagios Data Out. Ich schaue mir gerade die Dokumentation zum NDO Schema an und stelle fest, daß die Ideen hier auf eine Weise viele Fehler teilen, die auch dem MySQL Enterprise Manager Schema zugrunde liegen (Noch, das MEM-Team bastelt das grad um).</description>
    </item>
    
    <item>
      <title>Ein paar Gedanken zu Foreign Key Constraints</title>
      <link>https://blog.koehntopp.info/2009/10/20/ein-paar-gedanken-zu-foreign-key-constraints.html</link>
      <pubDate>Tue, 20 Oct 2009 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2009/10/20/ein-paar-gedanken-zu-foreign-key-constraints.html</guid>
      <description>Ich lese gerade SQLite Foreign Key Support und ich muß sagen, ich kann mir ein leichtes Grinsen nicht verkneifen.
Also, ich finds ja gut, daß SQLite die Option für Foreign Key Constraints implementiert und ich finds sogar noch besser, daß mit DEFERRABLE INITIALLY DEFERRED sogar die einzig sinnvolle Weise das zu tun bereitgestellt wird, aber ich frag mich schon, wozu das gut sein soll.
Foreign Keys   Aber von vorne.</description>
    </item>
    
    <item>
      <title>Ein kurzer, aber heftiger Schlagabtausch mit SQL_MODE</title>
      <link>https://blog.koehntopp.info/2009/10/08/ein-kurzer-aber-heftiger-schlagabtausch-mit-sql-mode.html</link>
      <pubDate>Thu, 08 Oct 2009 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2009/10/08/ein-kurzer-aber-heftiger-schlagabtausch-mit-sql-mode.html</guid>
      <description>Letzte Woche Montag haben wir beschlossen, den SQL_MODE in unseren Entwicklungsservern auf einen strengeren Wert als &amp;quot;&amp;quot; (den Default) zu setzen. Das war ein Fehlschlag und wir haben den Change diese Woche zurück gerollt. Aber von vorne.
Welchen SQL_MODE will man denn?   Als Ziel-Einstellung haben wir eine Kombination von
TRADITIONAL, NO_ENGINE_SUBSTITUTION, ONLY_FULL_GROUP_BY, NO_AUTO_VALUE_ON_ZERO ins Auge gefaßt.
SQL_MODE ist eine Einstellung in MySQL, mit der das Verhalten des Servers beeinflußt werden kann.</description>
    </item>
    
    <item>
      <title>Connection Scoped State bei MySQL</title>
      <link>https://blog.koehntopp.info/2009/04/19/connection-scoped-state-bei-mysql.html</link>
      <pubDate>Sun, 19 Apr 2009 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2009/04/19/connection-scoped-state-bei-mysql.html</guid>
      <description>Aus einer Diskussion in der deutschsprachigen MySQL Gruppe im USENET. Dort ging es um die Frage, warum phpMyAdmin ein eingeschränktes Werkzeug ist und bei vielen Helfern im Netz unbeliebt. Meine Antwort lautete so:
phpMyAdmin unterliegt wie auch viele grafische Werkzeuge für MySQL (darunter auch jene, die von MySQL selbst bereitgestellt werden) einigen besonderen Einschränkungen. Diese sind prinzipbedingt und daher auch nicht leicht zu beheben.
Aber von vorne:
In MySQL ist es so, daß die Connection einen besonderen Kontext oder Scope darstellt.</description>
    </item>
    
    <item>
      <title>Das MySQL-Sun-Dilemma</title>
      <link>https://blog.koehntopp.info/2008/11/17/das-mysql-sun-dilemma.html</link>
      <pubDate>Mon, 17 Nov 2008 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2008/11/17/das-mysql-sun-dilemma.html</guid>
      <description>Sun hat eine Box , die hat 4 CPU-Chips drin, jeder Chip hat 8 Cores und jeder Core hat 8 Threads, die in etwa das sind, was man anderswo als Core abrechnet, minus 7/8 FPU. Das macht effektiv eine Kiste in mit 256 Cores.
Jeder Core Thread selbst ist im Vergleich zu Intel-Hardware jedoch recht langsam, er bringt etwa ein Drittel bis ein Fünftel der Leistung eines Intel-Cores, außer in Benchmarks, wo die Dinger viel schicker poliert werden.</description>
    </item>
    
    <item>
      <title>mysql&gt; quit;</title>
      <link>https://blog.koehntopp.info/2008/05/28/mysql-quit.html</link>
      <pubDate>Wed, 28 May 2008 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2008/05/28/mysql-quit.html</guid>
      <description>Mit dem Ende dieser Woche endet nicht nur die MySQL Deutschland GmbH , sondern auch meine Tätigkeit bei MySQL. Den neuen Vertrag bei Sun habe ich, anders als zunächst geplant, nicht unterschrieben - mir ist relativ schnell klar geworden, daß ich mich in einer Firma dieser Größe nicht wohlfühlen werde.
Für MySQL bin ich seit Ende des Jahres 2005 unterwegs gewesen - bis zu 180 Tage im Jahr. Neben einigen größeren Projekten habe ich sehr viel kleineres Consulting gemacht - &amp;ldquo;Pivot-Consulting&amp;rdquo;, bei dem es nicht darum geht ein Projekt umzusetzen, sondern den Kunden dazu zu befähigen, das Projekt selber zu schaukeln.</description>
    </item>
    
    <item>
      <title>Die InnoDB Storage Engine: Konfiguration</title>
      <link>https://blog.koehntopp.info/2008/02/03/die-innodb-storage-engine-konfiguration.html</link>
      <pubDate>Sun, 03 Feb 2008 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2008/02/03/die-innodb-storage-engine-konfiguration.html</guid>
      <description>Links: Strukturen im Speicher, Rechts: Strukturen auf Disk. Oben: Log-Strukturen, Unten: Tablespace-Strukturen.
Wie eine Transaktion physikalisch organisiert wird   Wenn in InnoDB eine neue Transaktion begonnen und erzeugt wird, ist sie ja noch nicht comitted und damit hat die Datenbank gegenüber der Anwendung noch kein Versprechen gemacht. Entsprechend brauchen die Daten aus einer solchen Transaktion auch noch nicht persistent gemacht zu werden.
InnoDB versucht, eine Transaktion im Speicher zusammen zu bauen.</description>
    </item>
    
    <item>
      <title>Die InnoDB Storage Engine</title>
      <link>https://blog.koehntopp.info/2008/01/30/die-innodb-storage-engine.html</link>
      <pubDate>Wed, 30 Jan 2008 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2008/01/30/die-innodb-storage-engine.html</guid>
      <description>Die Storage Engine InnoDB ist eine Storage Engine, die ACID-konform betrieben werden kann, Transaktionen beherrscht und Foreign Key Constraints prüfen kann. Sie ist geeignet für alle Anwendungen, die Online Transaction Processing machen oder aus anderen Gründen eine hohe Rate von paralellen Schreibzugriffen haben.
Hat mein MySQL InnoDB Support und ist dieser betriebsbereit?   Mit dem Kommano SHOW ENGINES kann man sich die von einer Instanz unterstützten Engines anzeigen lassen. Wenn InnoDB enthalten und betriebsbereit ist, wird die Engine mit YES angezeigt.</description>
    </item>
    
    <item>
      <title>SUNW, äh, JAVA</title>
      <link>https://blog.koehntopp.info/2008/01/16/sunw-aeh-java.html</link>
      <pubDate>Wed, 16 Jan 2008 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2008/01/16/sunw-aeh-java.html</guid>
      <description>Aus irgendeinem Grund werden die Firmen verkauft, für die ich arbeite, kaum 2 Jahre nachdem ich da angefangen habe. Das war bei web.de so und jetzt passiert es gerade wieder: Sun hat meinen Arbeitgeber für eine runde Milliarde Dollar gekauft .
Was ich davon halten soll, weiß ich noch nicht - das wird sich erst ein den kommenden neun Monaten zeigen. Die nächsten 3 Monate werden meiner Erwartung nach die Anwälte erst einmal die letzten Details auskämpfen, und dann schaue ich mir den Laden mal an.</description>
    </item>
    
    <item>
      <title>Zehn Zentimeter</title>
      <link>https://blog.koehntopp.info/2007/08/11/zehn-zentimeter.html</link>
      <pubDate>Sat, 11 Aug 2007 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2007/08/11/zehn-zentimeter.html</guid>
      <description>Kristian, wenn Du über Performance redest, dann redest Du immer von verteilten, asynchronen Systemen . Verteilte, asynchrone Systeme sind doof, schwer zu programmieren und laufen der Theorie zuwider, die ich an der Uni gelernt habe. Ich warte glaube ich lieber auf schnellere Prozessoren.
 Viel Spaß beim Warten. Godot wird Dir Deine neue CPU bestimmt bald bringen.
Ein Gigahertz ist ein Takt pro Nanosekunde. Bei Lichtgeschwindigkeit kommt das Signal in einer Nanosekunde in etwa 30cm weit.</description>
    </item>
    
    <item>
      <title>Hardware für ein MySQL</title>
      <link>https://blog.koehntopp.info/2007/07/28/hardware-f-r-ein-mysql.html</link>
      <pubDate>Sat, 28 Jul 2007 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2007/07/28/hardware-f-r-ein-mysql.html</guid>
      <description>&amp;ldquo;Ich muß Hardware für einen Rechner kaufen, auf dem dediziert nur ein MySQL laufen soll. Was soll ich beschaffen?&amp;rdquo; ist eine Frage, die ich recht oft höre. Hier ist die lange Antwort.
Bevor man sich mit dem freundlichen Hardwarehöker des geringsten Mißtrauens in Verbindung setzen kann, muß man sich erst einmal ein paar Dinge überlegen.
Datenbank-Zielgröße bestimmen   Die allererste Überlegung ist die erwartete Zielgröße der Datenbank: Werden wir einen Bestand von 1G, 10G, 100G oder 1000G haben?</description>
    </item>
    
    <item>
      <title>Supertopp!</title>
      <link>https://blog.koehntopp.info/2007/02/03/supertopp.html</link>
      <pubDate>Sat, 03 Feb 2007 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2007/02/03/supertopp.html</guid>
      <description>Kris bei 200 km/h Gegenwind im Windtunnel von Sky Venture, Orlando.</description>
    </item>
    
    <item>
      <title>Ein Nagios-Plugin für MySQL</title>
      <link>https://blog.koehntopp.info/2007/01/20/ein-nagios-plugin-fuer-mysql.html</link>
      <pubDate>Sat, 20 Jan 2007 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2007/01/20/ein-nagios-plugin-fuer-mysql.html</guid>
      <description>Auf Sourceforge findet man Plug-in development guidelines für den Nagios Netzwerkmonitor. Demnach ist es trivial, Nagios-Plugins zu entwickeln: Der Check ist ein externes Programm, das den Returncode 0, 1 oder 2 zurückgibt und eine einzeilige Nachricht auf stdout druckt.
Tun wir das doch mal für MySQL: Wir wollen die Anzahl der Threads_connected überwachen und den Replikationsstatus: SQL-Thread und IO-Thread müssen laufen und der Slave-Lag darf nicht zu groß sein.
Wir schreiben das Plugin in C, damit wir zugleich mal lernen, die MYSQL Client-API in C zu verwenden - Shellscripte, die sich das Abbrechen gibt es ja schon genug.</description>
    </item>
    
    <item>
      <title>Ein Jahr auf der Straße</title>
      <link>https://blog.koehntopp.info/2006/10/31/ein-jahr-auf-der-strasse.html</link>
      <pubDate>Tue, 31 Oct 2006 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2006/10/31/ein-jahr-auf-der-strasse.html</guid>
      <description>Jetzt bin ich genau ein Jahr lang für MySQL auf der Straße gewesen. Eigentlich begann alles schon ein wenig früher, als ich meinen Resturlaub Anfang September 2005 dazu verwendet habe, am MySQL Consulting Bootcamp 2005 in München teilzunehmen und mich dort auch zertifizieren zu lassen. Zwei Monate später, am 1. November, habe ich dann meinen neuen Job angetreten.
Die ersten zwei Wochen habe ich Peter Zaitsev beim c&amp;rsquo;t DVD-Shop Benchmark begleitet und dabei eine Menge über MySQL Performance Tuning gelernt.</description>
    </item>
    
    <item>
      <title>MySQL Performanceprobleme mit einem Profiler analysieren</title>
      <link>https://blog.koehntopp.info/2006/10/14/mysql-performanceprobleme-mit-einem-profiler-analysieren.html</link>
      <pubDate>Sat, 14 Oct 2006 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2006/10/14/mysql-performanceprobleme-mit-einem-profiler-analysieren.html</guid>
      <description>Oprofile ist ein Profiler. Und zwar einer, der die Performance Measurement Instrumentation verwendet, die in moderne CPUs eingebaut ist, wenn diese vorhanden ist. Der Profiler braucht also keine speziell für Profiling compilierten Binaries, sondern zieht sich statische Samples des Programmzählers aus dem laufenden System und analysiert diese: Es findet heraus, welcher Prozeß gerade aktiv ist, welche Bibliothek in diesem Prozeß gerade verwendet wird und wenn Symboltabellen vorhanden sind (Kein &amp;ldquo;strip&amp;rdquo; auf die Bibliothek oder das Programm angewendet), dann weiß Oprofile sogar, welche Funktion oder Methode gerade aktiv ist.</description>
    </item>
    
    <item>
      <title>Kris vs. 2xMSA 30</title>
      <link>https://blog.koehntopp.info/2006/10/04/kris-vs-2xmsa-30.html</link>
      <pubDate>Wed, 04 Oct 2006 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2006/10/04/kris-vs-2xmsa-30.html</guid>
      <description>&amp;lt;Ein MSA-30 Array mit 14 Platten.
Liebes Tagebuch!
Heute bin ich gegen eine HP 585 und zwei MSA 30 angetreten und ich bin mir nicht ganz sicher, wer gewonnen hat. Aber laß mich von vorne erzählen.
Wie Du weißt, liebes Tagebuch, berechnet sich die Anzahl der Zugriffe, die man von einer einzelnen Platte pro Sekunde erwarten kann, wie folgt: 1000 ms/(Average Seek Time in ms + Rotational Delay in ms + Transfer Time in ms).</description>
    </item>
    
    <item>
      <title>MySQL: Zeichensatz-Grundlagen</title>
      <link>https://blog.koehntopp.info/2006/10/01/mysql-zeichensatz-grundlagen.html</link>
      <pubDate>Sun, 01 Oct 2006 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2006/10/01/mysql-zeichensatz-grundlagen.html</guid>
      <description>Markus fragt:
 Durch &amp;hellip; wechseln wir gerade unseren Root-Server. Dort habe ich bereits das Gentoo-Basissystem am fluppen. Bei der Umstellung möchte ich gleich von MySQL 4 auf 5 wechseln.Dabei stellt sich die Frage, ob ich das System nicht gleich von latin1 auf utf-8 umstellen soll. Sollte ich lieber bei latin1 bleiben und alles so migrieren oder doch den großen Wurf zu utf-8 wagen?
 Die Frage habe ich ihm schon beantwortet, aber versprochen, das Thema noch einmal im Blog &amp;ldquo;in groß&amp;rdquo; durchzudeklinieren.</description>
    </item>
    
    <item>
      <title>Zeichensatzärger</title>
      <link>https://blog.koehntopp.info/2006/08/06/zeichensatzaerger.html</link>
      <pubDate>Sun, 06 Aug 2006 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2006/08/06/zeichensatzaerger.html</guid>
      <description>Choose any font you like
Seit MySQL 4.1 existiert in MySQL Support für Zeichensätze und Sortierreihenfolgen. Das bedeutet im Wesentlichen, daß an jedem CHAR, VARCHAR und TEXT in der Datenbank und an jeder Stringkonstante dranklebt, in welcher Codierung der String vorliegt und mit welcher Sortierreihenfolge der String beim Sortieren und Vergleichen zu behandeln ist.
Vokabeln   Aber zuerst einmal ein bischen Vokabular:
Ein Zeichensatz ist eine Sammlung von Symbolen, die verwendet werden dürfen.</description>
    </item>
    
    <item>
      <title>Leben mit Fehlern - der Schlüssel zum Scaleout</title>
      <link>https://blog.koehntopp.info/2006/07/30/leben-mit-fehlern-der-schluessel-zum-scaleout.html</link>
      <pubDate>Sun, 30 Jul 2006 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2006/07/30/leben-mit-fehlern-der-schluessel-zum-scaleout.html</guid>
      <description>Scaling Patterns
In 2004 habe ich auf dem Linuxtag einen kleinen Vortrag zum Thema Skalierbarkeit gehalten. Schon damals war die Message an verschiedenen Stellen im Vortrag &amp;ldquo;Jedes Readproblem ist ein Caching-Problem, jedes Schreibproblem ist ein Verteilungs- und Batchproblem&amp;rdquo;:
Zum Skalieren muß man seine Anwendung in Teilanwendungen unterteilen und die Daten replizieren. Die Replikation muß asynchron erfolgen, ohne Two Phase Commit (2PC), sonst gewinnt man wenig bis nichts. Schreibzugriffe müssen verzögert und gebatched werden, damit sie effizienter abgewickelt werden können.</description>
    </item>
    
    <item>
      <title>Mein privates Datawarehouse - Sparen mit MySQL</title>
      <link>https://blog.koehntopp.info/2006/07/23/mein-privates-datawarehouse-sparen-mit-mysql.html</link>
      <pubDate>Sun, 23 Jul 2006 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2006/07/23/mein-privates-datawarehouse-sparen-mit-mysql.html</guid>
      <description>Meine Sparkasse exportiert mir die Kontoauszüge aus Wunsch auch als CSV. Die Dateien sehen so aus:
&amp;#34;Auftragskonto&amp;#34;;&amp;#34;Buchungstag&amp;#34;;&amp;#34;Valutadatum&amp;#34;;&amp;#34;Buchungstext&amp;#34;;&amp;#34;Verwendungszweck&amp;#34;;&amp;#34;Begünstigter/Zahlungspflichtiger&amp;#34;;&amp;#34;Kontonummer&amp;#34;;&amp;#34;BLZ&amp;#34;;&amp;#34;Betrag&amp;#34;;&amp;#34;Währung&amp;#34;;&amp;#34;Info&amp;#34;&amp;#34;08154711&amp;#34;;&amp;#34;30.12&amp;#34;;&amp;#34;30.12.05&amp;#34;;&amp;#34;LASTSCHRIFT&amp;#34;;&amp;#34;DRP 08154711 040441777 INKL. 16% UST 5.38 EUR&amp;#34;;&amp;#34;STRATO MEDIEN AG&amp;#34;;&amp;#34;040441777&amp;#34;;&amp;#34;10050000&amp;#34;;&amp;#34;-39,00&amp;#34;;&amp;#34;EUR&amp;#34;;&amp;#34;Umsatz gebucht&amp;#34;Weil ich wissen will, wofür ich mein Geld ausgebe, lade ich diese Daten in ein MySQL.
Das geht so:
Zunächst einmal muß ich mir eine Tabelle definieren, in die ich den Load vornehmen kann. Diese Tabelle hat Felder, die in erster Linie dazu geschaffen sind, die Daten aufnehmen zu können.</description>
    </item>
    
    <item>
      <title>Erfahrungen mit Nonoffice</title>
      <link>https://blog.koehntopp.info/2006/07/05/erfahrungen-mit-nonoffice.html</link>
      <pubDate>Wed, 05 Jul 2006 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2006/07/05/erfahrungen-mit-nonoffice.html</guid>
      <description>Seit dem 1. November 2005 arbeite ich für MySQL Deutschland GmbH als Consultant. Damit mit bin ich Teil einer Firma mit 320 Mitarbeitern in 27 Ländern. Ein Office habe ich noch nie gesehen . Einige der Kollegen, mit denen ich am engsten zusammenarbeite habe ich auch noch nie gesehen. Die anderen sehe ich so alle paar Monate mal. Die Zusammenarbeit ist gut und sehr intensiv.
Als ich von web.de zu MySQL gewechselt bin, war ich am Anfang sehr skeptisch und habe meine Interviewpartner gefragt, wie das denn wohl so ist, für eine &amp;ldquo;virtuelle&amp;rdquo; Firma zu arbeiten, in der die Kollegen so weit verstreut gesät sind.</description>
    </item>
    
    <item>
      <title>MySQL für Dummies (7)</title>
      <link>https://blog.koehntopp.info/2006/03/08/mysql-fuer-dummies-7.html</link>
      <pubDate>Wed, 08 Mar 2006 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2006/03/08/mysql-fuer-dummies-7.html</guid>
      <description>Mein Freund Heinz ist Vertriebler, und manchmal sagen Vertriebler überraschend schlaue Dinge. Heinz zum Beispiel sagt sehr gerne &amp;ldquo;Niemand will Backup. Alle wollen Restore!&amp;rdquo; Er meint damit, daß ein Backup nicht nur ein lästiges Costcenter in der IT ist, sondern daß es außerdem keinen Mehrwert &amp;ldquo;an sich&amp;rdquo; darstellt. Der Mehrwert liegt nicht in der Datensicherung, sondern in der Wiederherstellung der Daten.
Es ist sehr wichtig, dies im Kopf zu behalten, wenn man sein Backup plant: Es geht nicht wirklich um Datensicherung, sondern es geht um einen Plan für die Recovery von verlorenen Daten.</description>
    </item>
    
    <item>
      <title>MySQL für Dummies (6)</title>
      <link>https://blog.koehntopp.info/2006/03/07/mysql-fuer-dummies-6.html</link>
      <pubDate>Tue, 07 Mar 2006 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2006/03/07/mysql-fuer-dummies-6.html</guid>
      <description>gilt das ganze auch für Mysql Version 4.1?
 http://dev.mysql.com/doc/refman/4.1/en/binary-log.html .
 Sag mal kannst du mir ein wirklich gutes Mysql Buch empfehlen, welches nicht nur auf Syntax eingeht, sondern sich auch mit der Konfiguration des Servers auseinandersetzt? Der Preis ist zweitrangig.
 MySQL Certification Study Guide (4.1, veraltet) MySQL Certification Study Guide (5.0, aktuell) Die Bücher bereiten Dich auch das Bestehen der Prüfungen der MySQL Certification vor.
High Performance MySQL , kein Buch für blutige Anfänger, basierend auf 4.</description>
    </item>
    
    <item>
      <title>MySQL für Dummies (5)</title>
      <link>https://blog.koehntopp.info/2006/03/06/mysql-fuer-dummies-5.html</link>
      <pubDate>Mon, 06 Mar 2006 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2006/03/06/mysql-fuer-dummies-5.html</guid>
      <description>Key Buffer   In dem letzten Artikel dieser Serie haben wir gesehen, wie MySQL einen Index anlegt und was dies bedeutet. MySQL at einen Puffer, mit dem ein Index ganz oder teilweise im RAM gehalten werden kann. Dies ist der Key Buffer, und er ist eine sehr zentrale Konfigurationsvariable, die in der [mysqld]-Sektion der my.cnf gesetzt wird.
[mysqld] key_buffer = 100M Dies stellt einen Key Buffer von bis zu 100 MB für den mysqld zur Verfügung.</description>
    </item>
    
    <item>
      <title>MySQL für Dummies (4)</title>
      <link>https://blog.koehntopp.info/2006/03/05/mysql-fuer-dummies-4.html</link>
      <pubDate>Sun, 05 Mar 2006 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2006/03/05/mysql-fuer-dummies-4.html</guid>
      <description>Wie wir in den vorangegangenen Beispielen gesehen haben, reicht es nicht aus, einer Datenbank zu sagen, welche Daten sie zu suchen hat. Wir müssen ihr auch noch Hilfen geben, mit denen sie in der Lage ist, diese Aufgabe schnell zu erfüllen. Eine sehr wichtige solche Hilfe ist ein Index.
Eine MYD-Datei wird, wenn sie keine Lücken hat, durch Anfügen von neuen Datensätzen verlängert. Die natürliche Reihenfolge der Datensätze in einer MYD-Datei ohne Löschen ist also chronologisch.</description>
    </item>
    
    <item>
      <title>MySQL für Dummies (3)</title>
      <link>https://blog.koehntopp.info/2006/03/04/mysql-fuer-dummies-3.html</link>
      <pubDate>Sat, 04 Mar 2006 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2006/03/04/mysql-fuer-dummies-3.html</guid>
      <description>Suchen dauern auf unserer Tabelle sehr lange.
root@localhost [rootforum]&amp;gt; select * from t where i = 1163012190; +----------+--------------+---------------------------+------------+ | id | d | e | i | +----------+--------------+---------------------------+------------+ | 19999993 | vrciabekkgcb | ykdewonxucqpwtdvzgnschyaw | 1163012190 | +----------+--------------+---------------------------+------------+ 1 row in set (21.81 sec) root@localhost [rootforum]&amp;gt; select * from t where i = 944905110; +----+--------------+---------------------------+-----------+ | id | d | e | i | +----+--------------+---------------------------+-----------+ | 5 | kgiyuxheibsa | bipgdpnvetowphowepuerediy | 944905110 | +----+--------------+---------------------------+-----------+ 1 row in set (19.</description>
    </item>
    
    <item>
      <title>MySQL für Dummies (2)</title>
      <link>https://blog.koehntopp.info/2006/03/03/mysql-fuer-dummies-2.html</link>
      <pubDate>Fri, 03 Mar 2006 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2006/03/03/mysql-fuer-dummies-2.html</guid>
      <description>Für die folgenden Beispiele wird eine breitere Tabelle gebraucht, und es müssen auch einige Testdaten vorhanden sein. Daher hier einmal eine Tabellendefinition und ein Generatorscript für Testdaten:
root@localhost [rootforum]&amp;gt; drop table t; Query OK, 0 rows affected (0.00 sec) root@localhost [rootforum]&amp;gt; create table t ( id bigint unsigned not null, d char(12) not null, e char(25) not null, i integer unsigned not null ); Query OK, 0 rows affected (0.22 sec) root@localhost [rootforum]&amp;gt; [1]+ Stopped mysql -u root -p und</description>
    </item>
    
    <item>
      <title>MySQL für Dummies (1)</title>
      <link>https://blog.koehntopp.info/2006/03/02/mysql-fuer-dummies-1.html</link>
      <pubDate>Thu, 02 Mar 2006 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2006/03/02/mysql-fuer-dummies-1.html</guid>
      <description>Ein MySQL Datenbankserver hat ein datadir. Das Kommando
root@localhost [(none)]&amp;gt; show variables like &amp;#34;datadir&amp;#34;; +---------------+-----------------+ | Variable_name | Value | +---------------+-----------------+ | datadir | /var/lib/mysql/ | +---------------+-----------------+ 1 row in set (0.00 sec) sagt uns, wo das liegt. In datadir wird für jede mit CREATE DATABASE angelegte Datenbank ein Verzeichnis angelegt, und für jede mit CREATE TABLE in dieser Datenbank vorhandene Tabelle eine *.frm-Datei. Dies gilt für alle Tabellentypen, die MySQL verwendet, sogar für MEMORY-Tables.</description>
    </item>
    
    <item>
      <title>In with the out, old with the new...</title>
      <link>https://blog.koehntopp.info/2005/10/28/in-with-the-out-old-with-the-new.html</link>
      <pubDate>Fri, 28 Oct 2005 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2005/10/28/in-with-the-out-old-with-the-new.html</guid>
      <description>Das war&amp;rsquo;s .
Bis heute - fast zwei Jahre lang - war ich Security-Fuzzi für web.de. Das bedeutet: Ich habe Security Policy definiert, Fachabteilungen bei der Umsetzung von Policies beraten und entweder selbst oder von Dritten die Umsetzung von Policies prüfen lassen, und außerdem den Security Incident Management Prozess betrieben. In der Praxis bedeutet das, daß ich am härtesten Arbeitstag meines Lebens mit der Hilfe von vielen Kollegen einmal das gesamte Rechenzentrum von web.</description>
    </item>
    
    <item>
      <title>MySQL Consulting Bootcamp Munich 2005</title>
      <link>https://blog.koehntopp.info/2005/09/10/mysql-consulting-bootcamp-munich-2005.html</link>
      <pubDate>Sat, 10 Sep 2005 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2005/09/10/mysql-consulting-bootcamp-munich-2005.html</guid>
      <description>Hinter mir liegt eine Woche MySQL Consulting Bootcamp Munich 2005. Für mich eine Woche mit Intensivkursen in MySQL 5, Performanceoptimierung und MySQL Cluster - wir haben das Schlungsprogramm, das sonst mehr als zwei Wochen abgewickelt wird, in 5 Tagen durchgezogen. Nebenbei habe ich noch das MySQL 4 Core und Pro Exam abgelegt (Ergebnisse liegen noch nicht vor, aber ich fand die Prüfung ziemlich schwierig), und wir waren an 5 Tagen zirka viermal in verschiedenen Bierhallen, Biergärten oder im Hofbräuhaus.</description>
    </item>
    
    <item>
      <title>Change Request</title>
      <link>https://blog.koehntopp.info/2005/07/26/change-request.html</link>
      <pubDate>Tue, 26 Jul 2005 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2005/07/26/change-request.html</guid>
      <description>Changekoordinator: kris@webde-ag.de (Kristian Köhntopp) ID Change Request: 30726 Eingangsdatum: 25.07.2005  Titel: Deinstallation Kristian Köhntopp/Senior Security Engineer
Projektnummer: entfällt
Beschreibung: Deinstallation des Prozesses Senior Security Engineer von Kristian Köhntopp; Begründung: Installation des Prozesses &amp;ldquo;MySQL Consulting&amp;rdquo; auf dieser Hardware
Betroffene Teams/Abteilungen: IT, SE, Abuse, Legal, Presse, Freemail, Portal; Priorität: plangemäß, hoch
Externe Abhängigkeiten: MySQL AB; Abhängigkeiten von anderen Changes: Der Risikomanagementprozess ist mit fast allen anderen Prozessen im Unternehmen gekoppelt. Er muss auf Ersatzhardware installiert werden.</description>
    </item>
    
    <item>
      <title>MySQL und die Lizenzen</title>
      <link>https://blog.koehntopp.info/2004/03/14/mysql-und-die-lizenzen.html</link>
      <pubDate>Sun, 14 Mar 2004 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2004/03/14/mysql-und-die-lizenzen.html</guid>
      <description>Früher war alles besser. Früher zum Beispiel konnte MySQL gar nichts, und der Server stand unter der GPL , während der MySQL Client unter der LGPL stand und alles war gut. So gut, daß zum Beispiel das PHP Projekt den MySQL Client den PHP-Sourcen beigelegt hatte und daß man deswegen Mühe hatte, ein PHP zu finden, das nicht mit einer MySQL-Datenbank reden konnte. Dieses Bundling ist es unter anderem gewesen, das den Siegeszug der LAMP Plattform begründet hat.</description>
    </item>
    
  </channel>
</rss>
