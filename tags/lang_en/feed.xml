<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>lang_en on Die wunderbare Welt von Isotopp</title>
    <link>https://blog.koehntopp.info/tags/lang_en.html</link>
    <description>Recent content in lang_en on Die wunderbare Welt von Isotopp</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Oct 2023 20:59:09 +0000</lastBuildDate><atom:link href="https://blog.koehntopp.info/tags/lang_en/feed.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Fertig gelesen: Starter Villain</title>
      <link>https://blog.koehntopp.info/2023/10/01/fertig-gelesen-starter-villain.html</link>
      <pubDate>Sun, 01 Oct 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/10/01/fertig-gelesen-starter-villain.html</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://mastodon.social/@scalzi&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;John Scalzi&amp;rsquo;s&lt;/a&gt;

 latest book is currently
&lt;a href=&#34;https://www.amazon.de/Starter-Villain-turbo-charged-supervillains-minions-ebook/dp/B0BJDXRGX8&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Starter Villain&lt;/a&gt;

.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/10/starter-villain.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;The premise is simple: Charlie&amp;rsquo;s estranged Uncle Jake died.
Charlie and his uncle are estranged because Charlie&amp;rsquo;s father and Jake had a fallout at the funeral of Charlie&amp;rsquo;s mom,
and Charlie has not had much contact at all with Jake ever since.
Now, with Jake also dead, it turns out that Charlie somehow is his only heir.&lt;/p&gt;
&lt;p&gt;Then Charlie is holding watch at Jake&amp;rsquo;s funeral, and the entire story turns quickly into a James Bond novel,
with strange brutes trying to stab the corpse of Jake, ensuring he&amp;rsquo;s really dead,
and a collection of very weirdly imprinted flower bouquets &amp;ndash; &amp;ldquo;See you in hell&amp;rdquo; being one of the nicer ones.&lt;/p&gt;
&lt;p&gt;Charlie quickly learns that his uncle was a Villain, complete with a lair on a volcano island,
laser weapons to destroy satellites, and a collection of very nice and special cats (and Dolphins, but they are special and not nice).
He also learns that &amp;ldquo;Villain&amp;rdquo; does not exactly mean what he thinks that it means.&lt;/p&gt;
&lt;p&gt;Scalzi spent his pages playing nicely with the clich√©s and expectations around James-Bond-like supervillains,
and turning them into a fun story with a number of expected and unexpected twists.
He wouldn&amp;rsquo;t be Scalzi if there is no stuff to think about lurking in the background.
In this case, fairly obviously the relationship between 1950&amp;rsquo;s supervillains and present day billionaires, oligarchs
and our survival as a species.&lt;/p&gt;
&lt;p&gt;A nice two-afternoon read.&lt;/p&gt;
&lt;p&gt;&amp;ldquo;&lt;a href=&#34;https://www.amazon.de/Starter-Villain-turbo-charged-supervillains-minions-ebook/dp/B0BJDXRGX8&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Starter Villain&lt;/a&gt;

&amp;rdquo;,
John Scalzi, EUR 9,99.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fertig gelesen: A Life with Footnotes</title>
      <link>https://blog.koehntopp.info/2023/09/30/fertig-gelesen-a-life-with-footnotes.html</link>
      <pubDate>Sat, 30 Sep 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/09/30/fertig-gelesen-a-life-with-footnotes.html</guid>
      <description>&lt;p&gt;Rob Wilkins was the assistant and a good friend of Terry Pratchett.
He wrote a posthumous biography, titled
&lt;a href=&#34;https://www.amazon.de/gp/product/B09R2B8J17&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;A Life With Footnotes&lt;/a&gt;

.
Wilkins is now the manager of the Pratchett literary estate.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/09/pratchett.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;The book does what a biography is supposed to do:
It traces the life of Terry Pratchett,
illuminating his origins and the experiences that shaped his worldview.
Filled with anecdotes and tales from his readings, from conventions, and other encounters with fans,
it sketches a portrait of a lovable, quirky personality who crafted stories in his mind and then simply penned them down.&lt;/p&gt;
&lt;p&gt;Rob Wilkins then takes on the challenging segment of the biography and guides us through the tragic phase of Terry Pratchett:
his Alzheimer&amp;rsquo;s diagnosis, the mental and physical decline, the ever-increasing loss of control, and the interplay of good and bad days,
leading up to the emotional farewell that occurred long before his physical passing.&lt;/p&gt;
&lt;p&gt;&amp;ldquo;&lt;a href=&#34;https://www.amazon.de/gp/product/B09R2B8J17&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Terry Pratchett: A Life With Footnotes&lt;/a&gt;

&amp;rdquo;, Rob Wilkins, EUR 9,49.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fertig gelesen: Combat Ready Kitchen</title>
      <link>https://blog.koehntopp.info/2023/09/29/fertig-gelesen-combat-ready-kitchen.html</link>
      <pubDate>Fri, 29 Sep 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/09/29/fertig-gelesen-combat-ready-kitchen.html</guid>
      <description>&lt;p&gt;In &lt;a href=&#34;https://www.amazon.de/gp/product/B00TY3ZOQE&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Combat Ready Kitchen&lt;/a&gt;

,
Anastacia Marx de Salcedo traces the history of food preservation from an american point of view,
and demonstrates the co-development of combat rations and modern U.S. supermarket food.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/09/combat-ready.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;The book takes us through the history of U.S. combat rations, from before the invention of the tin can, through canned,
better preserved, but incredibly heavy food to what soldiers have today.
It shows how these military innovations have been seeded, purposefully, into the civilian food industry,
in order to enable the military to source food from civilian companies for their purposes, in formats that suit them.
This also had influence on how the industry preserves food for civilian consumption and enabled a multitude of convenience foods.&lt;/p&gt;
&lt;p&gt;While the development of food preservation for military and civilian needs was somewhat systematic,
the book is not.
It goes through the history not chronologically, but anecdotally, roughly ordered by kind of food,
but with plenty of sidelines, side stories and other distractions.
It still is an entertaining read, but it makes it hard to put down the book and take stock of what you just learned.&lt;/p&gt;
&lt;p&gt;One thing I took away is that food preservation as we understand it today is much more recent than most people think.
It is a thing humanity only learned in the late 80ies and early 90ies, and even today fundamental progress is being made.
Also, a lot of the stuff we do is not actually bad for the food, the nutrients or the taste,
it is in fact perfectly fine.
Still, other things amount to basically breaking down the food to constituent parts, and then reassembling something
from the parts, and that&amp;rsquo;s maybe less good, given how little we actually understand what makes a meal nourishing or healthy,
even today.&lt;/p&gt;
&lt;p&gt;Entertaining and interesting, but structured in a way that makes it harder than necessary for me to pull value out of it.&lt;/p&gt;
&lt;p&gt;&amp;ldquo;&lt;a href=&#34;%28https://www.amazon.de/gp/product/B00TY3ZOQE%29&#34;&gt;Combat Ready Kitchen: How the U.S. Military Shapes The Way You Eat&lt;/a&gt;

&amp;rdquo;,
Anastacia Marx de Salcedo, EUR 5.25.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fertig gelesen: Blue Machine</title>
      <link>https://blog.koehntopp.info/2023/09/26/fertig-gelesen-blue-machine.html</link>
      <pubDate>Tue, 26 Sep 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/09/26/fertig-gelesen-blue-machine.html</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://fediscience.org/@helenczerski&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Helen Czerski&lt;/a&gt;

 wrote a book.
&lt;a href=&#34;https://www.amazon.de/Blue-Machine-Ocean-Shapes-English-ebook/dp/B0BCTPP3DH&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Blue Machine: How the ocean shapes our world&lt;/a&gt;


occupies the weird space between memoir, travel blog and science outreach.&lt;/p&gt;
&lt;p&gt;In the middle of this she manages to explain the biggest machine on our planet:
The collection of oceans in which the continents are embedded.
But also the deep love of science, the desire to understand how our world functions,
and the connection between all people than live on it.&lt;/p&gt;
&lt;p&gt;The book is the story of a person who literally travelled the world, from the poles to the equator,
and from the surface of the oceans to their dark cold depths.
It also is the story of a physicist with knowledge about bubbles and how they work,
and how that line of research led her around the world, and into the oceans.
It also is a gentle introduction into climate science,
showing us how the ocean can be seen as a machine that manages the thermals of the planet,
capturing and transporting heat, feeding the weather machine in the atmosphere with energy and water vapor,
and also capturing and releasing carbon dioxide.&lt;/p&gt;
&lt;p&gt;Following her travels and experiences, we learn about the vertical layering structure of the oceans,
about the ability of water to capture fantastic amounts of energy,
about currents and how they transport water, energy, nutrients and life around the world,
and how humans have been living off all this on the surface of something much greater, deeper and larger than we ever imagined.&lt;/p&gt;
&lt;p&gt;This is an amazing and entertaining book that shares a unique and personal perspective of our world,
and at the same time manages to convey how something this vast and enormous can be at the same time fragile and in need our or care and understanding.&lt;/p&gt;
&lt;p&gt;Strongly recommended read, well worth the time.&lt;/p&gt;
&lt;p&gt;&amp;ldquo;&lt;a href=&#34;https://www.amazon.de/Blue-Machine-Ocean-Shapes-English-ebook/dp/B0BCTPP3DH&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Blue Machine&lt;/a&gt;

&amp;rdquo;, Helen Czerski, EUR 15.62&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Need for Smarter Clients</title>
      <link>https://blog.koehntopp.info/2023/09/18/the-need-for-smarter-clients.html</link>
      <pubDate>Mon, 18 Sep 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/09/18/the-need-for-smarter-clients.html</guid>
      <description>&lt;p&gt;Somebody asked me very politely on the Fedi:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Would you please post all but the first post in a thread as &amp;ldquo;unlisted&amp;rdquo;?&lt;/p&gt;
&lt;p&gt;I like to follow you, but the sum of all posts by you takes up so much space on my front page.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The answer to that request, also politely, is a firm &amp;ldquo;No.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Selection, ordering and presentation of posts is a client problem, which it has to solve, according to your configured preferences.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Of course, my client (Tusky) recognizes a thread and shows it as such.&lt;/p&gt;
&lt;p&gt;But all posts that are being sent as &amp;ldquo;public&amp;rdquo; are also shown separately on my front page.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That is an understandable problem, but not mine.&lt;/p&gt;
&lt;p&gt;I believe Tusky will also show you reposts of the same article by 17 different persons.
In total, you get to see 18 copies of that article (the original and 17 copies).
Would you ask these people to not repost because another of your followers already did that?
You would not.&lt;/p&gt;
&lt;p&gt;Tusky, and every other client must learn what it has shown previously, and to not show middle posts of threads if so desired.&lt;/p&gt;
&lt;p&gt;If we start to take care of recipient presentation preferences on the sender&amp;rsquo;s side, we are getting into an impossible situation.
The sum of all recipients has irreconcilable preferences.&lt;/p&gt;
&lt;p&gt;Also, we would end up in a &amp;ldquo;USENET-situation,&amp;rdquo; where advancement becomes impossible.
&amp;ldquo;No Umlauts, because my VT100 can&amp;rsquo;t render them.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;I can&amp;rsquo;t and won&amp;rsquo;t ever care for any client&amp;rsquo;s presentation preferences.
Get a client that can render stuff the way you want, and pay your client developers of choice to build the client you want.&lt;/p&gt;
&lt;p&gt;This network is federated, with dozens of clients.
This offers you choice and makes it impossible for me to care for you all.
If you don&amp;rsquo;t like this, please unsubscribe to my account.
The network is large, and you won&amp;rsquo;t miss my content.&lt;/p&gt;
&lt;p&gt;Thanks.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Invalid-UTF8 vs the filesystem</title>
      <link>https://blog.koehntopp.info/2023/09/14/invalid-utf8-vs-the-filesystem.html</link>
      <pubDate>Thu, 14 Sep 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/09/14/invalid-utf8-vs-the-filesystem.html</guid>
      <description>&lt;p&gt;A UNIX filename can contain arbitrary bytes in an arbitrary sequence, with two exceptions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It cannot contain NUL (&lt;code&gt;\0&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;It cannot contain slash (&lt;code&gt;/&lt;/code&gt;), because that is the directory separator.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But will all filesystems accept such filenames?
And how will this work with languages such as Python, which require all strings to be valid &lt;code&gt;utf-8&lt;/code&gt; and
which declare the filesystem interface to accept and return strings?&lt;/p&gt;
&lt;h1 id=&#34;a-test-program&#34;&gt;
    &lt;a href=&#34;#a-test-program&#34;&gt;
	A test program
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Let&amp;rsquo;s check.
Here is a small C program, based on &lt;a href=&#34;https://stackoverflow.com/questions/1301402/example-invalid-utf8-string&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this stackoverflow article&lt;/a&gt;

.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-C&#34; data-lang=&#34;C&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#include&lt;/span&gt; &lt;span class=&#34;cpf&#34;&gt;&amp;lt;stdio.h&amp;gt;&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#include&lt;/span&gt; &lt;span class=&#34;cpf&#34;&gt;&amp;lt;sys/stat.h&amp;gt;&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#include&lt;/span&gt; &lt;span class=&#34;cpf&#34;&gt;&amp;lt;unistd.h&amp;gt;&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;char&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;examples&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;a&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\xc3\xb1&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\xc3\x28&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\xa0\xa1&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\xe2\x82\xa1&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\xe2\x28\xa1&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\xe2\x82\x28&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\xf0\x90\x8c\xbc&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\xf0\x28\x8c\xbc&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\xf0\x90\x28\xbc&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\xf0\x28\x8c\x28&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\xf8\xa1\xa1\xa1\xa1&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\xfc\xa1\xa1\xa1\xa1\xa1&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;};&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;FILE&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;mkdir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;keks&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mo&#34;&gt;0755&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// don&amp;#39;t care if exists
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;chdir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;keks&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;       &lt;span class=&#34;c1&#34;&gt;// don&amp;#39;t care if succeed.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;examples&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nf&#34;&gt;printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;%s&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;examples&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;fp&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;fopen&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;examples&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;w&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nf&#34;&gt;printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;unable to open %d (%s)!&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;examples&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;k&#34;&gt;continue&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nf&#34;&gt;fprintf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;keks&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nf&#34;&gt;fclose&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;xfs&#34;&gt;
    &lt;a href=&#34;#xfs&#34;&gt;
	XFS
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;When running this on a Linux system with XFS, this works:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/09/invalid-utf8-xfs.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The program runs and generates all files. Even those with byte sequences that are not valid utf-8.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This works the same with ext4 on Linux.&lt;/p&gt;
&lt;h2 id=&#34;zfs&#34;&gt;
    &lt;a href=&#34;#zfs&#34;&gt;
	ZFS
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;When running this on a Linux system with ZFS, filenames containing invalid utf-8 sequences are rejected.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/09/invalid-utf8-zfs.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The program runs and generates files with valid utf-8 names. The &lt;code&gt;open(2)&lt;/code&gt; syscall fails for names with invalid utf-8 filenames.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;apfs&#34;&gt;
    &lt;a href=&#34;#apfs&#34;&gt;
	APFS
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;When running this on a MacOS Ventura system with APFS, filenames containing invalid utf-8 sequences are rejected.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/09/invalid-utf8-apfs.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The program runs and generates files with valid utf-8 names. The &lt;code&gt;open(2)&lt;/code&gt; syscall fails for names with invalid utf-8 filenames.&lt;/em&gt;&lt;/p&gt;
&lt;h1 id=&#34;unpacking-invalid-utf-8-filenames-with-python&#34;&gt;
    &lt;a href=&#34;#unpacking-invalid-utf-8-filenames-with-python&#34;&gt;
	Unpacking invalid utf-8 filenames with Python
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;I went and creates a &lt;code&gt;tar&lt;/code&gt; archive of the files generated on XFS and copied it over to my Mac.&lt;/p&gt;
&lt;p&gt;The following test program was used to unpack the &lt;code&gt;tar&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;ch&#34;&gt;#! /usr/bin/env python&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;tarfile&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;TarFile&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;chardet&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;os&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;TarFile&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;test.tar&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;r&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;names&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;getnames&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;names&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;bname&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;bytearray&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;raw&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;chardet&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;detect&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The test run fails:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;(venv) $ python tarnames.py
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;Traceback (most recent call last):
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;  File &amp;#34;.../tarnames.py&amp;#34;, line 15, in &amp;lt;module&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;    bname = bytearray(name, &amp;#39;raw&amp;#39;)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;            ^^^^^^^^^^^^^^^^^^^^^^
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;LookupError: unknown encoding: raw
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;intermediate-result&#34;&gt;
    &lt;a href=&#34;#intermediate-result&#34;&gt;
	Intermediate result
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;It probably is useful to restrict POSIX further and demand that filenames are always valid utf-8.
But that is not what the standard currently says, and also not what all filesystems guarantee.
And it can lead to unexpected behavior.&lt;/p&gt;
&lt;p&gt;Also, some programming languages such as Python demand of strings that they have valid utf-8 encoding,
but use filenames and strings equivalently.&lt;/p&gt;
&lt;p&gt;That can lead to weird behavior.&lt;/p&gt;
&lt;h1 id=&#34;further-research&#34;&gt;
    &lt;a href=&#34;#further-research&#34;&gt;
	Further research
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Apparently there is a function
&lt;a href=&#34;https://docs.python.org/3/library/sys.html#sys.getfilesystemencoding&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;sys.getfilesystemencoding()&lt;/code&gt;&lt;/a&gt;


without parameters.
Python seems to assume that all filesystems have the same encoding and that it is not path dependent.&lt;/p&gt;
&lt;p&gt;Apparently there are &lt;code&gt;os.fsencode()&lt;/code&gt; and
&lt;a href=&#34;https://docs.python.org/3/library/os.html#os.fsencode&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;os.fsdecode()&lt;/code&gt;&lt;/a&gt;

.&lt;/p&gt;
&lt;h2 id=&#34;modified-python-code&#34;&gt;
    &lt;a href=&#34;#modified-python-code&#34;&gt;
	Modified Python code
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;We are using &lt;code&gt;os.fsencode()&lt;/code&gt; to get &lt;code&gt;bytes&lt;/code&gt; from the filesystem interface.
We are then using &lt;code&gt;chardet.detect()&lt;/code&gt; on this byte-string and check the guesses.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;ch&#34;&gt;#! /usr/bin/env python&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;tarfile&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;TarFile&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;chardet&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;os&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;TarFile&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;test.tar&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;r&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;names&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;getnames&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;names&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;bname&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fsencode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bname&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;=}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;chardet&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;detect&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bname&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The result:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;bname=b&amp;#39;keks&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;{&amp;#39;encoding&amp;#39;: &amp;#39;ascii&amp;#39;, &amp;#39;confidence&amp;#39;: 1.0, &amp;#39;language&amp;#39;: &amp;#39;&amp;#39;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;bname=b&amp;#39;keks/a&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;{&amp;#39;encoding&amp;#39;: &amp;#39;ascii&amp;#39;, &amp;#39;confidence&amp;#39;: 1.0, &amp;#39;language&amp;#39;: &amp;#39;&amp;#39;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;bname=b&amp;#39;keks/\xc3\xb1&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;{&amp;#39;encoding&amp;#39;: &amp;#39;ISO-8859-1&amp;#39;, &amp;#39;confidence&amp;#39;: 0.73, &amp;#39;language&amp;#39;: &amp;#39;&amp;#39;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;bname=b&amp;#39;keks/\xc3(&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;{&amp;#39;encoding&amp;#39;: &amp;#39;ISO-8859-1&amp;#39;, &amp;#39;confidence&amp;#39;: 0.73, &amp;#39;language&amp;#39;: &amp;#39;&amp;#39;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;bname=b&amp;#39;keks/\xa0\xa1&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;{&amp;#39;encoding&amp;#39;: &amp;#39;IBM866&amp;#39;, &amp;#39;confidence&amp;#39;: 0.99, &amp;#39;language&amp;#39;: &amp;#39;Russian&amp;#39;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;bname=b&amp;#39;keks/\xe2\x82\xa1&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;{&amp;#39;encoding&amp;#39;: &amp;#39;Windows-1252&amp;#39;, &amp;#39;confidence&amp;#39;: 0.73, &amp;#39;language&amp;#39;: &amp;#39;&amp;#39;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;bname=b&amp;#39;keks/\xe2(\xa1&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;{&amp;#39;encoding&amp;#39;: &amp;#39;ISO-8859-1&amp;#39;, &amp;#39;confidence&amp;#39;: 0.73, &amp;#39;language&amp;#39;: &amp;#39;&amp;#39;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;bname=b&amp;#39;keks/\xe2\x82(&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;{&amp;#39;encoding&amp;#39;: &amp;#39;Windows-1252&amp;#39;, &amp;#39;confidence&amp;#39;: 0.73, &amp;#39;language&amp;#39;: &amp;#39;&amp;#39;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;bname=b&amp;#39;keks/\xf0\x90\x8c\xbc&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;{&amp;#39;encoding&amp;#39;: &amp;#39;Windows-1254&amp;#39;, &amp;#39;confidence&amp;#39;: 0.48310298982778344, &amp;#39;language&amp;#39;: &amp;#39;Turkish&amp;#39;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;bname=b&amp;#39;keks/\xf0(\x8c\xbc&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;{&amp;#39;encoding&amp;#39;: &amp;#39;Windows-1252&amp;#39;, &amp;#39;confidence&amp;#39;: 0.73, &amp;#39;language&amp;#39;: &amp;#39;&amp;#39;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;bname=b&amp;#39;keks/\xf0\x90(\xbc&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;{&amp;#39;encoding&amp;#39;: &amp;#39;Windows-1254&amp;#39;, &amp;#39;confidence&amp;#39;: 0.5521177026603239, &amp;#39;language&amp;#39;: &amp;#39;Turkish&amp;#39;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;bname=b&amp;#39;keks/\xf0(\x8c(&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;{&amp;#39;encoding&amp;#39;: &amp;#39;Windows-1252&amp;#39;, &amp;#39;confidence&amp;#39;: 0.73, &amp;#39;language&amp;#39;: &amp;#39;&amp;#39;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;bname=b&amp;#39;keks/\xf8\xa1\xa1\xa1\xa1&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;{&amp;#39;encoding&amp;#39;: &amp;#39;ISO-8859-1&amp;#39;, &amp;#39;confidence&amp;#39;: 0.73, &amp;#39;language&amp;#39;: &amp;#39;&amp;#39;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;bname=b&amp;#39;keks/\xfc\xa1\xa1\xa1\xa1\xa1&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;{&amp;#39;encoding&amp;#39;: &amp;#39;ISO-8859-1&amp;#39;, &amp;#39;confidence&amp;#39;: 0.73, &amp;#39;language&amp;#39;: &amp;#39;&amp;#39;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The guesses are trying to find a valid charset for the bytestring, and they find the lowest (least large) charset that matches.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Electric Cars and Numbers</title>
      <link>https://blog.koehntopp.info/2023/08/13/electric-cars-and-numbers.html</link>
      <pubDate>Sun, 13 Aug 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/08/13/electric-cars-and-numbers.html</guid>
      <description>&lt;p&gt;(based on a series of posts on Mastodon)&lt;/p&gt;
&lt;h1 id=&#34;i-got-an-electric-car&#34;&gt;
    &lt;a href=&#34;#i-got-an-electric-car&#34;&gt;
	I got an electric car
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;I made the driving license late in life, in 1998 at the age of 30.
My first car was a BMW 316i Coupe, used, 9000 Euro.
I drove this until 2007.
When I moved to Berlin, I found driving in the city inconvenient, and consequently used public transport.
Eventually the battery of the car died from standing around, and I sold it.&lt;/p&gt;
&lt;p&gt;In 2010, I became a father, and we bought a new car, a Renault Sc√©nic Grande 7-seater.
This is a car made from cupholders and small compartments, and it served its function of
&amp;ldquo;Moving the family around, including Grandma&amp;rdquo; quite well.
Nothing Renault makes lasts longer than 15 years, though, and so the thing was showing signs of age.&lt;/p&gt;
&lt;p&gt;Also,
&lt;a href=&#34;https://blog.koehntopp.info/2023/05/11/city-of-amsterdam-and-combustion-engines.html&#34;&gt;the City of Amsterdam changes the rules&lt;/a&gt;


of how to get into the city, and the old Scenic soon would be unable to get into the city.
So, an electric car was needed.&lt;/p&gt;
&lt;p&gt;I tried to like the BYD Dolphin, but that car comes only with seats where the headrest is fixed and cannot be adjusted.
At my size, that means the headrest sits somewhere at my lower shoulder blades.
I asked for advice, and the BYD salesperson just pointed at the BYD Tank, a monstrous SUV.
That had adjustable headrests for sure, but you wouldn&amp;rsquo;t want to drive such a thing inside Amsterdam&amp;rsquo;s city limits.&lt;/p&gt;
&lt;p&gt;So Renault again, this time a Megane e-tech, with a 60 kWh battery, and some 16 kWh/100 km energy use.
Also, apparently some 160 kW engine (peak power), which really is a 55 kW engine (sustained power).&lt;/p&gt;
&lt;p&gt;These are weird units for energy and power for most people.&lt;/p&gt;
&lt;p&gt;What do they even mean and how can we imagine them?&lt;/p&gt;
&lt;h1 id=&#34;everything-in-kwh&#34;&gt;
    &lt;a href=&#34;#everything-in-kwh&#34;&gt;
	Everything in kWh
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Back in the day, we had incandescent light bulbs, and the standard thing everybody my age can imagine is the 100 W bulb.
It was as bright as a modern 14W LED light today.
Running the 100 W lamp for one hour uses 100 Wh of energy, running it for 10 hours is 1000 Wh, or 1 kWh.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/08/100W.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;A 100 W incandescent bulk, &lt;a href=&#34;https://en.wikipedia.org/wiki/File:Gluehlampe_01_KMJ.png&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;as shown in Wikipedia&lt;/a&gt;

.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Watts are power (&amp;ldquo;Leistung&amp;rdquo; in German), and Watt-Hours are energy
(&amp;ldquo;Energie,&amp;rdquo; &amp;ldquo;Arbeit&amp;rdquo; in German.
&amp;ldquo;Leistung ist Arbeit pro Zeit&amp;rdquo; as my math teacher used to say to people who did not complete their test in time).&lt;/p&gt;
&lt;h2 id=&#34;solar-energy&#34;&gt;
    &lt;a href=&#34;#solar-energy&#34;&gt;
	Solar Energy
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;The sun shining on Germany on a bright day delivers 1 kW per m^2, so 1 h of sunshine is an irradiation of 1 kWh/qm.
Solar cells currently have an efficiency of 20%, so 1000 W of irradiation become 200 W of electricity,
the other 800 W become heat or are reflected.&lt;/p&gt;
&lt;p&gt;Such a 1 m^2 solar array would have an installed peak capacity of 200 Wp (&amp;ldquo;Watt peak,&amp;rdquo; or &amp;ldquo;Nennleistung&amp;rdquo; in German).
Five of those would deliver 1 kWp, and produce around 950 kWh of energy per year, under optimal conditions.&lt;/p&gt;
&lt;p&gt;In fact, 46 m^2 of my roof are covered in solar panels.
&lt;a href=&#34;https://blog.koehntopp.info/2022/05/02/a-solar-roof.html&#34;&gt;That&amp;rsquo;s 9250 Wp&lt;/a&gt;

,
which under this formula should produce up to 8780 kWh/year.&lt;/p&gt;
&lt;p&gt;They did, in fact, deliver 8000-ish kWh/year, from June 2022 to June 2023.
To compare, we used 5500 kWh of electricity in the year before we got the Solar panels.&lt;/p&gt;
&lt;h2 id=&#34;fuels-and-energy&#34;&gt;
    &lt;a href=&#34;#fuels-and-energy&#34;&gt;
	Fuels and Energy
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;When I was little, a car&amp;rsquo;s power was given in HP (Horsepower).
Today we use kW, but many people will still list HP in parentheses for old people&amp;rsquo;s convenience.&lt;/p&gt;
&lt;p&gt;1000 W are ~1 ‚Öì HP, or 1 HP are ~750 W.
Drive that for one hour, and you have used 1 kWh.&lt;/p&gt;
&lt;p&gt;Conveniently, the energy content of many fuels is almost decimal.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Fuel&lt;/th&gt;
&lt;th&gt;kWh&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1l Diesel&lt;/td&gt;
&lt;td&gt;9.7 kWh, ~10 kWh&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1l Benzine&lt;/td&gt;
&lt;td&gt;8.5 kWh&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1 m^3 Natural Gas&lt;/td&gt;
&lt;td&gt;10-12 kWh, ~10 kWh&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;em&gt;Almost metric: 1 m^3 of Gas or 1 l of Diesel each has an energy content of 10 kWh.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;So if your old Scenic Diesel uses 6.7l Diesel on 100 km, it has used around 66 kWh of energy.
A combustion engine car is around 33% efficient.&lt;/p&gt;
&lt;p&gt;So of these 66 kWh, around 22 kWh have been used to drive the distance.
The rest is waste heat.&lt;/p&gt;
&lt;p&gt;The new Megane uses 16 kWh for 100 km, so that is the energetic equivalent of 1.8l Benzine or 1.6l Diesel.
Times three, to account for combustion engine losses.&lt;/p&gt;
&lt;h2 id=&#34;other-energy-units&#34;&gt;
    &lt;a href=&#34;#other-energy-units&#34;&gt;
	Other energy units
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Calories (actually kilocalories, kcal) are known to many people as units for energy content of food.
A kilo of body fat is 7700 kcal, and that&amp;rsquo;s 8.9 kWh.
So 11.2 kilos of dad bod are 100 kWh.
Take that, Tesla.&lt;/p&gt;
&lt;p&gt;This is not theoretical energy at all, as
&lt;a href=&#34;https://www.youtube.com/watch?v=Vps_8dnnU_M&amp;amp;t=474s&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;S4E8 Mythbusters: Salami Rocket&lt;/a&gt;


has demonstrated.&lt;/p&gt;
&lt;p&gt;A bar of Milka chocolate has around 0.6 kWh.
So charging a 60 kWh car battery is around 100 Milka bars of energy content.&lt;/p&gt;
&lt;p&gt;If you are driving a Diesel at 6l/100 km, you burn 60 kWh of energy content, or around one bar of Milka per Kilometer.
Things become very conveniently convertible if everything is kW and kWh.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bergfreunde.de/kalorienverbrauch-sport-rechner/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bergfreunde&lt;/a&gt;

 has a human activity energy calculator,
which covers anything from Walking to Sex.
8h of walking for a fat old man will burn 3350 kcal, or 3.9 kWh.
Assuming 6 km/h, we will burn 8.1 kWh/100 km.
That is less than the Megane, but more than the Carver.
And a lot more than biking.&lt;/p&gt;
&lt;h2 id=&#34;long-distance-driving-and-charging&#34;&gt;
    &lt;a href=&#34;#long-distance-driving-and-charging&#34;&gt;
	Long Distance driving and charging
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;If you run your electric vehicle for long distances, you will observe that the last 20% of charge,
from 80% to 100%, take longer than the rest.
That is because batteries take energy quickly as long as they are empty, and the final 20% charge particularly slowly.&lt;/p&gt;
&lt;p&gt;Most people do not wait for a full charge, but charge to 80%-ish and then continue to drive.
They also won&amp;rsquo;t drive the car down to 0%.&lt;/p&gt;
&lt;p&gt;So at an energy use of 16-20 kWh/100 km at a speed of 100 km/h, you will be driving for about 2-2.5 hours until the battery runs empty.
Then the car will need to charge, and because you are on the Autoahn, you&amp;rsquo;ll be using a fast charger.
That will bring the car to 80% in around 30 minutes, sufficient to pee and get a coffee.&lt;/p&gt;
&lt;p&gt;This is the rhythm of the electric long distance drive:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Start SoC&lt;/th&gt;
&lt;th&gt;End SoC&lt;/th&gt;
&lt;th&gt;Time&lt;/th&gt;
&lt;th&gt;Energy Stored&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;29 %&lt;/td&gt;
&lt;td&gt;80%&lt;/td&gt;
&lt;td&gt;32 min&lt;/td&gt;
&lt;td&gt;30.20 kWh&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;9%&lt;/td&gt;
&lt;td&gt;80%&lt;/td&gt;
&lt;td&gt;37 min&lt;/td&gt;
&lt;td&gt;42.15 kWh&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;em&gt;Carging at a DC fast charger on the Autobahn.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;at-home-and-charging&#34;&gt;
    &lt;a href=&#34;#at-home-and-charging&#34;&gt;
	At home, and charging
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/08/ladepunkt.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;11 KW charge point as it is installed in public spaces all over the country in the Netherlands
(&lt;a href=&#34;https://nl.wikipedia.org/wiki/Oplaadpunt#/media/Bestand:Oplaadpaal_Utrecht.jpg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wikipedia&lt;/a&gt;

).&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;At home, you won&amp;rsquo;t be using a DC fast charger, but will be using an AC 11 kW charger.
On this, the car goes from 31% to 80% in 3h:10m.
A 22 kW charger would be twice as fast, but likely pointless.&lt;/p&gt;
&lt;p&gt;An 11 kW charger is always sufficiently fast to charge up completely in reasonable time.
And if not, sufficient to get to a SoC where you can drive to the Autobahn safely,
and then use a DC fast charger to charge up really fast.&lt;/p&gt;
&lt;h2 id=&#34;driving-accelerating-and-braking&#34;&gt;
    &lt;a href=&#34;#driving-accelerating-and-braking&#34;&gt;
	Driving, Accelerating and Braking
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;When you are driving a constant speed on a flat surface,
you are using the exact amount of energy needed to counteract wind resistance.
So if your car&amp;rsquo;s display reads &amp;ldquo;16 kW current energy use&amp;rdquo;, you are using 16 kW/21 HP to keep the current speed.
That is about as much as the engine power of an old 1978 Renault 4 (or a Citroen 2CV).&lt;/p&gt;
&lt;p&gt;The Megane has a more powerful engine, but only to accelerate nicely,
and then it will even reach the catalog power of &amp;ldquo;160 kW&amp;rdquo; &amp;ndash; for a short time.&lt;/p&gt;
&lt;p&gt;Well, the Megane also has a more powerful engine for better recuperation,
using the engine to convert kinetic energy back to electricity, and storing it back into the battery.
The limit for that is 60 kW, &amp;ldquo;accidentally&amp;rdquo; close to the sustained power of the engine.&lt;/p&gt;
&lt;p&gt;This is also a good case for a speed limit in the only country in Europa that has none:
In the Netherlands there is a 100 km/h speed limit (at night sometimes 120 km/h),
and that leads to extremely equalized car speeds on the Autobahn.&lt;/p&gt;
&lt;p&gt;You basically turn on cruise control, set it to 100 and are done with it.&lt;/p&gt;
&lt;p&gt;In Germany, you might set the Megane to 120 km/h, turn on as many assistance systems as possible
and switch mentally into Fuck-You mode, but you will still have to accelerate and decelerate more,
because speeds on the German Autobahn vary a lot.&lt;/p&gt;
&lt;p&gt;Not only does this make driving dangerous,
it also eats into your range without providing better average speeds.&lt;/p&gt;
&lt;h2 id=&#34;sustained-and-peak-power&#34;&gt;
    &lt;a href=&#34;#sustained-and-peak-power&#34;&gt;
	Sustained and Peak Power
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;The Megane is sold with a peak power of 160 kW, but the motor has a sustained power of only 55 kW.
You run it at even less, 16 kW, unless you accelerate.&lt;/p&gt;
&lt;p&gt;Air resistance is growing with larger speed, and the sustained power of the motor
basically defines the cars top speed.
But of course, this will also draw from the battery accordingly,
so you will run out of energy faster, and need to charge earlier.&lt;/p&gt;
&lt;p&gt;At 160 km/h, you will draw 55 kW, and will run out of power after 1 h.&lt;/p&gt;
&lt;p&gt;It is typical for electric motors to overdrive them.
For example, an electric locomotive rated at 4000 kW is routinely driven at 6000 kW
on initial acceleration, until it hits the thermal limit, I have been told.&lt;/p&gt;
&lt;p&gt;Also, the energy use of trains is incredibly low.
A &lt;a href=&#34;https://de.wikipedia.org/wiki/Stadler_Flirt&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Stadler Flirt&lt;/a&gt;

 uses around 330 kWh/100 km.
That&amp;rsquo;s the energy content of 30l Diesel, for a train of 60m length and 180 seats (around 300-350 people in commuter mode).
Or in other words, 5 times the energy use of a Diesel car,
so if 6 seats are occupied, it breaks even with a car (at an average occupancy of 1.2 people/car).&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/08/flirt-energy-use.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;A Flirt has drawn 1408 kWh from the overhead line, and recuperated 748 kWh, for a net energy use of 660 kWh.
At the Konstanz-Stuttgart Line (200 km), this equals 330 kWh/100 km, or around 39l of Benzine (or 34l of Diesel) in energy content.&lt;/em&gt;&lt;/p&gt;
&lt;h1 id=&#34;tldr&#34;&gt;
    &lt;a href=&#34;#tldr&#34;&gt;
	TL;DR
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;We can convert all kinds of energy into kWh, and use this to compare energy production and consumption.
This is convenient, because typical fuels happen to align somewhat with the metric system:
1 l of Diesel or 1 m^3 of Natural Gas both have each 10 kWh of energy content.
For fun, we can also do this with Milka Chocolate bars (0.6 kWh stored energy content)
or with Pizza (around 1 kWh per Europizza).&lt;/p&gt;
&lt;p&gt;We can do the same thing with power, and kW, and since power times time is energy,
we can also easily convert energy draw over time into battery depletion, and plan trips.&lt;/p&gt;
&lt;p&gt;Getting fluent with units and conversions helps us to develop a feel for range, speed, energy and cost.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ubuntu: systemctl --user does not work</title>
      <link>https://blog.koehntopp.info/2023/07/12/ubuntu-systemctl-user-does-not-work.html</link>
      <pubDate>Wed, 12 Jul 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/07/12/ubuntu-systemctl-user-does-not-work.html</guid>
      <description>&lt;p&gt;Memo to self:
I have a VPS with a legacy Ubuntu 20.04, and when creating a user to run a user-based service,
trying to use systemctl fails with the message:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ systemctl --user status
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Failed to connect to bus: No such file or directory
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To solve this, multiple changes were necessary:&lt;/p&gt;
&lt;h1 id=&#34;fixing-the-systemd-problem&#34;&gt;
    &lt;a href=&#34;#fixing-the-systemd-problem&#34;&gt;
	Fixing the &lt;code&gt;systemd&lt;/code&gt; problem
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;The service is supposed to run as the user &lt;code&gt;theservice&lt;/code&gt;, from the directory &lt;code&gt;/home/theservice/therepo&lt;/code&gt;,
and is to be controlled by a systemd instance for this user.
There was no such instance running.&lt;/p&gt;
&lt;h2 id=&#34;missing-packages&#34;&gt;
    &lt;a href=&#34;#missing-packages&#34;&gt;
	Missing packages
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Several required packages were not installed (server image, minimal packages installed):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# apt install dbus-user-session libpam-systemd libpam-cgfs&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;loginctl-config-not-correct&#34;&gt;
    &lt;a href=&#34;#loginctl-config-not-correct&#34;&gt;
	&lt;code&gt;loginctl&lt;/code&gt; config not correct
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Loginctl needs to be told what to do when the user is not logged in:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# loginctl enable-linger theservice&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;missing-environment-variables&#34;&gt;
    &lt;a href=&#34;#missing-environment-variables&#34;&gt;
	Missing environment variables
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Two environment variables were not defined properly:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ cat ~/.bashrc 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# ~/.bashrc: executed by bash(1) for non-login shells.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# see /usr/share/doc/bash/examples/startup-files (in the package bash-doc)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# for examples&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# THIS INSERTED vvv&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;XDG_RUNTIME_DIR&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;/run/user/&lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;id -u&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;DBUS_SESSION_BUS_ADDRESS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;unix:path=&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;XDG_RUNTIME_DIR&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;/bus&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# THIS INSERTED ^^^&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# If not running interactively, don&amp;#39;t do anything&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;case&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;$-&lt;/span&gt; in
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    *i*&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      *&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;esac&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; As you can see in the &lt;code&gt;case&lt;/code&gt; statement and the comment before, the remainder of the &lt;code&gt;.bashrc&lt;/code&gt; is
only run for interactive shells.
The variable definitions must appear before the &lt;code&gt;case&lt;/code&gt; statement, as shown.&lt;/p&gt;
&lt;h2 id=&#34;userservice-not-enabled-and-started&#34;&gt;
    &lt;a href=&#34;#userservice-not-enabled-and-started&#34;&gt;
	&lt;code&gt;user@.service&lt;/code&gt; not enabled and started
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;The user-based &lt;code&gt;systemd&lt;/code&gt; component was not enabled and started.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# systemctl enable user@.service&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# systemctl start user@1011.service    # the userid of the user I needed&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;defining-the-service&#34;&gt;
    &lt;a href=&#34;#defining-the-service&#34;&gt;
	Defining the service
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;The service we want to run is a Python program in a virtual environment,
logging to stdout and stderr.
It needs to be started by &lt;code&gt;systemd&lt;/code&gt; as the service user.&lt;/p&gt;
&lt;p&gt;We check out the repo and create virtual environment:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# sudo -Hi theserviceuser&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ git checkout git@github.com:theuser/therepo.git
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ python3 -m venv venv
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ &lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt; venv/bin/activate
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ pip install -r requirements.txt
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This will check out the source, create a &lt;code&gt;venv&lt;/code&gt; and then activate it and install the requirements.&lt;/p&gt;
&lt;p&gt;We can now create a service.
As the service user, run &lt;code&gt;systemctl --user edit --full theservice.service&lt;/code&gt; and install&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-systemd&#34; data-lang=&#34;systemd&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c&#34;&gt;# /home/theserviceuser/.config/systemd/user/theservice.service&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;[Unit]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;na&#34;&gt;Description&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;The Service&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;na&#34;&gt;After&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;syslog.target network.target&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;[Service]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;na&#34;&gt;Type&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;simple&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;na&#34;&gt;WorkingDirectory&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;/home/theserviceuser/therepo&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;na&#34;&gt;ExecStart&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;/home/theserviceuser/therepo/venv/bin/python3 /home/theserviceuser/therepo/main.py&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;na&#34;&gt;Restart&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;on-abort&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;na&#34;&gt;EnvironmentFile&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;/home/theserviceuser/therepo/.env&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;[Install]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;na&#34;&gt;WantedBy&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;multi-user.target&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;By using the Python instance from the &lt;code&gt;venv&lt;/code&gt;, we will automatically use stuff from the &lt;code&gt;venv&lt;/code&gt;, no activation required.&lt;/p&gt;
&lt;p&gt;We can now update all this with&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ systemctl --user stop theservice.service
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ git pull --rebase
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ systemctl --user start theservice.service
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;or a script that does the same.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MySQL: InnoDB Fragmentation</title>
      <link>https://blog.koehntopp.info/2023/07/06/mysql-innodb-fragmentation.html</link>
      <pubDate>Thu, 06 Jul 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/07/06/mysql-innodb-fragmentation.html</guid>
      <description>&lt;p&gt;There is a really nice article by Pep Pla, over at
&lt;a href=&#34;https://www.percona.com/blog/the-impacts-of-fragmentation-in-mysql/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;the Percona blog&lt;/a&gt;


about fragmentation in MySQL InnoDB tablespaces, which you should read.&lt;/p&gt;
&lt;p&gt;The article discusses &amp;ldquo;fragmentation&amp;rdquo; of data in tables, which happens in a way similar to how it happens in filesystems.&lt;/p&gt;
&lt;p&gt;InnoDB stores data by default in tablespaces, which by default are a file per table.
These files are subject to the fragmentation and growth rules of your filesystem,
but if you are smart, you are running MySQL on Linux on the XFS.
In that case, filesystem fragmentation (and unexplained commit latency variance) are not an issue,
because XFS takes care of handling this properly, and only database-internal fragmentation remains.&lt;/p&gt;
&lt;h1 id=&#34;primary-keys-data-order-and-working-set-size&#34;&gt;
    &lt;a href=&#34;#primary-keys-data-order-and-working-set-size&#34;&gt;
	Primary keys, data order and working set size
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Data inside an InnoDB tablespace is placed in primary key order, and that used to matter a lot,
because rows with closer primary keys used to be stored closer together on disk.
Up to the point where rows with adjacent primary keys had a good chance of being on the same page.&lt;/p&gt;
&lt;p&gt;In the past, it mattered more than today, because even if data was not stored on the same page,
pages that were physically stored closely together (on the same HDD track or cylinder) could be loaded faster.
That was the case, since &amp;ldquo;near&amp;rdquo; disk seeks were executed faster by an HDD than &amp;ldquo;far&amp;rdquo; disk seeks across the entire surface of a hard disk.&lt;/p&gt;
&lt;p&gt;With flash, seek times are largely irrelevant:
In fact, the internal Flash Translation Layer of flash storage will put data anywhere it sees fit,
and then issue you a Logical Block Address (LBA) that has no bearing whatsoever on the actual physical location of the page on the flash drive.
It may even move the actual physical data under you behind the scenes, and still refer to it by the same LBA.&lt;/p&gt;
&lt;p&gt;What matters a lot as a concept, though, is the Working Set Size (WSS) of your database.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The Working Set is the set of pages your database is going to reference in the next future interval&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This interval may be, for example, the next 1m, 10m or 1h.
That is, it makes initially limited sense to speak of the WSS as an unqualified term.
You&amp;rsquo;d have to use it with an interval instead, so the WSS-1m, WSS-10m, WSS-1h and so on.&lt;/p&gt;
&lt;p&gt;If you could predict what pages will be needed in the WSS-10m, you could preload these pages and cache them.
This would bring the disk reads to zero or close to zero for the coming 10 minutes.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Predicting the future is hard, though, especially if accuracy is required.
What we do instead is look to the past and hope the future looks alike.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So most people would want to look at the past 10 minutes,
and the recorded page numbers requested from disk as a triple of &lt;code&gt;(timestamp, tablespace_id, page_number)&lt;/code&gt;.
From this, we can build a histogram for a sliding 10m window, and we would know which pages have been in demand.
From the height of the histogram counter, we would even know how much.&lt;/p&gt;
&lt;p&gt;We can now size an InnoDB buffer pool, and calculate how large this pool would have to be to cache 95%, 99%, 99.99%, &amp;hellip;
of all page read requests.
Having a handle on the desired buffer pool size for a data set and a workload would be very useful to determine the amount
of memory our database instance would need to perform adequately:
It must be sized for ‚Äì at least ‚Äì the estimated buffer pool plus overhead plus some safety margin,
rounded up to available instance types.&lt;/p&gt;
&lt;p&gt;Unfortunately, we can only get aggregate statistics from an unpatched MySQL, and no page-read-request timeline as shown above.
Neither can we get a page-request histogram from &lt;code&gt;P_S&lt;/code&gt;, or a properly precalculated WSS estimation.
So it is necessary to patch MySQL to get this data, unfortunately.&lt;/p&gt;
&lt;p&gt;When we do this, and math a bit on the results, we observe there is actually such a thing as a WSS without a time-interval:&lt;/p&gt;
&lt;p&gt;As long as the workload is stable,
we can identify with some confidence a set of pages that need to be cached in order to quench most of the reads.
Adding buffer pool pages past this point will not improve performance substantially,
and there might still be a certain number of residual random page reads due to random accesses in the workload.
In order to also quench these, you&amp;rsquo;d have to be able to keep the entire database in memory.
While this is sometimes possible, there are workloads where this is not economical, especially at cloud pricing structures.&lt;/p&gt;
&lt;h2 id=&#34;designing-for-locality&#34;&gt;
    &lt;a href=&#34;#designing-for-locality&#34;&gt;
	Designing for locality
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Here Pep Pla comes in again, because he highlights in his article the principle of locality,
which is exactly what the working set size is.
Specifically, WSS is temporal locality ‚Äì we cache the pages we will need in the future in memory,
so that spatial locality does no longer matter.
Even when using HDD.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;By choosing a primary key smartly, we can make sure that primary keys that are being accessed &amp;ldquo;together&amp;rdquo; have similar values,
and each page is filled closely with many rows that we will be needing at the same time.&lt;/p&gt;
&lt;p&gt;For a fixed data size, this lowers the number of pages active concurrently, bringing down WSS size,
bringing down pool size, bringing down instance size, bringing down cloud cost.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Also, it is important to keep the row size down, so many rows fit into the same page,
and finally getting a handle on fragmentation inside a page ‚Äì but this is actually the least important factor in design.&lt;/p&gt;
&lt;p&gt;For the various MySQL flavors, exposing disk read request traces (as &lt;code&gt;(ts, tablespace_id, page#)&lt;/code&gt; triples)
and deriving a histogram and a WSS metric from it remains an open TODO point.&lt;/p&gt;
&lt;p&gt;Note how &amp;ldquo;Designing for locality&amp;rdquo; is not primarily a &amp;ldquo;fragmentation&amp;rdquo; issue ‚Äì the amount of empty space per page,
segment or tablespace does not matter in the first place.
Packing rows that are needed together densely is what matters: data density matters.
And empty space in a page can ultimately adversely affect that, but it is really the last item on the list.&lt;/p&gt;
&lt;h1 id=&#34;fill-factors-and-you-do-not-need-to-optimize-table&#34;&gt;
    &lt;a href=&#34;#fill-factors-and-you-do-not-need-to-optimize-table&#34;&gt;
	Fill Factors, and you do not need to &lt;code&gt;OPTIMIZE TABLE&lt;/code&gt;
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;&amp;ldquo;Empty space in a page&amp;rdquo; is a special kind of fragmentation, and in databases it is commonly called &amp;ldquo;fill factor.&amp;rdquo;
Pep Pla has been testing the behavior of InnoDB with various workloads and page fill factor settings,
and this is the first documented and systematic work in this area that I am aware of.&lt;/p&gt;
&lt;p&gt;Using the &lt;code&gt;innodb_space&lt;/code&gt; tool from &lt;a href=&#34;https://github.com/jeremycole/innodb_ruby&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jeremy Cole&amp;rsquo;s Tooling&lt;/a&gt;

,
he observed the behavior of InnODB after a longer term mixed insert and delete workload.&lt;/p&gt;
&lt;p&gt;The results are pretty encouraging.
Basically, according to the results from his testing,
it never made sense to run &lt;code&gt;OPTIMIZE TABLE&lt;/code&gt; to repack and re-order the data for flash storage.
Disk seeks do not matter much any more on flash,
and there will always be empty space in the pages of tables that see permanent random inserts and deletes.
So running &lt;code&gt;OPTIMIZE TABLE&lt;/code&gt; will bring the table size down and repack it,
only to create a wave of page splits immediately after when the DML workload continues and needs room to work.&lt;/p&gt;
&lt;p&gt;Pep Pla shows fragmentation maps for the same table after 400 iterations of his DML workload using different fill factors,
and it shows that the initial fill factor after an &lt;code&gt;OPTIMIZE TABLE&lt;/code&gt; is no longer visually identifiable.
Instead, all tables look similarly fragmented, so their shape is dominated by the workload, not the
&lt;code&gt;OPTIMIZE TABLE&lt;/code&gt; and the fill factor parameters.&lt;/p&gt;
&lt;p&gt;It may be useful to &lt;code&gt;OPTIMIZE&lt;/code&gt; (and compress) tables that are being archived, but as soon as they see DML,
they will be reshaped by the workload again, and you might as well not &lt;code&gt;OPTIMIZE&lt;/code&gt;.&lt;/p&gt;
&lt;h1 id=&#34;designing-for-locality-vs-uuid&#34;&gt;
    &lt;a href=&#34;#designing-for-locality-vs-uuid&#34;&gt;
	Designing for locality vs UUID
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;It is worth mentioning that very many tables have a row-access frequency that matches the rows primary key,
if the rows&amp;rsquo; primary key is an &lt;code&gt;auto_increment&lt;/code&gt;.
That is, very many applications frequently access rows that have recently been written,
while older rows are being used much less frequently.&lt;/p&gt;
&lt;p&gt;By using &lt;code&gt;auto_increment&lt;/code&gt; primary keys,
data is automatically ordered physically so that &amp;ldquo;cold data&amp;rdquo; is at the front of the table and &amp;ldquo;hot data&amp;rdquo; is at the end.
This also puts hot rows together into the same page or pages close by, at the end of the table.
This is good for performance in InnoDB, and also keeps the WSS down.&lt;/p&gt;
&lt;p&gt;Using a random primary key (a MD5 or a UUID v4) will not impose any order on the primary key.
In InnoDB, where the primary key value determines the physical position of the row in the table,
this essentially scatters rows across the entire table.
This creates a very large working set, bloating required buffer space, and increasing instance size:
There will be a hot row in any page with the same probability, so you&amp;rsquo;ll have to cache all pages to quench reads.&lt;/p&gt;
&lt;p&gt;Using a UUID v1 is better because they have a temporal component,
which can be used to leverage an &lt;code&gt;auto_increment&lt;/code&gt;-like ordering.
Unfortunately, MySQL does not do this by providing a UUID v1 data type, which does the right thing automatically.
Instead, we get to use a pair of functions &lt;code&gt;UUID_TO_BIN()&lt;/code&gt; and &lt;code&gt;BIN_TO_UUID()&lt;/code&gt;,
which require you to manually cast the data every time you access it and remember to set the swap flag properly.
This is very uncomfortable and error-prone,
more so in large development organizations.&lt;/p&gt;
&lt;p&gt;Try to use &lt;code&gt;auto_increment&lt;/code&gt; with MySQL InnoDB.
If you can&amp;rsquo;t, try to go with UUID v1 and the &lt;code&gt;UUID_TO_BIN()&lt;/code&gt; functions, with the swap flag set.&lt;/p&gt;
&lt;p&gt;For the various MySQL flavors, it remains an open TODO point to provide a UUID v1 and a UUID v4 data type.&lt;/p&gt;
&lt;h1 id=&#34;row-fragmentation&#34;&gt;
    &lt;a href=&#34;#row-fragmentation&#34;&gt;
	Row Fragmentation
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;MySQL InnoDB is famously bad at storing files, and Pep Pla discusses that cursory, too.
In fact, the Percona Blog also provides
&lt;a href=&#34;https://www.percona.com/blog/how-innodb-handles-text-blob-columns/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;another article on this&lt;/a&gt;


with some more depth, which is a lot more opinionated than the official manual on the subject at hand.&lt;/p&gt;
&lt;p&gt;Basically, when a row becomes too large (at 1/2 page size, 8 KB),
InnoDB stores individual fields of a row &amp;ldquo;off-table&amp;rdquo; in overflow pages.
The article does not discuss this, but to my knowledge, each overflow page holds only one field,
so the overhead is statistically much larger than &amp;ldquo;on average 1/2 page&amp;rdquo; as stated in that article.
This effect becomes stronger if you have tables with multiple BLOB/TEXT columns in a row,
and each is just barely large enough to trigger off-table storage.&lt;/p&gt;
&lt;p&gt;Accessing data that is stored in overflow pages uses up additional buffer pool pages to hold them,
at a rate of at least one per overflowed field, increasing the working set size, and hence necessary instance size.
In versions of MySQL before MySQL 8, such data also forced the use of on-disk temporary tables,
which impacted query performance badly to a large extent,
but this is now fortunately fixed.&lt;/p&gt;
&lt;p&gt;So in the past, the general advice was to avoid TEXT/BLOB columns altogether,
and if you must use them, do not use them as part of a join or any query that was marked as &amp;ldquo;using temporary.&amp;rdquo;
Since MySQL 8, this is much better, but still be aware of the working set size increase.&lt;/p&gt;
&lt;p&gt;For the various MySQL flavors remains an open TODO point to provide a more efficient (Postgres TOAST-like?) BLOB storage,
in order to bring down storage overhead.&lt;/p&gt;
&lt;p&gt;Another long-standing BLOB performance-related work item that is not linked to fragmentation
would be to provide a &amp;ldquo;partial updates&amp;rdquo;/&amp;ldquo;BLOB streaming&amp;rdquo; API in the protocol,
because this is another well-known point of inefficiency:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Try to store a BLOB larger than &lt;code&gt;max_allowed_packed&lt;/code&gt; in the database.&lt;/li&gt;
&lt;li&gt;Try to change 4 bytes at offset 32M in a 64M BLOB efficiently using MySQL protocol.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you do, and observe what happens on the wire, in memory and on disk, you&amp;rsquo;d be scared.
Until it is fixed, use the filesystem or S3 for this, and store filenames or URLs instead.&lt;/p&gt;
&lt;h1 id=&#34;recommendations&#34;&gt;
    &lt;a href=&#34;#recommendations&#34;&gt;
	Recommendations?
    &lt;/a&gt;
&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;You probably do not need to care much about fragmentation if your database uses flash-based storage.
InnoDB is relatively stable for DML workload, and &lt;code&gt;OPTIMIZE TABLE&lt;/code&gt; is usually not worth the effort,
unless you move a table to archive/read-only.&lt;/li&gt;
&lt;li&gt;You would do well to design for data density and temporal locality, bringing down working set size.
&lt;ul&gt;
&lt;li&gt;Often this happens automatically when using &lt;code&gt;auto_increment&lt;/code&gt; as a primary key.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Even in MySQL 8, you would still do well to keep BLOB and TEXT fields out of main tables,
or where it makes sense, out of the database completely.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Server Side improvements needed:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MySQL has no good instrumentation that can trace disk read requests by &lt;code&gt;(ts, tablespace_id, page#)&lt;/code&gt;,
making it hard to estimate working set size, and derive an optimal instance size from it.
You will need to patch the database server in order to grab this data.
This needs fixing in the mainline server source.&lt;/li&gt;
&lt;li&gt;MySQL should have a UUID v1 and a UUID v4 data type, which would be a lot less error-prone that the
current set of functions.
This needs fixing in the mainline server source.&lt;/li&gt;
&lt;li&gt;MySQL has an abysmally underdeveloped BLOB storage and long-standing gaps in its BLOB access API
(efficient partial updates, BLOB streaming).
This needs fixing in the mainline server source.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A Great Resignation, Management Edition</title>
      <link>https://blog.koehntopp.info/2023/06/22/a-great-resignation-management-edition.html</link>
      <pubDate>Thu, 22 Jun 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/06/22/a-great-resignation-management-edition.html</guid>
      <description>&lt;p&gt;This is not much of a blog post, but just a &lt;a href=&#34;https://chaos.social/@isotopp/110586700595558261&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;thread dump from Mastodon&lt;/a&gt;

 as requested by a friend,
because my Mastodon posts expire after some time.&lt;/p&gt;
&lt;p&gt;Based on my work and the people I know, I have some (remote) view into what happens in a few companies at the C- and Mid-Level management.
And from where I sit, it seems the great resignation is not only a thing that affects workers, but also managers.
It is almost funny.&lt;/p&gt;
&lt;p&gt;These people are often pretty awesome administrative people.
Mid-level managers with amazing Jira- and Miro-skills, breaking down large work parcels of well-understood jobs into team-sized packages,
describing the requirements and planning the required hours, then mapping them onto calendars.
Or budget jugglers that take large unstructured sums of cost, and find a way to parcel them out in a halfway reasonable way into individual cost centers and items.&lt;/p&gt;
&lt;h1 id=&#34;digital-and-other-transformations&#34;&gt;
    &lt;a href=&#34;#digital-and-other-transformations&#34;&gt;
	Digital and other transformations
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;These companies are also all in a series of transformations, at all levels of the stack simultaneously.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Many are moving on-premises workloads to cloud, but the workloads are not cloud-shaped.&lt;/li&gt;
&lt;li&gt;Two enterprises I happen to know about are also changing their implementation language from something exotic to something less efficient, but a lot easier to hire for.&lt;/li&gt;
&lt;li&gt;One enterprise is also breaking up a monolithic application into a set of microservices, but the cut lines are unclear and need to be found.&lt;/li&gt;
&lt;li&gt;One enterprise is modifying the way they do business from a single product to a series of interconnected and interdependent products, some of them in highly regulated markets.&lt;/li&gt;
&lt;li&gt;Another enterprise is changing the way they make their product from mostly manual labor into something based on sensor input and data science.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These transformations require a different kind of manager:
they need less of an administrative person, and more business process designer;
they require a different kind of empowerment and delegation, from the top to them, and from them on downwards ‚Äì much more autonomous on the delegation poker side;&lt;/p&gt;
&lt;p&gt;What is also needed is an entirely different kind of understanding of the company itself, less interchangeable business administration skills,
and more business-specific skills about how the sausage is made.&lt;/p&gt;
&lt;p&gt;On top of that are traditional hierarchies and communication structures that are based on in-person attendance and mostly oral tradition,
and a skill-set that is well suited for the Clear and Complicated domains of &lt;a href=&#34;https://en.wikipedia.org/wiki/Cynefin_framework&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;the Cynefin-Model&lt;/a&gt;

,
but wrong for the Complex and Chaotic domains.&lt;/p&gt;
&lt;p&gt;The Enterprise cannot perform the set of transitions it must execute to stay relevant,
when the entire Org and the people that carry and build the structure of the Org are incapable of transforming their way of working to match the problem.
So they leave.&lt;/p&gt;
&lt;p&gt;Which for an organization that is in the Complex and Chaotic realm of a transformation makes the problem worse,
because the intimate knowledge of the processes that make this company unique and competitive goes with them.
The people coming in have to learn these things,
but if the Org does not have &lt;em&gt;written&lt;/em&gt; account of what matters and has no way of &lt;em&gt;teaching&lt;/em&gt; these things that make this company special,
it basically loses its specialty and becomes meaningless, interchangeable and then soon extinct.&lt;/p&gt;
&lt;h1 id=&#34;what-remote-work-does-for-companies&#34;&gt;
    &lt;a href=&#34;#what-remote-work-does-for-companies&#34;&gt;
	What Remote Work does for companies
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Funnily,
companies that optimize for remote work are also companies
that out of necessity optimize for a written instead of an oral culture.
They tend to have very well documented ways of specifying and teaching what they do, why and how,
and a proper self-service onboarding process complemented by a mentoring system ‚Äì
and that also works for mid- and C-level management.&lt;/p&gt;
&lt;p&gt;Companies that optimize for remote are executing transformations easier because they understand their meta better.
Many workers understand that.
Maybe not in this way or even in words, but they can read the room, and they are reacting to their environment, especially the skilled ones.&lt;/p&gt;
&lt;p&gt;A preference for remote work is useful even, or especially, if you come into the office,
because a company that can do remote properly understands what it does and how it works better than a company that executes &amp;ldquo;remote&amp;rdquo; with a &amp;ldquo;zoom harder&amp;rdquo; policy.&lt;/p&gt;
&lt;h1 id=&#34;interviewing-to-find-organizations-that-know-their-stuff&#34;&gt;
    &lt;a href=&#34;#interviewing-to-find-organizations-that-know-their-stuff&#34;&gt;
	Interviewing to find organizations that know their stuff
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;So when you interview, these are useful and interesting questions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How did your company change their way of working during Covid?&lt;/li&gt;
&lt;li&gt;How did your management style evolve under Covid and after?&lt;/li&gt;
&lt;li&gt;How do you detect misalignment, disagreement or conflict or other causes for in-person meetings when working remotely,
and what are the ways you handle these situations?&lt;/li&gt;
&lt;li&gt;How do you evolve agreement from oral consensus to documentation to training material?
How do you document and teach processes?&lt;/li&gt;
&lt;li&gt;How did your way of working as a person and as a member of the Org evolve in the last 5 years?
What can you point to that illustrates process maturation and advancement?&lt;/li&gt;
&lt;li&gt;In what way did your Org execute transformations in the last five years?
That certainly was not frictionless.
What worked, what didn&amp;rsquo;t, what did the Org learn?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If that reads a lot like a reverse interview ‚Äì well, that&amp;rsquo;s what it is.&lt;/p&gt;
&lt;p&gt;But the objective is clear:
You want to find out if the org you are about to join has access to its own meta,
and if it can change and consciously design its org structure, work, and communications culture.&lt;/p&gt;
&lt;p&gt;All companies right now are executing a series of transformations at multiple levels of their business.
That is because the world right now is a lot less stable than it used to be in the last 50 years.
But only those that do not let these things happen to them, but are actively shaping the process will not be painful to work at.&lt;/p&gt;
&lt;p&gt;You must find these early in the interview process.&lt;/p&gt;
&lt;p&gt;In any case, the information you want to find when interviewing for a job is again:&lt;/p&gt;
&lt;p&gt;&amp;ldquo;Does this company shape itself and its future consciously?
Does it design itself?
Or does change happen to the org accidentally?
Does it understand what it does, and why? Or are they winging it?&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Most management is winging it, most companies are cheating their way to the next quarterlies.&lt;/p&gt;
&lt;p&gt;You do your work, but you do have an understanding of what management is supposed to do.
Does management understand their job, tho?&lt;/p&gt;
&lt;p&gt;Can you respect your current or future management?
Can they express the value they provide in a way &lt;em&gt;that is understandable and meaningful to you?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Can they explain the business, and what specifically the competitive advantage is this org has within its own competitive set?
Do they know why this differentiation exists, and how it is protected or extended?
Do they understand in what way the structure they are building and upholding helps in doing this?
And how it needs to change to be able to continue?&lt;/p&gt;
&lt;p&gt;Basically, you want to find out if they know the C-level strategy they exist in.
If they know what direction everybody is supposed to march in, and what their local objectives are as a part of the greater whole.
You need to find out if they have context that they are making local decisions in.&lt;/p&gt;
&lt;p&gt;Incidentally, it is this (and not ping-pong tables) that builds engagement and loyalty.&lt;/p&gt;
&lt;p&gt;People love to work for a company that understands how it functions,
and can talk sensibly about this ‚Äì about its business and communication processes,
and the why and how of useful interaction.&lt;/p&gt;
&lt;p&gt;People love to work for organizations that have an idea of how to change and into what, instead of being shaped by accident.&lt;/p&gt;
&lt;h1 id=&#34;stressors&#34;&gt;
    &lt;a href=&#34;#stressors&#34;&gt;
	Stressors
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Another contributing factor is that transformations interrupt the value extraction process of neoliberal shareholder value,
and also upsets established hierarchies.&lt;/p&gt;
&lt;p&gt;Shifting to the left side of the Cynefin model means you need smaller teams of higher qualified people.
Teams that perform work in a way that is much harder to quantify,
and create value that is hard to express in right-side organizational structures.&lt;/p&gt;
&lt;p&gt;That is, shareholders and their demand for dividend and rising stock value interfere with the investment needs,
increased risk and hard to measure gains that transformations require,
and thus the owners of the enterprise are an impediment to the change that the company needs to be able to continue to deliver value to them.&lt;/p&gt;
&lt;p&gt;That is, some individual owners always understand that problem,
but the owners as a group don&amp;rsquo;t and can&amp;rsquo;t and are working against their own best interest.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Side Remark:&lt;/em&gt; Similar structural pressure is currently visible in German society, at the &amp;ldquo;Berlin vs. Berlin Outskirts&amp;rdquo; conflict or at the national mobility and energy transformation.&lt;/p&gt;
&lt;h1 id=&#34;side-remarks-from-the-pandemic-coping-discord&#34;&gt;
    &lt;a href=&#34;#side-remarks-from-the-pandemic-coping-discord&#34;&gt;
	Side Remarks from the Pandemic Coping Discord
    &lt;/a&gt;
&lt;/h1&gt;
&lt;h2 id=&#34;a-friend-gives-an-example-at-the-individual-level&#34;&gt;
    &lt;a href=&#34;#a-friend-gives-an-example-at-the-individual-level&#34;&gt;
	A friend gives an example at the individual level
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;IC: &amp;ldquo;The existing code is bad and undocumented. Three weeks for the fix, provided there are no landmines.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;M: &amp;ldquo;So you commit to 3w?&amp;rdquo;&lt;/p&gt;
&lt;p&gt;IC: &amp;ldquo;No, because I don&amp;rsquo;t know if there are landmines. Usually there are.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;M: &amp;ldquo;But I need a binding commitment to before the end of July!&amp;rdquo;&lt;/p&gt;
&lt;p&gt;That&amp;rsquo;s lack of tech understanding paired with pressure from the shareholder end.&lt;/p&gt;
&lt;h2 id=&#34;another-friend-talks-about-stressors&#34;&gt;
    &lt;a href=&#34;#another-friend-talks-about-stressors&#34;&gt;
	Another friend talks about Stressors
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;M: &amp;ldquo;My personal theory is that we are running into some inherent limits of the current management model during the last decade and are now seeing stress fractures.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;K: &amp;ldquo;But the question is where the stress is originating.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;M: &amp;ldquo;Complexity (as observed at each management level).&amp;rdquo;&lt;/p&gt;
&lt;p&gt;K: &amp;ldquo;Ok, that matches what I think if you accept that it is these transformations that are causing the stress. What you call stress fractures I call transformation overload.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;M (responding to the three-week-commitment example above):
&amp;ldquo;A good example for what I mean by complexity at that management level:
The manager can communicate only a scalar detail upwards, but the problem is a complex data object.
The manager cannot report what happens nor the risk properly.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;K: &amp;ldquo;A command and control management is unable to handle situations that require nuance and understanding of detail?&amp;rdquo;&lt;/p&gt;
&lt;p&gt;M: &amp;ldquo;Yes. Management level A needs to reduce their stress, and forces their lower level B to simplify. That increases pressure and stress at the level of B.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;M: C has called this &amp;ldquo;driven by financials.&amp;rdquo;
The only universal scalar is Euro,
but expressing all things in Euros is becoming increasingly harder and is losing information.&lt;/p&gt;
&lt;p&gt;M: A lot of fighting and pressure is actually about &amp;ldquo;simplify your reporting&amp;rdquo; vs. &amp;ldquo;accept my complexity.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;M: &amp;ldquo;This is also in part why we see a preference for managed services. They are an attempt to encapsulate complexity. Often that fails, and the complexity reappears and attacks the PO consuming that service.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;C: &amp;ldquo;A way to solve the conflict is to ask more &amp;lsquo;Why&amp;rsquo; questions downstack, and to create more tasks that allow for interpretation.&amp;rdquo;
That is basically a move to the left-hand side of Cynefin.&lt;/p&gt;
&lt;p&gt;M: &amp;ldquo;That requires a trust that is larger than Euro-Scalars. And ultimately that breaks at the shareholder-level, latest.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;H2: &amp;ldquo;And non-technical management also believes these things are simple. Click here, and ChatGPT will develop the software autonomously. It&amp;rsquo;s those pesky IT people making all these things that complicated.&amp;rdquo;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>What to do with self-driving car data?</title>
      <link>https://blog.koehntopp.info/2023/06/12/what-to-do-with-self-driving-car-data.html</link>
      <pubDate>Mon, 12 Jun 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/06/12/what-to-do-with-self-driving-car-data.html</guid>
      <description>&lt;p&gt;This is what a self-driving car sees, or constructs from the sensor data it uses:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/06/self-driving-01.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Screenshot from &lt;a href=&#34;https://youtu.be/JC94Y063x58?t=38&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;How is LiDAR remote sensing used for Autonomous vehicles?&lt;/a&gt;

&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Specifically, LIDAR data is supposed to be extremely accurate and fast,
&lt;a href=&#34;https://www.asprs.org/a/publications/proceedings/fall2006/0009.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Lidar Data Accuracy&lt;/a&gt;


claims 2-3cm resolution and many scans per second for aircraft LIDAR, and
&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8659977/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Assessing Vehicle Profiling Accuracy of Handheld LiDAR&lt;/a&gt;


claims similar resolution for casual LIDARing crash scenes with Apple handheld hardware.&lt;/p&gt;
&lt;p&gt;Autonomous vehicles are using this data to detect other traffic, vehicles and persons, to classify them,
and to model their behavior.
For this, they are building a model of the world around them,
in which the position and the speed vector of anything detected is very well known and tracked.
It stands to reason that this is a very well-calibrated system, because if it were not,
the car would build the world-model wrongly and hit other people or things.&lt;/p&gt;
&lt;h1 id=&#34;questions-for-self-driving-car-builders&#34;&gt;
    &lt;a href=&#34;#questions-for-self-driving-car-builders&#34;&gt;
	Questions for self-driving car builders
    &lt;/a&gt;
&lt;/h1&gt;
&lt;h2 id=&#34;detecting-speeding-while-driving&#34;&gt;
    &lt;a href=&#34;#detecting-speeding-while-driving&#34;&gt;
	Detecting speeding while driving
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/06/self-driving-02.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Albrechtstra√üe, driving towards Wenckebachstra√üe, in Berlin. To the right a playground. This road is a &amp;ldquo;30 zone&amp;rdquo;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Consider this car driving in a 30 zone in Berlin towards the main road. It is being passed on the left by another car,
driving&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;35 km/h&lt;/li&gt;
&lt;li&gt;50 km/h&lt;/li&gt;
&lt;li&gt;70 km/h&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In this situation, should the self-driving car send a report to the police for a traffic-violation (speeding) automatically?
If yes, why at this threshold and not any other? If no, why should the car ignore this?&lt;/p&gt;
&lt;h2 id=&#34;detecting-speeding-while-parking&#34;&gt;
    &lt;a href=&#34;#detecting-speeding-while-parking&#34;&gt;
	Detecting speeding while parking
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Consider the same situation, but the car is parked in a GDPR-compliant &amp;ldquo;Sentry Mode&amp;rdquo;.
That is, the car does not record any data from the public space, unless it has reason to (for example, because it is being burglared).
But of course its sensors do not stop at a road boundary, and it still somehow notices the speeding happening.&lt;/p&gt;
&lt;p&gt;Should it report the traffic violation, or let it go?
If it should let it go despite having a recording, why? If the threshold is different from driving, why?&lt;/p&gt;
&lt;h2 id=&#34;the-offending-car-could-have-been-on-auto-but-it-was-not&#34;&gt;
    &lt;a href=&#34;#the-offending-car-could-have-been-on-auto-but-it-was-not&#34;&gt;
	The offending car could have been on auto, but it was not
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Consider the offending, speeding car to be a model at least as capable as the model doing the recording.
It could drive autonomously, and if it were, it would have been following the posted speed limit of 30 km/h.
But the driver disabled the autonomous mode and manually and willfully speeded.&lt;/p&gt;
&lt;p&gt;Should the driver be fined normally or get a different fine? Why?&lt;/p&gt;
&lt;p&gt;Should that car have reported itself and its driver? Why or why not?&lt;/p&gt;
&lt;h2 id=&#34;the-recording-car-is-parked-illegally&#34;&gt;
    &lt;a href=&#34;#the-recording-car-is-parked-illegally&#34;&gt;
	The recording car is parked illegally
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;The driver of the recording car tries to park illegally:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/06/self-driving-03.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Wenckebachstrasse 1, Berlin. The driver tries to park to the right of the Seat and the red-white boundary.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The car has a map of legal parking spaces in the area available, and can position itself within 3 cm accuracy.
The driver tries to park it to the right of the Seat and the red-white boundary.
The car warns the driver, and is overridden.
Behind the driver on the other side of the road is a playground.
The building in front of the driver is the Wenckebach Hospital.&lt;/p&gt;
&lt;p&gt;Should the car self-report the parking violation? Should this include data about the driver?
Should another car spotting this report the parking violation?
Or should only a &lt;a href=&#34;https://algoritmeregister.amsterdam.nl/en/automated-parking-control/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Scanauto&lt;/a&gt;

 report this once it spots it on its tour?
Why or why not?&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Getting rid of phishing training mails</title>
      <link>https://blog.koehntopp.info/2023/05/23/getting-rid-of-phishing-training-mails.html</link>
      <pubDate>Tue, 23 May 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/05/23/getting-rid-of-phishing-training-mails.html</guid>
      <description>&lt;p&gt;Just like your work computer is being infested with corporate malware as to prevent it from being taken over from other people&amp;rsquo;s malware,
your account is also being spammed with corporate malware spam as to prevent it from being taken over by other malware spam.
And just like corporate malware &lt;a href=&#34;https://blog.koehntopp.info/2018/06/18/websense-dlp-gives-instant-root.html&#34;&gt;increases your machine&amp;rsquo;s attack surface&lt;/a&gt;

,
because it is &lt;a href=&#34;https://blog.koehntopp.info/2017/10/20/aslr.html&#34;&gt;badly written&lt;/a&gt;

 and running with privileges,
corporate spam is a useless &lt;a href=&#34;https://publikationen.bibliothek.kit.edu/1000119662&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;nuisance&lt;/a&gt;

 that
&lt;a href=&#34;https://blog.lukaszolejnik.com/solving-phishing-is-not-simple-can-anti-phishing-training-make-it-even-worse/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;doesn&amp;rsquo;t do what it is supposed to do&lt;/a&gt;

.&lt;/p&gt;
&lt;p&gt;Of course, working in an enterprise, you will be subjected to such campaigns anyway.
So the best outcome for you would be to identify a phishing training campaign when it runs the first time,
and then upgrade your filters so that you will never be bothered again.&lt;/p&gt;
&lt;p&gt;The good news is that all phishing training campaigns have automatically detectable traits,
mostly X-Header lines, because the campaign needs to be able to deliver quantifiable results to the corporate overlords that pay for it.
And of course, we can filter for these.&lt;/p&gt;
&lt;h1 id=&#34;the-x-header&#34;&gt;
    &lt;a href=&#34;#the-x-header&#34;&gt;
	The X-Header
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;What X-Header actually is being used depends a lot on the Phishing Training service provider your company is using.
It may be something such as &lt;code&gt;X-KnowB4&lt;/code&gt; or &lt;code&gt;X-PhishMe&lt;/code&gt; or similar.
To find out what it is, you need to check the actual raw message content.&lt;/p&gt;
&lt;p&gt;In Mail.app, select the message you have identified as phishing training mail, and select
&lt;code&gt;View -&amp;gt; Message -&amp;gt; Raw Source (‚å•‚åòU)&lt;/code&gt;.
Then check for lines that start with &lt;code&gt;X-&lt;/code&gt; in the header that identify the training provider or reference &amp;ldquo;Phish&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/phish-06.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;See Message Raw Source in Mail.app.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In Outlook for Mac, select the message you have identified as phishing training mail, and select
&lt;code&gt;View Source&lt;/code&gt;.
Then check for lines that start with &lt;code&gt;X-&lt;/code&gt; in the header that identify the training provider or reference &amp;ldquo;Phish&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/phish-07.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;See Message Raw Source in Outlook for Mac.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The line you are looking for might be looking like this:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/phish-08.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;*In our case, the line identifying the phishing training mails looks like &lt;code&gt;X-Phishme: Phishing_Training&lt;/code&gt;.
In fact, we only care about the presence of the &lt;code&gt;X-PhishMe&lt;/code&gt; header line and the actual value after the &lt;code&gt;:&lt;/code&gt; is completely irrelevant.&lt;/p&gt;
&lt;p&gt;This header, in the exact spelling shown, is what we want. It is best to copy and paste it to prevent spelling errors.&lt;/p&gt;
&lt;h1 id=&#34;mailapp&#34;&gt;
    &lt;a href=&#34;#mailapp&#34;&gt;
	Mail.app
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;I&amp;rsquo;m on a Mac, and for a long time my corporate email was on Gmail.
Unfortunately, Gmail cannot filter on arbitrary X-headers, and registering an application to OAuth against corporate mail is complicated.
But Apple&amp;rsquo;s &lt;code&gt;Mail.app&lt;/code&gt; comes preregistered, was allowed, and can filter.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/phish-01.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;So I can just sacrifice another 200 MB or so to the God of Better Mail and get proper filters in return.
In any case, &lt;code&gt;‚åò-,&lt;/code&gt; (&amp;ldquo;Cmd-Comma&amp;rdquo;) gives me the &lt;code&gt;Rules&lt;/code&gt; menu, and from there I can &lt;code&gt;Add Rule&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/phish-02.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;You would want to add a filter on the Header-Line &lt;code&gt;X-PhishMe&lt;/code&gt;.
For what, we want to create a rule that looks like this:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/phish-03.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This is what our filter should look like, but it can&amp;rsquo;t.
That is, because the first time around Mail.app does not know about this &lt;code&gt;X-&lt;/code&gt; header.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Currently, your Mail.app does not yet understand this particular X-Header, so when you want to create this rule,
you need to &lt;code&gt;Edit header list...&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/phish-04.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;and then add the header to the list of known header lines:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/phish-05.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Only now can you create the filter as shown above.
In this example, I have moved the message to the Trash Bin, but you can choose any target you want.
Whatever you do, make sure that the last action you choose is &amp;ldquo;Stop evaluating rules&amp;rdquo;, then hit OK.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Now drag the rule up so that it becomes the first rule in the list.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You are done.&lt;/p&gt;
&lt;h1 id=&#34;outlook&#34;&gt;
    &lt;a href=&#34;#outlook&#34;&gt;
	Outlook
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;In Outlook for Mac, also hit &lt;code&gt;‚åò-,&lt;/code&gt; (&amp;ldquo;Cmd-Comma&amp;rdquo;) and choose &lt;code&gt;Rules&lt;/code&gt;.
Create a new rule and make sure it is enabled:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/phish-09.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;The rule should look like this:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/phish-10.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;That is, move the message to a folder of your choice, and make sure to enable &amp;ldquo;Stop processing more rules&amp;rdquo;.
Make sure the rule is the first one in the list.&lt;/p&gt;
&lt;p&gt;You are done.&lt;/p&gt;
&lt;h1 id=&#34;summary&#34;&gt;
    &lt;a href=&#34;#summary&#34;&gt;
	Summary
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;All phishing trainings need to have uniquely identifiable marks in order for the training campaign to produce the required key performance indicators.
We can find these labels and use them to filter.
Our mailer will automatically ignore subsequent runs of the phishing training, for our peace of mind.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>50 years in filesystems: towards 2004 ‚Äì LFS</title>
      <link>https://blog.koehntopp.info/2023/05/17/50-years-in-filesystems-towards-2004-lfs.html</link>
      <pubDate>Wed, 17 May 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/05/17/50-years-in-filesystems-towards-2004-lfs.html</guid>
      <description>&lt;p&gt;This is part 5 of a series.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&amp;ldquo;&lt;a href=&#34;https://blog.koehntopp.info/2023/05/05/50-years-in-filesystems-1974.html&#34;&gt;1974&lt;/a&gt;

&amp;rdquo; on the traditional Unix Filesystem.&lt;/li&gt;
&lt;li&gt;&amp;ldquo;&lt;a href=&#34;https://blog.koehntopp.info/2023/05/06/50-years-in-filesystems-1984.html&#34;&gt;1984&lt;/a&gt;

&amp;rdquo; on the BSD Fast File System.&lt;/li&gt;
&lt;li&gt;&amp;ldquo;&lt;a href=&#34;https://blog.koehntopp.info/2023/05/12/50-years-in-filesystems-1994.html&#34;&gt;1994&lt;/a&gt;

&amp;rdquo; on SGI XFS.&lt;/li&gt;
&lt;li&gt;&amp;ldquo;&lt;a href=&#34;https://blog.koehntopp.info/2023/05/15/50-years-in-filesystems-vnodes.html&#34;&gt;Vnodes&lt;/a&gt;

&amp;rdquo; on how to have multiple filesystems in Unix.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Progress is sometimes hard to see, especially when you have been part of it or otherwise lived through it.
Often, it is easier to see by comparing modern educational material and the problems discussed with older material.
Or look for the research papers and sources that fueled the change. So this is what we do.&lt;/p&gt;
&lt;h1 id=&#34;frontiers-in-the-nineties&#34;&gt;
    &lt;a href=&#34;#frontiers-in-the-nineties&#34;&gt;
	Frontiers in the Nineties
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;SGI&amp;rsquo;s XFS is pretty much the culmination point in filesystem technology for anything that does in-place updates.
Extents, generous usage of B+-trees and lock splitting across allocation groups make it a great filesystem that is fast and scales well.
The introduction of a metadata log allows it to recover quickly.&lt;/p&gt;
&lt;p&gt;The Nineties were also busy with operating systems research.
Specifically, cluster operating systems were very much en vogue:
Tanenbaum was in Amsterdam, busy with &lt;a href=&#34;https://en.wikipedia.org/wiki/Amoeba_%28operating_system%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Amoeba&lt;/a&gt;

.
Bell Labs was busy with &lt;a href=&#34;https://en.wikipedia.org/wiki/Plan_9_from_Bell_Labs&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Plan 9&lt;/a&gt;

.
And at the UCB, Ousterhout was working on &lt;a href=&#34;https://en.wikipedia.org/wiki/Sprite_%28operating_system%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sprite&lt;/a&gt;

.&lt;/p&gt;
&lt;p&gt;All were experimenting with cluster-unified filesystems, distributed processing, workload migration,
and generally trying to build what 20 years later would become the &lt;a href=&#34;https://www.amazon.com/Datacenter-Computer-Introduction-Warehouse-Scale-Architecture/dp/159829556X&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Warehouse-Scale Computer&lt;/a&gt;

.&lt;/p&gt;
&lt;p&gt;Part of the Sprite development at UCB, specifically, was the Log-Structured File System (LFS), and
Mendel Rosenblum and John K. Ousterhout present it in &lt;a href=&#34;https://www.usenix.org/legacy/publications/library/proceedings/sd93/seltzer.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this paper&lt;/a&gt;

 from 1992.
This is a long paper, 27 pages, but if you read it with hindsight, you can really appreciate how enlightened it was.&lt;/p&gt;
&lt;h1 id=&#34;lfs&#34;&gt;
    &lt;a href=&#34;#lfs&#34;&gt;
	LFS
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Filesystems with in-place updates are in part already using logs for faster recovery in 1992.
The paper poses the question &amp;ldquo;What if we had a filesystem that only had a log, and never did in-place updates?&amp;rdquo;,
calling it a log-structured file system.
It then proceeds to present an implementation and benchmarks for such a thing.&lt;/p&gt;
&lt;h2 id=&#34;reads-are-cached-only-writes-matter&#34;&gt;
    &lt;a href=&#34;#reads-are-cached-only-writes-matter&#34;&gt;
	&amp;ldquo;Reads are cached, only writes matter&amp;rdquo;
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;In working with distributed operating systems, the Sprite team noticed that they have a lot of memory available.
They found with increasing memory sizes, the probability of a file being served by the buffer cache instead of reading it from disk increased by a lot,
and eventually almost all disk reads are being served from memory.&lt;/p&gt;
&lt;p&gt;Writes cannot be cached very well, and eventually they need to hit persistent storage,
but with the reads being cached it would be worthwhile and possible to construct a filesystem optimized for writes.&lt;/p&gt;
&lt;p&gt;The team also observes that CPU speeds grow exponentially, following Moore&amp;rsquo;s law.
The same seems to be true for memory sizes, which being on-chip silicon structures also obey this law.
But disks do not work that way.
While their capacity grows, their transfer speed and seek time does not improve much, because mechanical parts do not obey Moore&amp;rsquo;s law.
Disks are a problem: While linear writes perform well, seeks are slow and are not getting faster much.&lt;/p&gt;
&lt;p&gt;So they propose never overwriting any data, but always appending changed blocks to the end of a log.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/log-adoption.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;


&lt;em&gt;‚ÄúAh you think the log is your ally? You merely adopted the log. I was born with it, designed for it.‚Äù&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;garbage-collection&#34;&gt;
    &lt;a href=&#34;#garbage-collection&#34;&gt;
	Garbage collection
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Of course, disks in the Nineties were finite, as they are now.
So there has to be a &lt;em&gt;cleaner&lt;/em&gt; process that identifies, frees and compacts space that is no longer needed by any current view of the filesystem.&lt;/p&gt;
&lt;p&gt;This is much like the Garbage Collection in Java Virtual Machines, which were invented around the same time.
And much like the GC in JVMs, it would turn out to be the weak spot of the system.&lt;/p&gt;
&lt;p&gt;A lot of the paper busies itself with simulating workloads on the filesystem with different cleaner policies,
and the team then lands on a system that very much evolves in the same way Java GC evolved,
with a multi-tier compaction process that mirrors the &amp;ldquo;Young&amp;rdquo;, &amp;ldquo;Old&amp;rdquo;, and &amp;ldquo;Permanent&amp;rdquo; generations of Java objects.
This is not entirely surprising from hindsight:
Other, newer systems such as Cassandra, Zookeeper and other storages that use LSM Trees are using a very similar strategy with good success.&lt;/p&gt;
&lt;p&gt;Specifically, LFS partitions the storage into contiguous segments, and cleans storage segment by segment:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We used a simulator to explore different cleaning policies and discovered a simple but effective algorithm based on cost and benefit:
it segregates older, slowly changing data from younger rapidly changing data and treats them differently during cleaning.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Other code takes multiple nearly empty segments of the same age and copies them together into a single segment, freeing up the others.&lt;/p&gt;
&lt;p&gt;This creates a certain amount of background copy activity from the cleaner process.
It also creates a race between the writers to the system using up free space,
and the cleaner process trying to provide sufficient free space.
If the system writes data heavily and free space goes down, the cleaner may need to be prioritized higher,
consuming more I/O, in order to make sufficient progress in providing clean segments to write to.
This will also slow down the writers.&lt;/p&gt;
&lt;p&gt;Benchmarks executed as part of the research show that the system can indeed write to disk at up to 70% of the theoretically available maximum bandwidth.
But this is true only under ideal conditions.
Also, the data is not stored in read-order at all, so read performance is only good if data is actually cached.&lt;/p&gt;
&lt;p&gt;Segments are sufficiently large to amortize the cost of seeking to them.
In the Mid-Nineties, that meant a size of around 0.5 to 1 MB.&lt;/p&gt;
&lt;p&gt;Cleaning is then a three-step process:
After suitable segments have been identified from metadata,
the cleaner reads multiple segments into memory, compacts them into a smaller number of segments,
and writes them out to disk in a single large I/O operation.
The old segments can now be marked as clean, and be returned to the free segment pool.&lt;/p&gt;
&lt;h2 id=&#34;using-ffs-data-structures&#34;&gt;
    &lt;a href=&#34;#using-ffs-data-structures&#34;&gt;
	Using FFS data structures
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;LFS uses data structures from FFS almost unchanged:
The filesystem has superblocks, inodes, direct and indirect blocks, and uses the same structures for directories, too.
All information changed is buffered and then written out sequentially in a single disk write that appends atomically and asynchronously to the log.&lt;/p&gt;
&lt;p&gt;Not overwriting things means duplicating things, so when a file grows by appending a block, the file&amp;rsquo;s inode changes.
This means the block containing the changed inode needs to be written out again, together with block added to the file.
LFS needs to keep track of inodes in an &lt;em&gt;inode map&lt;/em&gt;, and this now also needs to be updated and written out:
even if it is small enough to be cached in memory, it needs to be persisted.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/lfs-structures.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;


&lt;em&gt;LFS does indeed do limited in-place updates: The superblock and checkpoint region are written in fixed locations.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;LFS stops short of also appending new copies of the inode map and ultimately the superblock for each disk write,
and puts these things into fixed locations.
So we do have in-place updates for certain limited metadata structures.
This is unfortunate, as we will see when we are looking at LFS&amp;rsquo; legacy.&lt;/p&gt;
&lt;h2 id=&#34;soft-updates&#34;&gt;
    &lt;a href=&#34;#soft-updates&#34;&gt;
	Soft Updates
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;In order for LFS to write out changes to data and metadata such as indirect blocks, direct blocks, inodes and directories,
updates had to be written in the proper order, even if the entire write happened in a single big I/O operation.
Writing out data &amp;ldquo;from the leaves of the filesystem tree to the top&amp;rdquo; sorts the updates in a way that made recovery easier,
because each data structure that had pointers to dependent blocks would be written out only after these blocks had already been persisted.&lt;/p&gt;
&lt;p&gt;It turns out that this logic also has merit for traditional filesystems that do in-place updates.
It allows &lt;a href=&#34;https://www.usenix.org/legacy/publications/library/proceedings/bsdcon02/mckusick.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;file system checking to go on in the background&lt;/a&gt;

 while the filesystem is already being made available,
and it can &lt;a href=&#34;https://www.usenix.org/legacy/publications/library/proceedings/usenix99/mckusick.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;eliminate almost all synchronous metadata updates&lt;/a&gt;

 in the filesystem.&lt;/p&gt;
&lt;h1 id=&#34;lfs-in-bsd&#34;&gt;
    &lt;a href=&#34;#lfs-in-bsd&#34;&gt;
	LFS in BSD
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;The BSD FFS crew, also at UCB, was very aware of Ousterhout&amp;rsquo;s work, and picks it up the year after he publishes.
They port the filesystem to BSD and &lt;a href=&#34;https://www.usenix.org/legacy/publications/library/proceedings/sd93/seltzer.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;write a 1993 paper about it&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/lfs-ffs-feature-comparison.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Features and subsystems of BSD FFS are matched with the equivalent structures and concepts on the BSD LFS side.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;They note a few shortcomings, and present improvements:
The cleaner was single-threaded. No matter how many LFS filesystems were mounted, there was only a single cleaner process.
Now there is one per mounted filesystem.
They also provide a structural verifier for the filesystem, something similar to a &lt;code&gt;fsck&lt;/code&gt;, but a thing that can run in the background,
while the filesystem is mounted.&lt;/p&gt;
&lt;p&gt;Also, the original LFS code was using more memory than necessary, and BSD LFS was made a lot more memory efficient.&lt;/p&gt;
&lt;p&gt;A lot of the paper is then a validation that their implementation is indeed a faithful port, and an improvement over original LFS,
and benchmarking.&lt;/p&gt;
&lt;p&gt;The benchmarks confirm improved write performance, but also show weakness concerning read workloads.
This is for two reasons: data is possibly fragmented,
and the file system buffer cache in their machines is often too small to soak up the disk reads.
And secondly, when the cleaner process is running, it interacts badly with both the disk reads and writes via disk seeks,
and that costs more performance than anticipated.
This is in particular true for a database-like (TPC-B) benchmark load,
which performs badly and requires extensive tuning.&lt;/p&gt;
&lt;p&gt;Notably, the paper already hints at several improvements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;There are two places where in-place updates still happen.
By removing them, the filesystem would automatically become transactional and gain snapshot functionality.
In fact, each disk write would eventually create a snapshot, and actually &amp;ldquo;snapshotting&amp;rdquo; the filesystem would simply mean
to prevent the cleaner from collecting certain snapshots.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Adding checksums to disk blocks already has happened in a few places.
Turning this into a Merkle tree would be a trivial extension, and make validating the complete integrity not only of the
structure, but also of the file data a lot easier.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The paper already notes that ordering writes in the log in a certain way makes background validation easier:
If blocks being pointed to are written before blocks that point to them, referential integrity of the filesystem is being kept at all times.
It is just that a transaction may be incomplete, but because it&amp;rsquo;s not referenced anywhere that is not a problem,
and the disk blocks will be eventually collected and freed by the cleaner.&lt;/p&gt;
&lt;p&gt;Nothing in this idea is actually dependent on the filesystem being LFS.
In fact, it can and was successfully applied to BSD FFS, too, under the name of
&lt;a href=&#34;https://www.usenix.org/legacy/publications/library/proceedings/usenix99/mckusick.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;soft updates&lt;/em&gt;&lt;/a&gt;

,
allowing to mount unchecked filesystems and then running a check in the background.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;performance-war&#34;&gt;
    &lt;a href=&#34;#performance-war&#34;&gt;
	Performance War
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;While Seltzer, Bostic, McKusick et al., the original authors of the BSD FFS, were busy porting Sprite LFS to BSD,
and tuning it,
Larry McVoy and S.R. Kleiman pick up the BSD FFS sources at Sun and add support for extents to it.
The resulting patch is tiny, and the work is being documented in
&lt;a href=&#34;https://people.freebsd.org/~pfg/docs/fs/ExtentlikePerformanceforUFS.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Extent-like Performance from a UNIX File System&lt;/a&gt;

.&lt;/p&gt;
&lt;p&gt;To Seltzers chagrin, EFS often and consistently outperforms LFS, requires little to no tuning.
In &lt;a href=&#34;https://people.freebsd.org/~pfg/docs/fs/ExtentlikePerformanceforUFS.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;File System Logging Versus Clustering: A Performance Comparison&lt;/a&gt;


this is confirmed, even if it takes a long paper with many benchmarks to arrive at this finding.
The problem is mostly with the disk seeks induced from running the cleaner.&lt;/p&gt;
&lt;p&gt;If only something could be done about this&amp;hellip;&lt;/p&gt;
&lt;p&gt;Something could be done, but it would happen at Sun and NetApp, and not in BSD: We&amp;rsquo;re getting ZFS and WAFL.&lt;/p&gt;
&lt;p&gt;Also, we&amp;rsquo;re getting things that can seek a lot faster than disks: Flash Storage.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>50 years in filesystems: A detour on vnodes</title>
      <link>https://blog.koehntopp.info/2023/05/15/50-years-in-filesystems-vnodes.html</link>
      <pubDate>Mon, 15 May 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/05/15/50-years-in-filesystems-vnodes.html</guid>
      <description>&lt;p&gt;This is part 4 of a series.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&amp;ldquo;&lt;a href=&#34;https://blog.koehntopp.info/2023/05/05/50-years-in-filesystems-1974.html&#34;&gt;1974&lt;/a&gt;

&amp;rdquo; on the traditional Unix Filesystem.&lt;/li&gt;
&lt;li&gt;&amp;ldquo;&lt;a href=&#34;https://blog.koehntopp.info/2023/05/06/50-years-in-filesystems-1984.html&#34;&gt;1984&lt;/a&gt;

&amp;rdquo; on the BSD Fast File System.&lt;/li&gt;
&lt;li&gt;&amp;ldquo;&lt;a href=&#34;https://blog.koehntopp.info/2023/05/12/50-years-in-filesystems-1994.html&#34;&gt;1994&lt;/a&gt;

&amp;rdquo; on SGI XFS.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Progress is sometimes hard to see, especially when you have been part of it or otherwise lived through it.
Often, it is easier to see by comparing modern educational material and the problems discussed with older material.
Or look for the research papers and sources that fueled the change. So this is what we do.&lt;/p&gt;
&lt;h1 id=&#34;how-to-have-multiple-filesystems&#34;&gt;
    &lt;a href=&#34;#how-to-have-multiple-filesystems&#34;&gt;
	How to have multiple filesystems
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Steve Kleiman wrote
&amp;ldquo;&lt;a href=&#34;https://www.semanticscholar.org/paper/Vnodes%3A-An-Architecture-for-Multiple-File-System-in-Kleiman/e0d14c74f23ef9b21c2fc37b5197fbfe348a7fcf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Vnodes: An Architecture for Multiple File System Types in Sun UNIX&lt;/a&gt;

&amp;rdquo;
in 1986.&lt;/p&gt;
&lt;p&gt;This is a short paper, with little text, because most of it is listing of data structures and diagrams of C language &lt;code&gt;struct&lt;/code&gt;&amp;rsquo;s pointing at each other.
Kleiman wanted to have multiple file systems in Unix, but wanted the file systems to be able to share interfaces and internal memory, if at all possible.
Specifically, he wanted a design that provided&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;one common interface with multiple implementations,&lt;/li&gt;
&lt;li&gt;supporting BSD FFS, but also NFS and RFS, two remote filesystems, and Non-Unix filesystems, specifically MS-DOS,&lt;/li&gt;
&lt;li&gt;with the operations being defined by the interface being atomic.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And the implementations should be able to handle memory and structures dynamically, without performance impact,
reentrant and multicore capable, and somewhat object-oriented.&lt;/p&gt;
&lt;h1 id=&#34;two-abstractions&#34;&gt;
    &lt;a href=&#34;#two-abstractions&#34;&gt;
	Two abstractions
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;He looked at the various operations, and decided to provide two major abstractions:
The filesystem (&lt;code&gt;vfs&lt;/code&gt;, virtual filesystem) and the inode (&lt;code&gt;vnode&lt;/code&gt;, virtual inode), representing a filesystem and a file.&lt;/p&gt;
&lt;p&gt;In true C++ style (but expressed in C), we get a virtual function table for each type, representing the class:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For the &lt;code&gt;vfs&lt;/code&gt; type, this is a &lt;code&gt;struct vfsops&lt;/code&gt;,
a collection of function pointers with operations such as &lt;code&gt;mount&lt;/code&gt;, &lt;code&gt;unmount&lt;/code&gt;, &lt;code&gt;sync&lt;/code&gt; and &lt;code&gt;vget&lt;/code&gt;.
Later in the paper, prototypes and functionality of these functions are explained.&lt;/li&gt;
&lt;li&gt;For the &lt;code&gt;vnode&lt;/code&gt; type, likewise, we get &lt;code&gt;struct vnodeops&lt;/code&gt;.
The functions here are &lt;code&gt;open&lt;/code&gt;, &lt;code&gt;rdwr&lt;/code&gt; and &lt;code&gt;close&lt;/code&gt;, of course, but also &lt;code&gt;create&lt;/code&gt;, &lt;code&gt;unlink&lt;/code&gt;, and &lt;code&gt;rename&lt;/code&gt;.
Some functions are specific to a filetype such as &lt;code&gt;readlink&lt;/code&gt;, &lt;code&gt;mkdir&lt;/code&gt;, &lt;code&gt;readdir&lt;/code&gt; and &lt;code&gt;rmdir&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Actual mounts are being tracked in &lt;code&gt;vfs&lt;/code&gt; objects, which point to the operations applicable to this particular subtree with their &lt;code&gt;struct vfsops *&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Similarly, open files are being tracked in &lt;code&gt;vnode&lt;/code&gt; instances, which again, among other things, have a &lt;code&gt;struct *vnodeops&lt;/code&gt; pointer.
&lt;code&gt;vnodes&lt;/code&gt; are part of their &lt;code&gt;vfs&lt;/code&gt;, so they also have &lt;code&gt;struct *vfs&lt;/code&gt; to their filesystem instance.&lt;/p&gt;
&lt;p&gt;Both, the &lt;code&gt;vfs&lt;/code&gt; and the &lt;code&gt;vnode&lt;/code&gt; need to provide a way for the implementation to store implementation specific data (&amp;ldquo;subclass private fields&amp;rdquo;).
So both structures end with &lt;code&gt;caddr_t ...data&lt;/code&gt; pointers.
That is, the private data is not part of the virtual structure, but located elsewhere and pointed to.&lt;/p&gt;
&lt;h2 id=&#34;vnodes-in-action&#34;&gt;
    &lt;a href=&#34;#vnodes-in-action&#34;&gt;
	Vnodes in action
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/vfs-vnode-structures.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;


&lt;em&gt;One full page in the paper is dedicated to showing the various structures pointing at each other.
What looks confusing at first glance is actually pretty straightforward and elegant, once you trace it out.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Kleiman sets out to explain how things work using the &lt;code&gt;lookuppn()&lt;/code&gt; function, which replaces the older &lt;code&gt;namei()&lt;/code&gt; function from traditional Unix.
Analogous to &lt;code&gt;namei()&lt;/code&gt;, the function consumes a path name, and returns a &lt;code&gt;struct vnode *&lt;/code&gt; to the vnode represented by that pathname.&lt;/p&gt;
&lt;p&gt;Pathname traversal starts at the root vnode or the current directory vnode for the current process,
depending on the first character of a pathname being &lt;code&gt;/&lt;/code&gt; or not.&lt;/p&gt;
&lt;p&gt;The function then takes the next pathname component, iteratively, and calls the &lt;code&gt;lookup&lt;/code&gt; function for the current vnode.
This function takes a pathname component, and a current &lt;code&gt;vnode&lt;/code&gt; assuming it is a directory.
It then returns the &lt;code&gt;vnode&lt;/code&gt; representing that component.&lt;/p&gt;
&lt;p&gt;If a directory is a mountpoint, it has &lt;code&gt;vfsmountedhere&lt;/code&gt; set.
This is a &lt;code&gt;struct vfs *&lt;/code&gt;. &lt;code&gt;lookuppn&lt;/code&gt; follows the pointer,
and can call the &lt;code&gt;root&lt;/code&gt; function for that &lt;code&gt;vfs&lt;/code&gt; to get the root &lt;code&gt;vnode&lt;/code&gt; for that filesystem, replacing the current &lt;code&gt;vnode&lt;/code&gt; being worked on.&lt;/p&gt;
&lt;p&gt;The inverse must also be possible:
When resolving a &amp;ldquo;&lt;code&gt;..&lt;/code&gt;&amp;rdquo; component and the current &lt;code&gt;vnode&lt;/code&gt; has a root flag set in its &amp;ldquo;flags&amp;rdquo; field,
we go from the current &lt;code&gt;vnode&lt;/code&gt; to the &lt;code&gt;vfs&lt;/code&gt; following the &lt;code&gt;vfsmountedhere&lt;/code&gt; pointer.
Then we can use the &lt;code&gt;vnodecovered&lt;/code&gt; field in that &lt;code&gt;vfs&lt;/code&gt; to get the &lt;code&gt;vnode&lt;/code&gt; of the superior filesystem.&lt;/p&gt;
&lt;p&gt;In any case, upon successful completion, a &lt;code&gt;struct vnode*&lt;/code&gt; representing the consumed pathname is returned.&lt;/p&gt;
&lt;h2 id=&#34;new-system-calls&#34;&gt;
    &lt;a href=&#34;#new-system-calls&#34;&gt;
	New system calls
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;In order to make things work,
and to make things work efficiently, a few new system calls had to be added to round out the interfaces.&lt;/p&gt;
&lt;p&gt;It is here in Unix history that we get &lt;code&gt;statfs&lt;/code&gt; and &lt;code&gt;fstatfs&lt;/code&gt;, to get an interface to filesystems in userland.
We also gain &lt;code&gt;getdirentries&lt;/code&gt; (plural) to get multiple directory entries at once (depending on the size of the buffer provided),
which makes directory reading faster a lot for remote filesystems.&lt;/p&gt;
&lt;h1 id=&#34;in-linux&#34;&gt;
    &lt;a href=&#34;#in-linux&#34;&gt;
	In Linux
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Looking at the Linux kernel source, we can find the general structure of Kleiman&amp;rsquo;s design,
even if the complexity and richness of the Linux kernel obscure most of it.
The Linux kernel has a wealth of file system types, and added also a lot of functionality that wasn&amp;rsquo;t present in BSD 40 years ago.
So we find a lot more structures and system calls,
implementing namespaces, quotas, attributes, read-only modes, directory name caches, and other things.&lt;/p&gt;
&lt;h2 id=&#34;the-file&#34;&gt;
    &lt;a href=&#34;#the-file&#34;&gt;
	The file
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Still, if you squint, the original structure can still be found:
Linux splits the in-memory structures around files in two, the opened &lt;code&gt;file&lt;/code&gt;, which is an inode with a current position associated,
and the &lt;code&gt;inode&lt;/code&gt;, which is the whole file.&lt;/p&gt;
&lt;p&gt;We find instances of file objects, &lt;code&gt;struct file&lt;/code&gt;, defined
&lt;a href=&#34;https://github.com/torvalds/linux/blob/v6.3/include/linux/fs.h#L942C3-L981&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;

.
Among all the other things a file has, it has most notably a field &lt;code&gt;loff_t f_pos&lt;/code&gt;,
an offset (in bytes) from the start of the file,
the current position.&lt;/p&gt;
&lt;p&gt;The file&amp;rsquo;s class is defined via a virtual function table.
We find the pointer as &lt;code&gt;struct file_operations *f_op&lt;/code&gt;,
and the definition &lt;a href=&#34;https://github.com/torvalds/linux/blob/v6.3/include/linux/fs.h#L1754-L1798&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;

.
It shows all the things a file can do, most notable, &lt;code&gt;open&lt;/code&gt;, &lt;code&gt;close&lt;/code&gt;, &lt;code&gt;lseek&lt;/code&gt; and then &lt;code&gt;read&lt;/code&gt; and &lt;code&gt;write&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The file also contains pointers to the inode, &lt;code&gt;struct inode *f_inode&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;the-inode&#34;&gt;
    &lt;a href=&#34;#the-inode&#34;&gt;
	The inode
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Operations on files without the need of an offset work on the file as a whole,
defined as &lt;code&gt;struct inode *&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Check the definition &lt;a href=&#34;https://github.com/torvalds/linux/blob/v6.3/include/linux/fs.h#L595-L705&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;

.
We see other definitions in here that have no equivalent in BSD from 40 years ago, such as ACLs and attributes.&lt;/p&gt;
&lt;p&gt;We find the inode&amp;rsquo;s class is defined via a virtual function table,
&lt;code&gt;struct inode_operations *i_op&lt;/code&gt;,
and the definition &lt;a href=&#34;https://github.com/torvalds/linux/blob/v6.3/include/linux/fs.h#L1800-L1840&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;

.
Again, a lot of them deal with new features such as ACLs and extended attributes,
but we also find those we expect such as &lt;code&gt;link&lt;/code&gt;, &lt;code&gt;unlink&lt;/code&gt;, &lt;code&gt;rename&lt;/code&gt; and so on.&lt;/p&gt;
&lt;p&gt;The inode also contains a pointer to a filesystem, the &lt;code&gt;struct super_block *i_sb&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;the-superblock&#34;&gt;
    &lt;a href=&#34;#the-superblock&#34;&gt;
	The superblock
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;A mountpoint is represented as an instance of &lt;code&gt;struct super_block&lt;/code&gt;,
defined &lt;a href=&#34;https://github.com/torvalds/linux/blob/v6.3/include/linux/fs.h#L1136-L1268&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;

.
Again, the class is a &lt;code&gt;struct super_operations *s_op&lt;/code&gt;, defined
&lt;a href=&#34;https://github.com/torvalds/linux/blob/v6.3/include/linux/fs.h#L1886-L1918&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;

.&lt;/p&gt;
&lt;p&gt;As an added complexity, there is no finite list of filesystems.
It is instead extensible through loadable modules, so we also have a &lt;code&gt;struct file_system_type&lt;/code&gt;,
&lt;a href=&#34;https://github.com/torvalds/linux/blob/v6.3/include/linux/fs.h#L1886-L1918&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;

.
This is basically a class with only one class method as a factory for superblocks, &lt;code&gt;mount&lt;/code&gt;.&lt;/p&gt;
&lt;h1 id=&#34;summary&#34;&gt;
    &lt;a href=&#34;#summary&#34;&gt;
	Summary
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Unix changed.
It became a lot more runtime extensive, added a lot of new functionality and gained system calls.
Things became more structured.&lt;/p&gt;
&lt;p&gt;But the original design and data structures conceived by Kleiman and Joy held up, and can still be found in current Linux, 40 years later.
We can point to concrete Linux code, which while looking completely different, is structurally mirroring the original design ideas.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>50 years in filesystems: 1994</title>
      <link>https://blog.koehntopp.info/2023/05/12/50-years-in-filesystems-1994.html</link>
      <pubDate>Fri, 12 May 2023 12:13:14 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/05/12/50-years-in-filesystems-1994.html</guid>
      <description>&lt;p&gt;This is part 3 of a series.
The first part is &amp;ldquo;&lt;a href=&#34;https://blog.koehntopp.info/2023/05/05/50-years-in-filesystems-1974.html&#34;&gt;1974&lt;/a&gt;

&amp;rdquo;.
The second part is &amp;ldquo;&lt;a href=&#34;https://blog.koehntopp.info/2023/05/06/50-years-in-filesystems-1984.html&#34;&gt;1984&lt;/a&gt;

&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Progress is sometimes hard to see, especially when you have been part of it or otherwise lived through it.
Often, it is easier to see if you compare modern educational material, and the problems discussed with older material.
And then look for the research papers and sources that fueled the change.&lt;/p&gt;
&lt;p&gt;In Linux (and Unix in general), this is easy.&lt;/p&gt;
&lt;h1 id=&#34;1994--the-sgi-xfs-filesystem&#34;&gt;
    &lt;a href=&#34;#1994--the-sgi-xfs-filesystem&#34;&gt;
	1994 ‚Äî The SGI XFS Filesystem
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;In 1994, the paper &lt;a href=&#34;http://www.scs.stanford.edu/nyu/02fa/sched/xfs.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Scalability in the XFS File System&lt;/a&gt;

 saw publication.
Computers got faster since 1984, and so did storage.
Notably, we are now seeing boxes with multiple CPUs, and with storage reaching into the Terabytes.
The improvements to the 4.3BSD fast filing system (or the modified version in SGI IRIX called EFS) were no longer sufficient.&lt;/p&gt;
&lt;p&gt;SGIs benchmarks cite machines that had large backplanes with many controllers (one benchmark cites a box with 20 SCSI controllers),
many disks (three-digit-numbers of hard drives),
and many CPUs (the benchmarks quote 12 socket machines) with a lot of memory (up to one gigabyte quoted in the benchmarks).&lt;/p&gt;
&lt;p&gt;Filesystems became larger than FFS could handle,
files became larger than FFS could handle,
the number of files per directory led to large lookup times,
central data structures such as allocation bitmaps did no longer scale,
and global locks made concurrent access to the file system with many CPUs inefficient.
SGI set out to design a fundamentally different filesystem.&lt;/p&gt;
&lt;p&gt;Also, the Unix community as a whole was challenged by Cutler and Custer,
who showed with NTFS for Windows NT 4.0 what was possible if you redesign from scratch.&lt;/p&gt;
&lt;h1 id=&#34;requirements&#34;&gt;
    &lt;a href=&#34;#requirements&#34;&gt;
	Requirements
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;The XFS filesystem was a firework of new ideas, and a large deviation from traditional Unix filesystem design.
The list of new things is long:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Facilitate concurrency with
&lt;ul&gt;
&lt;li&gt;allocation zones&lt;/li&gt;
&lt;li&gt;inode lock splitting&lt;/li&gt;
&lt;li&gt;facilities for large, parallel I/O requests, DMA and Zero-Copy I/O&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Scalability of access by building the filesystem around the concepts of
&lt;ul&gt;
&lt;li&gt;B+-Trees&lt;/li&gt;
&lt;li&gt;Extents: pairs of (start, length) descriptors&lt;/li&gt;
&lt;li&gt;decoupling &amp;ldquo;file write&amp;rdquo; and &amp;ldquo;file layout&amp;rdquo; on disk to allow for contiguous files by using delayed allocation and preallocation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Introduce a write-ahead log to journal metadata changes
&lt;ul&gt;
&lt;li&gt;log asynchronously to allow for write coalescence&lt;/li&gt;
&lt;li&gt;leveraging the log for recovery, so that recovery time is proportional to the amount of data in flight, not the size of the filesystem&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;XFS was written with these requirements,
and primarily in order to provide a filesystem that could leverage all the performance of large SGI boxes for video editing, video serving and scientific computing.&lt;/p&gt;
&lt;h2 id=&#34;a-logging-filesystem-but-not-a-log-structured-filesystem&#34;&gt;
    &lt;a href=&#34;#a-logging-filesystem-but-not-a-log-structured-filesystem&#34;&gt;
	A logging filesystem, but not a log structured filesystem
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;This is also happening at about the same time as John K. Ousterhout asking
&amp;ldquo;&lt;a href=&#34;https://web.stanford.edu/~ouster/cgi-bin/papers/osfaster.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Why Aren‚Äôt Operating Systems Getting Faster As Fast as Hardware?&lt;/a&gt;

&amp;rdquo;.
Ousterhout started to explore the ideas of a log-based filesystem with the experimental Sprite operating system.&lt;/p&gt;
&lt;p&gt;Log-based filesystems are an extremely radical idea that we need to discuss later, even if they originally predate XFS by a bit.
But they weren&amp;rsquo;t very usable originally, because they need different hardware which can offer a lot more disk seeks.
Log structured file system ideas had to become a lot more refined to actually have an impact,
so we are going to discuss them later in the series.&lt;/p&gt;
&lt;h2 id=&#34;what-irix-had-before&#34;&gt;
    &lt;a href=&#34;#what-irix-had-before&#34;&gt;
	What IRIX had before
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;IRIX as coming already with EFS, the specially sauced-up version of BSD FFS that used extents.
It suffered from an 8 GB filesystem size limit, a 2 GB filesize limit, and it could not utilize the full hardware I/O bandwidth,
which made many customers of these fantastically expensive machines somewhat sad.&lt;/p&gt;
&lt;p&gt;Demands for video playback and from the database community led to requirements
that stated the new filesystem needed to support hundreds of TB of disk space,
hundreds of MB/s of I/O bandwidth and many parallel I/O requests in order to be able to saturate the hardware provided,
and all this without running out of CPU.&lt;/p&gt;
&lt;p&gt;The title of the paper is &amp;ldquo;Scalability in the XFS File System&amp;rdquo; and not &amp;ldquo;Implementation of ‚Ä¶&amp;rdquo;,
so it is more a show of the features provided and a superficial discussion of the implementation and the design decisions around it.
It is not an in-depth discussion of the implementation,
nor are extensive benchmarks provided.&lt;/p&gt;
&lt;h1 id=&#34;features&#34;&gt;
    &lt;a href=&#34;#features&#34;&gt;
	Features
    &lt;/a&gt;
&lt;/h1&gt;
&lt;h2 id=&#34;large-filesystems&#34;&gt;
    &lt;a href=&#34;#large-filesystems&#34;&gt;
	Large filesystems
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;XFS supports large filesystems.
Previous filesystems use 32-bit pointers to blocks.
At 8 KB block size, with 32-bit block pointers, the limit is 32 TB.&lt;/p&gt;
&lt;p&gt;Moving to 64-bit block pointers would make many data structures multiple of 8 bytes in size, which seemed like a waste.&lt;/p&gt;
&lt;p&gt;For concurrency (see below), XFS introduces the concept of &lt;strong&gt;allocation groups&lt;/strong&gt; (AGs), which are always smaller than 4 GB.
Allocation groups have local instances of the filesystem data structures, for example, inode maps or free block tracking.
These are independently locked and so allow for concurrent operations in different allocation groups.&lt;/p&gt;
&lt;p&gt;Allocation groups also help to save on pointer sizes:
Where possible, AG-relative block numbers are being used, and these always fit into 32-bit pointers.
In fact, a 4G allocation group can have only 1M blocks or fewer blocks (at 4K minimum blocksize),
so a single maximum sized extent within a single AG can be packed into 40 bits (5 bytes).&lt;/p&gt;
&lt;p&gt;The maximum file size and filesystem size is 8 EB (2^63-1).&lt;/p&gt;
&lt;h2 id=&#34;bandwidth-and-concurrency&#34;&gt;
    &lt;a href=&#34;#bandwidth-and-concurrency&#34;&gt;
	Bandwidth and Concurrency
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Concurrent operations are a design goal for XFS.
1994 is the age of 20 MB/s SCSI controllers, but SGI built machines with large chassis that could house many controllers and many drives.
Benchmarks quote machines with an aggregate bandwidth of 480 MB/s delivering file I/O performance of over 370 MB/s with no tuning, including all overheads.
This is quite an impressive result for everyday usage in 1994.&lt;/p&gt;
&lt;p&gt;XFS achieves this using large blocks (4 KB or 8 KB block size), and the concept of extents.&lt;/p&gt;
&lt;h3 id=&#34;extents-and-b-trees&#34;&gt;
    &lt;a href=&#34;#extents-and-b-trees&#34;&gt;
	Extents and B-Trees.
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Extents&lt;/strong&gt; are a core concept in XFS.
They are tuples, most of the time pairs of &lt;code&gt;(startblock, length)&lt;/code&gt;.
For mapping file blocks to disk blocks (&amp;ldquo;bmap&amp;rdquo;), they are triples &lt;code&gt;(offset, length, startblock)&lt;/code&gt;.
Using truncated values, because of the size limits imposed by the maximum AG size,
they can describe a contiguous sequence of blocks up to 2M blocks in size in 4 bytes,
which is a lot more efficient than what BSD FFS did before.&lt;/p&gt;
&lt;p&gt;Extents also allow XFS to do large I/O requests because they describe sections of contiguous blocks,
making it easy to create read or write requests for several blocks apiece.
It does I/O by default with 64 KB memory buffers, unless special provisions are being made to make them even larger.&lt;/p&gt;
&lt;p&gt;The filesystem assumes an underlying disk structure with striping, and provides a number of 2 or 3 outstanding I/O requests to allow for concurrent I/O.
It checks for backpressure, that is, it checks that the application is actually reading data.
If it does, it issues additional read requests to keep the number of requests in flight at 3 by default,
good for 192 KB in flight at once.&lt;/p&gt;
&lt;p&gt;Groups of Extents can be collected in linear lists, but that will lead to scaling problems.
So XFS uses &lt;strong&gt;B+-Trees&lt;/strong&gt;, which degrade to linear lists if there is only one single index block.&lt;/p&gt;
&lt;p&gt;Usually tuples are indexed on their first value, but for some structures such as free lists, multiple indexes are kept:
It is useful to index free space by &lt;code&gt;startblock&lt;/code&gt; for closeness, but also by &lt;code&gt;length&lt;/code&gt; to fit free spaces in the right size.&lt;/p&gt;
&lt;h3 id=&#34;breaking-the-single-writer-inode-lock&#34;&gt;
    &lt;a href=&#34;#breaking-the-single-writer-inode-lock&#34;&gt;
	Breaking the single-writer inode lock
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/overlapping-write.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;


&lt;em&gt;Posix locks the in-memory inode to guarantee &lt;a href=&#34;https://blog.koehntopp.info/2018/11/29/but-is-it-atomic.html&#34;&gt;atomic writes&lt;/a&gt;

.
This makes sure any two large multiple-block writes always happen one-before-the-other.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;XFS also breaks the in-memory inode locks:
Posix demands that large, overlapping, multiple block writes are totally ordered.
When they overlap, it must not happen that there is a block soup of alternating blocks from write A and write B.&lt;/p&gt;
&lt;p&gt;The default implementation in most kernels is simply a file-global lock placed at the in-memory inode, making sure there can be only one writer per inode.
Implementers of databases hate that because it limits the write concurrency on any single file to One.
This is, for example, why Oracle recommends that you make tablespaces from multiple files, each no larger than one GB.&lt;/p&gt;
&lt;p&gt;XFS, in &lt;code&gt;O_DIRECT&lt;/code&gt; mode, removes this lock and allows atomic, concurrent writes, making database people very happy.&lt;/p&gt;
&lt;h2 id=&#34;dynamic-inodes-and-improved-free-space-tracking&#34;&gt;
    &lt;a href=&#34;#dynamic-inodes-and-improved-free-space-tracking&#34;&gt;
	Dynamic Inodes and improved Free Space Tracking
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;With large filesystems, you can never know:
The applications may need a large number of inodes for many small files, or a small number of large files.
Also, what is a good distance between the inode and the data blocks that belong to the file?&lt;/p&gt;
&lt;p&gt;There is no good answer to the first question, and &amp;ldquo;as close as possible&amp;rdquo; is the answer to the second question.
So XFS creates Inodes dynamically, as needed, in chunks of 64 inodes.&lt;/p&gt;
&lt;p&gt;The relatively large inode size of 256 bytes (compared to 128 in BSD FFS and 64 in traditional Unix)
is being compensated by the fact that XFS creates Inodes only as needed, and places them relatively closely to the file start.
This frees up a substantial amount of disk space ‚Äì
in Unix filesystems with fixed inode counts as much as 3-4% of the disk space can be locked up in pre-allocated inodes.
And even with cylinder groups, there will be considerable distance between an inode and the first data block.&lt;/p&gt;
&lt;p&gt;Because inodes can reside anywhere on the disk and not just behind the superblock, they need to be tracked.
XFS does with one B+-tree per allocation group.
The tree is indexed by the start block, and records for each inode in the chunk if it is available or in-use.
The inodes themselves are not kept in the tree, but in the actual chunks which are close to the file data.&lt;/p&gt;
&lt;p&gt;Similarly, free space is tracked in chunks, and kept in per-AG trees, indexed twice: by start block and by length.&lt;/p&gt;
&lt;h2 id=&#34;write-ahead-log&#34;&gt;
    &lt;a href=&#34;#write-ahead-log&#34;&gt;
	Write-Ahead Log
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Recovering a large filesystem after a crash can be slow.
The recovery time is proportional to the size of the filesystem, and the number of files in it,
because the system basically has to scan the entire filesystem and rebuild the directory tree in order to ensure things are consistent.
With XFS, the filesystem also is a lot more fragile, as it provides a variable number of inodes, spread out non-contiguously over the disk.
Recovering them would be extra expensive.&lt;/p&gt;
&lt;p&gt;Using write-ahead logging for metadata, this can be avoided most of the time.
Recovery time is proportional to the size of the log, that is, the amount of data in flight at the time of the crash.&lt;/p&gt;
&lt;p&gt;The log contains log entries containing a descriptor header and a full image of all changed metadata structures:
inodes, directory blocks, free extent tree blocks, inode allocation tree blocks, allocation group blocks, and the superblock.
Because full images are stored in the block, recovery is simple: the recovery process simply copies these new, changes images into the place where they are supposed to be, without needing to understand what kind of structure it changes.&lt;/p&gt;
&lt;p&gt;The trust of the authors into the log was huge:
Initially XFS had no &lt;code&gt;fsck&lt;/code&gt; program.
This turned out to be overly optimistic, and so now &lt;code&gt;xfs_repair&lt;/code&gt; exists.&lt;/p&gt;
&lt;h3 id=&#34;metadata-update-performance&#34;&gt;
    &lt;a href=&#34;#metadata-update-performance&#34;&gt;
	Metadata update performance
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;XFS is logging metadata updates, which means they need to be written to the filesystem log.
By default, this log is placed inline, in the filesystem.
But it is also possible to take it out, and put onto other media, for example, flash storage or battery-backed memory.&lt;/p&gt;
&lt;p&gt;Writes to the log are asynchronous, if possible, but with partitions serving NFS they cannot be.
Asynchronous writes allow for write batching, with speeds things up.
But NFS servers profit a lot from accelerated log storage.&lt;/p&gt;
&lt;p&gt;Because all metadata updates need to be logged, it can happen that intense metadata operations flood the log.
A &lt;code&gt;rm -rf /usr/src/linux&lt;/code&gt; for example is not an operation where XFS is particularly fast, because the metadata update stream will eventually overflow the log.
And because everything else in XFS is parallel by AG, the log is usually the only source of contention.&lt;/p&gt;
&lt;h2 id=&#34;large-files-and-sparse-files&#34;&gt;
    &lt;a href=&#34;#large-files-and-sparse-files&#34;&gt;
	Large files and sparse files
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;In FFS, files are mapped by the classical dynamic array, with direct blocks and up to three levels of indirect blocks.
With 64-bit filesize, this becomes unwieldy: there will be more than three levels of indirect blocks required,
and a substantial number of blocks would be required what essentially becomes a list of incrementing numbers.
FFS (and EFS) are also forced to layout blocks the moment each block is allocated in the filesystem buffer pool.
So effectively, no attempt to contiguously layout files on disk is being made.
Instead, blocks are placed individually.&lt;/p&gt;
&lt;p&gt;XFS replaces this dynamic array with extents.&lt;/p&gt;
&lt;p&gt;In file placement maps, these mapping extents are triples &lt;code&gt;(blockoffset, length, disk block)&lt;/code&gt;.
These extents are stored in the inode itself until this overflows.
Then XFS starts to root a B+-tree of the mapping extents in the inode, indexed by logical block number for fast seeks.&lt;/p&gt;
&lt;p&gt;This data structure allows compressing a substantial number of blocks (up to 2M blocks) in a single descriptor,
assuming contiguous allocation is possible.
So even large files could be stored in very few extents, in the optimal case one extent per AG.&lt;/p&gt;
&lt;h3 id=&#34;delayed-allocation-and-preallocation-for-contiguous-layout&#34;&gt;
    &lt;a href=&#34;#delayed-allocation-and-preallocation-for-contiguous-layout&#34;&gt;
	Delayed allocation and Preallocation for contiguous layout
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;XFS also provides a new concept, delayed allocation, in which virtual extents can be allocated in the file system buffer pool.
These are blocks full of yet unwritten data that have not been layouted, and hence lack a physical position.
Only on flush these blocks are layouted, contiguously, and then written out linearly in large writes, to speed things up.&lt;/p&gt;
&lt;p&gt;This is a fundamental change to how the filesystem buffer cache works ‚Äì
previously it was possible to use &lt;code&gt;(device, physical block number)&lt;/code&gt; to identify buffer cache blocks and prevent duplicate buffer allocation.
When porting XFS to Linux, the Linux kernel initially could not accommodate strategies that do not use such identification in the normal buffer cache, so at first XFS required a separate buffer cache.
This got fixed later, as the porting progressed.&lt;/p&gt;
&lt;p&gt;To ensure that files can be layouted without fragmentation, in a single extent, XFS aggressively preallocates storage for open files.
The default amount of disk space preallocated is dependent on the amount of free space in the filesystem, and can be substantial.&lt;/p&gt;
&lt;p&gt;The internet is littered with questions by XFS users asking where their disk space is, and the answer is always &amp;ldquo;in the open file handles of &lt;code&gt;/var/log&lt;/code&gt;. Also, check the &lt;a href=&#34;https://man7.org/linux/man-pages/man5/xfs.5.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;manpage&lt;/a&gt;

 for &lt;code&gt;allocsize=&lt;/code&gt; and also check &lt;a href=&#34;https://linux-xfs.oss.sgi.narkive.com/jjjfnyI1/faq-xfs-speculative-preallocation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;/proc/sys/fs/xfs/speculative_prealloc_lifetime&lt;/code&gt;&lt;/a&gt;

.&amp;rdquo;&lt;/p&gt;
&lt;h3 id=&#34;locality&#34;&gt;
    &lt;a href=&#34;#locality&#34;&gt;
	Locality
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;XFS does not use allocation groups for locality much.
They exist mostly for concurrency.
Instead, file placement is mostly around directories and existing blocks of the current file.
The only exception is &amp;ldquo;new directories&amp;rdquo;, which are placed &amp;ldquo;away&amp;rdquo; from their parent directory by putting them into a different AG.&lt;/p&gt;
&lt;p&gt;In large files, if new extents need to be placed, they go &amp;ldquo;initially near the inode, then near the existing block in the file which is closest to the offset in the file for which we are allocating space&amp;rdquo;, as the paper specifies.
This places the inode close to the start of the file, and blocks added later to whatever is already present.&lt;/p&gt;
&lt;h2 id=&#34;large-directories&#34;&gt;
    &lt;a href=&#34;#large-directories&#34;&gt;
	Large directories
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;In the traditional Unix filesystem and in BSD FFS, directory name lookups are linear operations.
Large directories slow this down a lot, for any kind of pathname to inode translation.&lt;/p&gt;
&lt;p&gt;XFS chose the ubiquitous B+-Tree as a structure for directories, too, but with a quirk:
Since the keys are supposed to be filenames, a variable length structure, they would be completely different from all the other tree implementations in the filesystem.
The XFS authors did not like this idea, so they are hashing the filename into a fixed 4-byte name hash, and then store one or more directory entries as &lt;code&gt;(name, inode)&lt;/code&gt; pairs in the value.&lt;/p&gt;
&lt;p&gt;There was some tradeoff discussion involved in this, but the authors found that short keys allow storing many entries per block,
leading to wide trees, and thus faster lookups.
They boast &amp;ldquo;We can have directories with millions of entries&amp;rdquo;, something that was previously unthinkable in Unix filesystems.&lt;/p&gt;
&lt;h1 id=&#34;a-lot-of-code&#34;&gt;
    &lt;a href=&#34;#a-lot-of-code&#34;&gt;
	A lot of code
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/xfs-scaling.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;


&lt;em&gt;XFS Benchmarks in 1994 show nice and welcome linear scaling behavior that utilizes the hardware offered well.
It handles well on large boxes with (for 1994) high core-counts.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;XFS is a large filesystem.
Linux ext2 is only 5000 lines of kernel code (and about 10x this in user-land).
XFS is 50.000 lines of kernel code, and that is without the IRIX volume manager XLV (in Linux, the XFS port uses LVM2 instead).&lt;/p&gt;
&lt;p&gt;XFS was released under the GNU GPL in May 1999, and was ported into the Linux kernel starting in 2001.
As of 2014, it was supported in most Linux distributions and RHEL used it as the default filesystem.
And even in 2024 it is still holding up reasonably well, on HDD and on flash.&lt;/p&gt;
&lt;p&gt;It still is the filesystem with the best scaling behavior, the best concurrency behavior, and the most consistent commit times,
which makes it the preferred filesystem for any kind of database usage.
This is due to the elimination of several global locks that impair concurrent usage and performance in large filesystems,
and due to the consistent use of B+-Tree structures with &lt;code&gt;O(log(n))&lt;/code&gt; scaling behavior where before algorithms with worse scaling behavior have been used.
The use of extents also allows dynamically growing I/O sizes, benefiting throughput,
and together with the novel idea of delayed allocation encourage contiguous file placement.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>City of Amsterdam and Combustion Engines</title>
      <link>https://blog.koehntopp.info/2023/05/11/city-of-amsterdam-and-combustion-engines.html</link>
      <pubDate>Thu, 11 May 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/05/11/city-of-amsterdam-and-combustion-engines.html</guid>
      <description>&lt;p&gt;Electrive.net had an article about Copenhagen banning combustion engines in the city, starting 2030:
(&lt;a href=&#34;https://www.electrive.net/2023/05/08/kopenhagen-will-verbrenner-autos-ab-2030-aussperren/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Article in German&lt;/a&gt;

).
So I had to check what is the current state in Amsterdam.&lt;/p&gt;
&lt;h1 id=&#34;current-state&#34;&gt;
    &lt;a href=&#34;#current-state&#34;&gt;
	Current state
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;The Netherlands has a central register for license plates.
It is public, and anyone can check.
There are many places that allow you to do that for car, not owner data.
For &lt;a href=&#34;https://www.autoweek.nl/kentekencheck/P-664-rg/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;example&lt;/a&gt;

.&lt;/p&gt;
&lt;p&gt;The city of Amsterdam also allows you to check if a given license plate is allowed to enter the cities milieuzone.
You can &lt;a href=&#34;https://ontheffingen.amsterdam.nl/publiek/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;check yourself&lt;/a&gt;

.
And so can any license plate scanner.&lt;/p&gt;
&lt;p&gt;In the &lt;a href=&#34;https://www.amsterdam.nl/verkeer-vervoer/milieuzone-amsterdam/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;overview page&lt;/a&gt;

 for the milieuzone,
the city helpfully explains:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Let op:&lt;/strong&gt; dat u de Milieuzone mag inrijden betekent niet dat u ook in aanmerking komt voor een parkeervergunning.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Attention:&lt;/strong&gt; Note that being allowed to enter the Environmental Zone does not mean you are also eligible for a parking permit.&lt;/p&gt;
&lt;h1 id=&#34;after-2030&#34;&gt;
    &lt;a href=&#34;#after-2030&#34;&gt;
	After 2030
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;The rules for the milieuzone are becoming stricter &lt;a href=&#34;https://www.amsterdam.nl/verkeer-vervoer/milieuzone-amsterdam/aanscherping-milieuzones/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;starting 2025&lt;/a&gt;

,
and by 2030 no combustion engines are being allowed in the city at all.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NL-wide license plate check for &lt;a href=&#34;https://www.opwegnaarzes.nl/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;commercial vehicles&lt;/a&gt;

.&lt;/li&gt;
&lt;li&gt;New lorries will need to be electric starting 2025 to be allowed into the city.&lt;br&gt;
Existing lorries will have to be Euro 6 or better. There are some more rules for easing the changeover.
Starting 2030, no lorries with combustion engines are allowed into the city.&lt;/li&gt;
&lt;li&gt;Small commercial delivery vehicles (vans, Sprinters) with Diesel must be Euro 4 or better already.
New cars must be electric starting 2025. Euro 5 is required starting 2027, Euro 6 starting 2028,
no combustion starting 2028.&lt;/li&gt;
&lt;li&gt;Bus lines are in the process of being converted to electric, and this is nearly complete.
It will be finished by 2025.
Rules for charter buses are to follow.&lt;/li&gt;
&lt;li&gt;Taxis electric starting 2025.
Tax incentives and better starting places as well as priority for parking and taxi licenses are provided already.
This is going well, most Taxis are electric already.&lt;/li&gt;
&lt;li&gt;Scooters (25 km/h and 45 km/h) must be electric by 2025.
Get a pedelec, maybe?&lt;/li&gt;
&lt;li&gt;Ships (tourist and transport) must be electric by 2025.
Ferries over the river Ij are already being converted.
70% rebate for harbor fees for electric ships right now.&lt;/li&gt;
&lt;li&gt;Cars must be Euro 4 or better right now.
Only electric cars are allowed into the city by 2030.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;important-advice&#34;&gt;
    &lt;a href=&#34;#important-advice&#34;&gt;
	Important advice
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/scanauto.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;


&lt;em&gt;Scanautos are being used to automatically enforce parking rules inside the city.
They are checking around 800x more effective than an unaugmented parking enforcement human.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In Amsterdam, most major streets do not allow you to park on public ground.
Side streets often have only a limited number of public parking spots,
the others require a residential parking permit.
Parking in parking structures or in the street costs around 50 Euro/day if you find a space.&lt;/p&gt;
&lt;p&gt;Parking permits are &lt;strong&gt;not&lt;/strong&gt; shown on the dashboard, and similarly, parking violations are &lt;strong&gt;not&lt;/strong&gt; ticketed in paper behind the windshield wiper.
Instead, everything is based on automated license plate scanning:
Enter your license plate at the parking fee collector terminal,
the scanauto will countercheck what it scanned with the central database.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://algoritmeregister.amsterdam.nl/parkeercontrole/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Enforcement is automatic&lt;/a&gt;

, and the coverage is excellent.
If you do not pay, or overpark, you will be caught.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.amsterdam.nl/parkeren/parkeerbon/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;That will cost you&lt;/a&gt;

 at minimum 72.90 Euros in punishment,
plus fees, plus the unpaid parking fee.
In total this usually ends up between 110 Euros and 150 Euros
.
The target for processing (between parking violation and notification) is officially two days.
But it often is &amp;ldquo;while you still park&amp;rdquo; (20 minutes or less),
so near realtime.
This has the effect of ruining whatever you are currently doing in the city, so just park legally.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/overtoom.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;


&lt;em&gt;S106, Overtoom. A major inroad into the city. Note how this is one lane per direction, and no parking at the side.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The cheapest way to do that is to park at a &lt;a href=&#34;https://www.amsterdam.nl/en/parking/park-ride/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Park and Ride&lt;/a&gt;

,
and then take the tram or subway into the city.
Or just use the bus, tram, subway or train, starting at your door.&lt;/p&gt;
&lt;p&gt;The city does not believe into building roads to places that have more capacity than can be parked at the destination.
So most major inroads into Amsterdam are single lane.
Not only will you not be able to park in the city.
Most likely, you will also hate every minute of getting there before you have to turn around.
Be sensible, use OV.&lt;/p&gt;
&lt;h1 id=&#34;summary&#34;&gt;
    &lt;a href=&#34;#summary&#34;&gt;
	Summary
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/electric-charge-points.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Map of &lt;a href=&#34;https://www.amsterdam.nl/parkeren/elektrische-oplaadpunten-amsterdam/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;electric charge points&lt;/a&gt;

 in Amsterdam&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;So for anybody but private individual transport, Amsterdam will be fully electric by 2025,
and the final conversion will take another 5 years.
This is not an unrealistic goal.
If you walk through the city, you can see how the conversion is already in full swing at an amazing and still increasing speed.&lt;/p&gt;
&lt;p&gt;The city has built the required infrastructure in terms of charge points already,
and provides maps to prove it.&lt;/p&gt;
&lt;p&gt;But individual motorized transport does not scale to a city with the density of Amsterdam.
Cities are for humans, not for cars, and Amsterdam makes it very clear that cars are not welcome.
Use public transport to get around in Amsterdam.
That is already fully electric, and except for the buses always has been.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>It&#39;s a Modulith</title>
      <link>https://blog.koehntopp.info/2023/05/10/its-a-modulith.html</link>
      <pubDate>Wed, 10 May 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/05/10/its-a-modulith.html</guid>
      <description>&lt;p&gt;&amp;ldquo;Computers are simple&amp;rdquo; is what I am telling people I train.
&amp;ldquo;There are only Zeroes and Ones, and it is not getting much more complicated.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;&amp;ldquo;But computers are hard&amp;rdquo;, they respond.&lt;/p&gt;
&lt;p&gt;&amp;ldquo;That is correct.
In computer systems, complexity is almost never in the individual layers, but it comes from the width and breadth of the stack.
It&amp;rsquo;s in the interactions of the components that we are putting together.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;When you start with how a CPU is being built, and then put the layers of the stack on top of each other until you end up with a classical single-process application, in some object-oriented language, with a GUI ‚Äì that&amp;rsquo;s around two to three dozen layers of abstractions piled on top of each other.
Things that one could learn the internals of, and how they interact.
But that&amp;rsquo;s only local, without network stacks, communication protocols, proxies, and without the peculiarities of distributed systems, which open up the same exercise, again, only across, not down.&lt;/p&gt;
&lt;p&gt;There is a lot to be said about computer science as a science, because anything that complicated is working at all.
All the interfaces, encapsulations, and abstractions are obviously good for &lt;em&gt;something&lt;/em&gt; ‚Äì as long as they don&amp;rsquo;t leak.
When they do leak, things get weird, fast:
One is making a small change somewhere in the stack, an epsilon,
and somewhere else something acts up, non-linearly, and does a giant delta, and everybody is having a very sad day.&lt;/p&gt;
&lt;p&gt;So if developers prefer to sit in enclosed offices, without a phone, and with soundproof headphones,
that is because work on such systems is mostly to unfold the stack in your mind,
and to anticipate what will happen on all the other layers when you write a line of code.&lt;/p&gt;
&lt;h1 id=&#34;the-amazon-prime-video-team-publishes-a-paper&#34;&gt;
    &lt;a href=&#34;#the-amazon-prime-video-team-publishes-a-paper&#34;&gt;
	The Amazon Prime Video team publishes a paper
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;With this as a background, one can now read &amp;ldquo;&lt;a href=&#34;https://www.primevideotech.com/video-streaming/scaling-up-the-prime-video-audio-video-monitoring-service-and-reducing-costs-by-90&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Scaling up the Prime Video audio/video monitoring service and reducing costs by 90%&lt;/a&gt;

&amp;rdquo;,
a writeup published by the Amazon Prime Video Streaming Team.
They have implemented a functionality which probes frames from the video stream sent to customers, applies tests and recognizes certain artefacts that impair quality,
so that they can be corrected.&lt;/p&gt;
&lt;p&gt;Amazon being Amazon, they have implemented that as a pile of microservices that interact in an event-driven architecture with lambdas and step functions,
in order to shovel data from one S3 bucket into another, running the required analytics on the way.
Notification about things found are being put on SNS.&lt;/p&gt;
&lt;p&gt;That works as expected: The project was done exploratory, as a proof-of-concept, and they were able to show that it does what was requested.&lt;/p&gt;
&lt;p&gt;Scaling up, they then found that the distribution of components was suboptimal:
Lambdas and step functions are not good elements for batch processing video frames with ML detectors, because they have never been designed for this.
They are good components for web applications.&lt;/p&gt;
&lt;p&gt;Also, it turns out that S3 is not a good storage and communication mechanism for fast and very temporary IPC,
because a web storage with low cost is optimized for low transaction rates, and it targets consumers that can tolerate high latency.&lt;/p&gt;
&lt;p&gt;The article then presents a solution, which was to put all these things into a single container that are tightly coupled,
and put them into ECS.
Because the components are now within a single container, and hence on the same box, sharing the same memory,
they now can exchange video frames via shared memory instead of pushing them through http and TLS over the network.
Similarly, the lambdas and step function somewhere out on the network are now local procedure calls, or at least local RPC.&lt;/p&gt;
&lt;p&gt;Obviously, that eliminates a lot of communication latencies because the high-rpm part of the distributed system is now a single local application.&lt;/p&gt;
&lt;h1 id=&#34;what-was-learned&#34;&gt;
    &lt;a href=&#34;#what-was-learned&#34;&gt;
	What was learned
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;The surprising part, according to the team, was that this was a mostly painless process that required only minor code changes.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Conceptually, the high-level architecture remained the same.
We still have exactly the same components as we had in the initial design (media conversion, detectors, or orchestration).
This allowed us to reuse a lot of code and quickly migrate to a new architecture.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;they summarize.&lt;/p&gt;
&lt;p&gt;And that is maybe the takeaway from this article:
In a cleanly architected and properly encapsulated system, the components can be redistributed and rearranged with only minor code changes.
We can change the layout of the system without having to start over.
The architecture was not really changed, but mostly the components&amp;rsquo; deployment was rearranged.&lt;/p&gt;
&lt;h1 id=&#34;modulith&#34;&gt;
    &lt;a href=&#34;#modulith&#34;&gt;
	Modulith
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/modulith-microservices.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;


&lt;em&gt;A modulithic deployment of co-located microservices allows for easy scaling and rearrangement.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Unfortunately, the subtitle of the article is
&amp;ldquo;The move from a distributed microservices architecture to a monolith application helped achieve higher scale, resilience, and reduce costs&amp;rdquo;.
This sets wrong expectations and makes it harder to pick up the actual learning.&lt;/p&gt;
&lt;p&gt;What the AWS Prime Video team arrived at is most closely described as a
&lt;a href=&#34;https://www.informatik-aktuell.de/entwicklung/methoden/modulith-first-der-angemessene-weg-zu-microservices.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Modulith&lt;/a&gt;

,
only that they arrived at it the other way around.
Fowler suggests you start
&lt;a href=&#34;https://martinfowler.com/bliki/MonolithFirst.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Monolith first&lt;/a&gt;


and then chisel off the components you identify as standalone subservices.
They instead used pre-made AWS infrastructure components to build a highly modular prototype,
and then identified tightly coupled components and merged their deployment without giving up the modular structure.
Fowler himself points to
&lt;a href=&#34;https://samnewman.io/blog/2015/04/07/microservices-for-greenfield/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;an article by Sam Newman&lt;/a&gt;


and the book that came from it as a way of doing this.&lt;/p&gt;
&lt;p&gt;The result is not really a single-instance monolith, anyway.
Components are merged into a single ECS container, but of course ECS will deploy it with the required degree of parallelism,
and it is still part of a larger system that communicates in an event-driven architecture using lambdas and messages.&lt;/p&gt;
&lt;p&gt;So if this article is anything, it is an example of the benefits good observability has,
and how a good architecture allows you to rearrange the layout of well-isolated and structured components with clean interfaces at will.
The application can be made to run on different substrates, in order to react to different demands of scale or changing business requirements.&lt;/p&gt;
&lt;p&gt;Or in other words, people who understand how their stuff works have few problems to adjust their application to changing requirements.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>50 years in filesystems: 1984</title>
      <link>https://blog.koehntopp.info/2023/05/06/50-years-in-filesystems-1984.html</link>
      <pubDate>Sat, 06 May 2023 12:13:14 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/05/06/50-years-in-filesystems-1984.html</guid>
      <description>&lt;p&gt;This is part 2 of a series. The first part is &amp;ldquo;&lt;a href=&#34;https://blog.koehntopp.info/2023/05/05/50-years-in-filesystems-1974.html&#34;&gt;1974&lt;/a&gt;

&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Progress is sometimes hard to see, especially when you have been part of it or otherwise lived through it.
Often, it is easier to see if you compare modern educational material, and the problems discussed with older material.
And then look for the research papers and sources that fueled the change.&lt;/p&gt;
&lt;p&gt;In Linux (and Unix in general), this is easy.&lt;/p&gt;
&lt;h1 id=&#34;1984--the-bsd-fast-filing-system&#34;&gt;
    &lt;a href=&#34;#1984--the-bsd-fast-filing-system&#34;&gt;
	1984 ‚Äî The BSD Fast Filing System
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;The original Unix filesystem was doing well, but also had a large number of obvious problems.
BSD Unix undertook an effort to fix them, and this is documented in the book
&amp;ldquo;&lt;a href=&#34;https://www.amazon.de/Design-Implementation-4-3Bsd-Operating-System/dp/0201061961&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Design and Implementation of the 4.3BSD UNIX Operating System&lt;/a&gt;

&amp;rdquo;
by Leffler, McKusick et. al&lt;a href=&#34;http://libgen.rs/book/index.php?md5=61457A629D5DE3B8966141A9D51FE89B&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;.&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;A more concise, but also more academic discussion can be found in the classic 1984 paper &lt;a href=&#34;https://dsf.berkeley.edu/cs262/FFS.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;A Fast File System for UNIX&lt;/a&gt;

,
which lists Marshall McKusick, Bill Joy (then at Sun), Samuel Leffler (then at LucasFilm) and Robert Fabry as authors.
The paper promises a reimplementation of the Unix filesystem for higher throughput, better allocation and better locality of reference.&lt;/p&gt;
&lt;h2 id=&#34;the-hardware&#34;&gt;
    &lt;a href=&#34;#the-hardware&#34;&gt;
	The hardware
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;It is 1984.
The computers targeted by 4.3BSD are desktop and cabinet workstations.
These are machines with 32-bit data registers and 32-bit address registers.&lt;/p&gt;
&lt;p&gt;External data and address bus sizes vary:
Earlier 68k CPUs had smaller sized buses, but in 1984 the Motorola 68020 debuted.
It was the first 68k to offer buses with the full width of 32 bits, at a budget of ca. 200k transistors on the die.
Later the 68030 integrated the MMU, previously a separate chip,
and the 68040 also integrated the FPU, again previously a separate chip.&lt;/p&gt;
&lt;p&gt;Early Sun workstations, the Sun-3 series, feature these CPUs.
But Sun took the designs from the experimental Berkeley RISC systems and released the Sun-4 series in 1986 with SPARC architecture RISC chips.
SPARC architecture is not without compromises, but was very viable and saw continuous development until after the purchase of Sun by Oracle, which then killed both the SPARC, and later also the Itanium CPU architecture.&lt;/p&gt;
&lt;p&gt;Curt Schimmel discusses the tradeoffs made by SPARC in the MMU, register and memory access design, and why they made sense. See &lt;a href=&#34;https://www.amazon.de/UNIX-Systems-Modern-Architectures-Multiprocessing/dp/0201633388&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;UNIX Systems for Modern Architectures&lt;/a&gt;

&lt;a href=&#34;http://libgen.rs/book/index.php?md5=0E4A02E80A6250838CB1D3C3A1405CAD&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;.&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;In between, in 1985, the MIPS architecture debuted, which is another series of RISC CPU architectures. It also starts out as a fully 32-bit type of system, and found use in SGI workstations.&lt;/p&gt;
&lt;p&gt;HP had another RISC-type of CPU, the PA-RISC, an outgrowth of their &amp;ldquo;Spectrum&amp;rdquo; research programme, coming to market in 1986 (and later replaced by Intel&amp;rsquo;s failed Itanium).&lt;/p&gt;
&lt;p&gt;Systems pioneer DEC themselves had the VAX, a 32-bit cabinet computer with a CISC CPU, and that since 1977 already.
They would not go RISC until 1992, but then fully 64-bit with the Alpha AXP (&amp;ldquo;DEC Alpha&amp;rdquo;) architecture.
While interesting, this did not last long: with the sale to Compaq in 1998, the CPU was discontinued, and the IP was sold to Intel in 2001.&lt;/p&gt;
&lt;p&gt;In general, workstation type systems in 1984 had main memory in the low two-digit MB range, and ran at clock speeds of two-digit MHz system clocks.&lt;/p&gt;
&lt;h1 id=&#34;43bsds-fast-filing-system&#34;&gt;
    &lt;a href=&#34;#43bsds-fast-filing-system&#34;&gt;
	4.3BSD&amp;rsquo;s Fast Filing System
    &lt;/a&gt;
&lt;/h1&gt;
&lt;h2 id=&#34;the-traditional-filesystems-shortcomings&#34;&gt;
    &lt;a href=&#34;#the-traditional-filesystems-shortcomings&#34;&gt;
	The traditional filesystems shortcomings
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;The 32-bit VAX systems were being used for typical 1980&amp;rsquo;s workstation work, which include things such as image processing or VLSI chip design.
On these systems, the original Unix filesystem showed structural problems in keeping up with file size, I/O speed, and simple number of files.
Also, the tiny 512-byte I/O size slowed disk subsystem performance considerably.&lt;/p&gt;
&lt;p&gt;The paper mentions the strict segregation of filesystem metadata at the front of the file system from the actual data in the back part of the filesystem.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A 150 MB traditional UNIX file system consists of 4 megabytes of inodes followed by 146
megabytes of data.
This organization segregates the inode information from the data; thus accessing a file
normally incurs a long seek from the file‚Äôs inode to its data.
Files in a single directory are not typically
allocated consecutive slots in the 4 megabytes of inodes, causing many non-consecutive blocks of inodes to
be accessed when executing operations on the inodes of several files in a directory.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This defines one major goal for BSD FFS: Better filesystem layout, bringing metadata and data closer together,
storing files in a single directory closer together,
and preventing fragmentation of a file into small fragments that can be loaded only inefficiently.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/filesystem-fragmentierung.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;


&lt;em&gt;Fragmentation: Initially, four files are being created, each using 2 blocks.
Then the files B and D are being deleted.
The free space is then being reclaimed by the three-block-sized file E, which is stored in non-adjacent blocks.
This causes small disk seeks, and slow I/O.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Another goal stated is to increase disk block size.
Larger disk blocks benefit throughput in two ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Larger disk blocks provide larger units of I/O, so more data is transferred in a single I/O operation.&lt;/li&gt;
&lt;li&gt;Larger disk blocks also allow the filesystem to store more file pointers in an indirect block, greatly reducing the number of indirect block accesses.
This is primarily a problem if indirect blocks are not cached in a file system buffer cache.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The paper quotes the throughput of an already marginally optimized, traditional Unix filesystem at around 4% of the theoretical maximum,
which is abysmally bad.
This is mainly attributed to fragmentation, non-contiguous storage of adjacent blocks in a file.
Defragmentation, already suggested in 1976, was discarded as a non-viable idea.
The authors instead aim for a solution that places files sensibly in the first place.&lt;/p&gt;
&lt;h2 id=&#34;bsd-ffs-innovations&#34;&gt;
    &lt;a href=&#34;#bsd-ffs-innovations&#34;&gt;
	BSD FFS innovations
    &lt;/a&gt;
&lt;/h2&gt;
&lt;h3 id=&#34;cylinder-groups-and-understanding-chs&#34;&gt;
    &lt;a href=&#34;#cylinder-groups-and-understanding-chs&#34;&gt;
	Cylinder Groups and understanding CHS
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;The BSD FFS understands the physical layout of a harddisk, with &lt;a href=&#34;https://en.wikipedia.org/wiki/Cylinder-head-sector&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;cylinders, heads and sectors&lt;/a&gt;

 (CHS).
It divides the disk into cylinder groups, adjacent tracks of all disk heads.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/cylinder-groups.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;


&lt;em&gt;As the disk rotates, various disk heads reach inside the platter stack like a comb.
Each head marks a track on the disk, which is subdivided into physical disk blocks by the controller hardware.
Together, all tracks marked by all heads form a cylinder.
A cylinder group is a set of consecutive cylinders. (Image: &lt;a href=&#34;https://pages.cs.wisc.edu/~remzi/OSTEP/file-ffs.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OSTEP&lt;/a&gt;

, page 3)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Each cylinder group becomes a mini-version of a traditional Unix filesystem, with a copy of the superblock, its own local inode area, and local inode and block usage bitmaps.
The usage of bitmaps is also novel, as they replace the free lists used in the traditional filesystem.
As the filesystem has information about the CHS layout, it also makes sure that the superblock is not always placed on the same platter for each copy,
trying to make the filesystem better redundant against harddisk failure.&lt;/p&gt;
&lt;blockquote&gt;
&lt;h1 id=&#34;excursion-raid-and-other-efforts-at-berkeley&#34;&gt;
    &lt;a href=&#34;#excursion-raid-and-other-efforts-at-berkeley&#34;&gt;
	Excursion: Raid and other Efforts at Berkeley
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;The &lt;a href=&#34;https://www2.eecs.berkeley.edu/Pubs/TechRpts/1987/CSD-87-391.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RAID paper&lt;/a&gt;

 was published only several years later,
but &lt;a href=&#34;http://web.eecs.umich.edu/~michjc/eecs584/Papers/katz-2010.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;according to Katz&lt;/a&gt;

 was developed also in Berkeley, during the same time frame, 1983/1984.&lt;/p&gt;
&lt;p&gt;Katz also mentions that during that time Stonebraker was around, working on Ingres (a Postgres predecessor),
and refers to his demands for low-commit latency as driving the attempts on improving disk bandwidth with FFS and, later,  RAID.
Serious work on the RAID taxonomy we know today did not begin before 1987, though.&lt;/p&gt;
&lt;p&gt;The RAID paper was used by many startups and storage companies as the foundation of their development,
among them NetApp, and EMC (via Data General&amp;rsquo;s Clariion Disk Array)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;BSD FFS not only understood CHS geometry of disks, but also processor speed and disk rotational speed.
This allowed it to configure and record in the superblock an &lt;a href=&#34;https://en.wikipedia.org/wiki/Interleaving_%28disk_storage%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;interleave factor&lt;/a&gt;

 to optimize disk I/O throughput.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/interleave.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;


&lt;em&gt;The harddisk rotates continuously, but the CPU needs time to set up the next transfer.
During this time the head may have moved already past the next block start boundary, and now the system would need to wait one full rotation to be able to write.
Using an appropriate interleave factor, blocks of adjacent numbers are not stored adjacently on disk, but instead other blocks are interleaved in-between.
This gives the CPU enough time to think and set up the next block transfer.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The faster the CPU, the lower the interleave factor required.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;All of these optimizations became irrelevant relatively quickly the moment harddrives were sold with integrated controllers,
started to lie about their CHS geometry and ultimately as linear block addresses (LBA) took over.
But for ten to 15 years, this provided a nice performance advantage.&lt;/p&gt;
&lt;h3 id=&#34;large-blocks-smaller-fragments-and-tail-packing&#34;&gt;
    &lt;a href=&#34;#large-blocks-smaller-fragments-and-tail-packing&#34;&gt;
	Large blocks, smaller fragments, and tail packing
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Internally, FFS uses logical blocks of at least 4 KB size.
Anything with at least 4 KB block size can create files of 4 GB size with at most two levels of indirection.&lt;/p&gt;
&lt;p&gt;Large blocks make for faster I/O, but they also come with storage overhead, as files grow in sizes of blocks.
Since logical blocks in FFS are made up from multiple physical blocks, FFS introduces the concept of fragments to expose the smaller internal physical blocks.
Through tail packing, the ends of multiple files can be stored together in the same logical block, using only as many physical blocks as necessary.&lt;/p&gt;
&lt;p&gt;Additional logic was necessary to prevent a slowly growing file from going through phases of fragment-by-fragment growth and constant re-layouting.
To overcome this, space is being pre-allocated to full logical blocks, and tail packing only happens on file close when the preallocation is canceled.&lt;/p&gt;
&lt;h3 id=&#34;long-seek-layout-policy&#34;&gt;
    &lt;a href=&#34;#long-seek-layout-policy&#34;&gt;
	Long Seek Layout Policy
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;BSD FFS introduces a number of layout policies that control the placement of new directories, new files and the handling of large files.
Global policies are mostly concerned with choosing a well-suited cylinder group to place data in,
while local policies then handle the placement inside a cylinder group.&lt;/p&gt;
&lt;p&gt;The new filesystem layout has cylinder groups. Each has their own inode table, and free space bitmaps for inodes and blocks.
The filesystem aims to prevent fragmentation.&lt;/p&gt;
&lt;p&gt;This is of course impossible in certain circumstances:
If, for example, a cylinder group is 512 MB in size, and a file larger than 512 MB is to be written, it will use up one inode in that cylinder group, but all available free blocks are gone.
If a second file is to be placed into this cylinder group, the inode can be used, but the data blocks for that file need to be placed somewhere else ‚Äì which is undesirable.&lt;/p&gt;
&lt;p&gt;It would be better to force a long seek, a switch from one cylinder group to the next, for large files.
The filesystem would profit from forcing such a long seek every megabyte of filesize or so.
This would use up free blocks from one cylinder group to the next, evenly, while at the same time leaving some number of free blocks for other files in each cylinder group.&lt;/p&gt;
&lt;p&gt;This would, of course, fragment a file, on purpose, but also make sure the fragments are sufficiently large to allow large file I/O.
Fragmentation (non-adjacent placement of blocks in a file) is only really a performance problem if the fragments are too small to be read efficiently.&lt;/p&gt;
&lt;h3 id=&#34;directory-layout-policy&#34;&gt;
    &lt;a href=&#34;#directory-layout-policy&#34;&gt;
	Directory Layout Policy
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Files in the same directory are often used together.
It is useful to place all files in the same directory together in the same cylinder group.&lt;/p&gt;
&lt;p&gt;Of course, when this is done, it is also necessary to put different directories into different cylinder groups, to ensure even use of the filesystem space available.
That means a shell script such as&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#! /usr/bin/bash
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; i in &lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;seq -w &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; 10&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;do&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  touch file&lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  mkdir dir&lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;will create ten files named &lt;code&gt;fileXX&lt;/code&gt;, which will all be placed in the same cylinder group as the current directory.&lt;/p&gt;
&lt;p&gt;It will also create ten subdirectories of the current directory named &lt;code&gt;dirXX&lt;/code&gt;.
Each of them will be placed in a different cylinder group, if possible.
FFS will choose the cylinder group that has a greater than average number of free inodes, and the smallest number of directories already in it.&lt;/p&gt;
&lt;p&gt;The actual choice of the inode in a cylinder group is &amp;ldquo;next available&amp;rdquo;, so pretty simple.
But that is not a problem, because the whole cylinder group inode table fits into 8-16 blocks.&lt;/p&gt;
&lt;p&gt;For placement of data blocks, a lot of effort is invested into finding rotationally optimal block, given the needed interleave factor for this machine.&lt;/p&gt;
&lt;p&gt;BSD FFS requires some free space to be available in the filesystem at all times.
Many of its algorithms degenerate to the performance of the traditional file system if the filesystem fills up more than 90%.&lt;/p&gt;
&lt;h2 id=&#34;other-changes-and-improvements&#34;&gt;
    &lt;a href=&#34;#other-changes-and-improvements&#34;&gt;
	Other changes and improvements
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;BSD FFS also removes several limits that came with the traditional filesystem.&lt;/p&gt;
&lt;h3 id=&#34;long-inode-numbers-and-block-addresses&#34;&gt;
    &lt;a href=&#34;#long-inode-numbers-and-block-addresses&#34;&gt;
	Long Inode Numbers and Block Addresses
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;For example, &lt;a href=&#34;https://github.com/dspinellis/unix-history-repo/blob/BSD-4_3_Tahoe-Snapshot-Development/.ref-BSD-4_3/usr/src/sys/h/dir.h#L42&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Inode numbers are now 32-bit numbers&lt;/a&gt;

.
This increases the number of files possible per filesystem from 64 K to 4 G.&lt;/p&gt;
&lt;p&gt;The size of an &lt;a href=&#34;https://github.com/dspinellis/unix-history-repo/blob/BSD-4_3_Tahoe-Snapshot-Development/.ref-BSD-4_3/usr/src/sys/h/inode.h#L40-L59&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;inode&lt;/a&gt;

 has doubled:
It is now &lt;a href=&#34;https://github.com/dspinellis/unix-history-repo/blob/BSD-4_3_Tahoe-Snapshot-Development/.ref-BSD-4_3/usr/src/sys/h/inode.h#L61-L65&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;forced to be 128 bytes&lt;/a&gt;

 in size (with 20 unused bytes)
Also, disk block addresses are now 4 bytes.
At 4 KB block size, this is sufficient to account for 4 G blocks, or a maximum of 16 TB filesystem size.&lt;br&gt;
File length is recorded in a &lt;code&gt;quad&lt;/code&gt;, allowing for more than 4 G individual filesize.&lt;/p&gt;
&lt;p&gt;Inodes now contain 12 direct blocks, and three types of indirect blocks.
At 4 KB block size, this is good for 1024 block addresses per indirect block, resulting in
&lt;code&gt;12 + 1024 + 1024^2 + 1024^3 = 1074791436&lt;/code&gt; blocks per file, or a maximum filesize just north of 4 TB.&lt;/p&gt;
&lt;p&gt;Unix User-ID and Group-ID are still limited to a short, limiting the number of users and groups per system to 64 K.&lt;/p&gt;
&lt;p&gt;Space has been preallocated for 8-byte timestamps, even if the time types in the inode are still limited to 4 bytes.&lt;/p&gt;
&lt;h3 id=&#34;long-filenames&#34;&gt;
    &lt;a href=&#34;#long-filenames&#34;&gt;
	Long filenames
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;The traditional filesystem has directory slots of a fixed 16-byte length,
with 2 bytes for the inode number and 14 bytes for the filename.&lt;/p&gt;
&lt;p&gt;BSD FFS defined a &lt;a href=&#34;https://github.com/dspinellis/unix-history-repo/blob/BSD-4_3_Tahoe-Snapshot-Development/.ref-BSD-4_3/usr/src/sys/h/inode.h#L61-L65&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;more complex directory entry structure&lt;/a&gt;

.
A single entry contains a 4-byte inode number, a 2-byte record length and a 2-byte name length, and then the actual filename.
Filenames are limited to 255 bytes for each pathname component,
and directory entries are rounded up in length to the next 4-byte boundary.&lt;/p&gt;
&lt;p&gt;Directories are still essentially a linked list, and searching for names in large directories is slow.&lt;/p&gt;
&lt;p&gt;Searching for free space in directories is now more complicated:
To create a new directory entry, we now need to search through the directory from the start, trying to find a gap in the current structure that is large enough for the name we are being asked to create.
If none is found, the new name is appended at the end, growing the directory in size.&lt;/p&gt;
&lt;p&gt;Free space in directories is never reclaimed through compaction, only eventually re-used if a new name happens to fit.&lt;/p&gt;
&lt;h3 id=&#34;symlinks&#34;&gt;
    &lt;a href=&#34;#symlinks&#34;&gt;
	Symlinks
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;The traditional filesystem allowed a file to have multiple names, using the &lt;code&gt;link()&lt;/code&gt; system call and the hardlink mechanism.
Hardlinks are limited in number (a &lt;code&gt;short&lt;/code&gt;, so 64 K names).&lt;/p&gt;
&lt;p&gt;They can be lost accidentally, for example, by saving a hardlinked file with certain editors.
If the editor does write a file as &lt;code&gt;filename.new&lt;/code&gt;, then unlinks the old &lt;code&gt;filename&lt;/code&gt; and moves the new file into place, the hardlinked nature of the file will be modified.&lt;/p&gt;
&lt;p&gt;Hardlinks also reference the original inode of the file multiple times, so they cannot span filesystem boundaries.&lt;/p&gt;
&lt;p&gt;BSD introduces a new filetype (&lt;code&gt;l&lt;/code&gt;, symlink), and places a &amp;ldquo;replacement filename&amp;rdquo; in the linked file, which determines the link target location.
It can be an absolute or relative name (relative to the location of the symlink file).&lt;/p&gt;
&lt;p&gt;This creates a &amp;ldquo;soft&amp;rdquo; or &amp;ldquo;symbolic link.
Trying to access a symlink will kick off a reinterpretation of the filename in &lt;code&gt;namei()&lt;/code&gt; using the replacement filename,
resulting in the attempted &lt;code&gt;open()&lt;/code&gt; system call being deflected to the link target location.&lt;/p&gt;
&lt;p&gt;Since the deflection happens in &lt;code&gt;namei()&lt;/code&gt;, which can traverse filesystem boundaries, the new link type is not subject to the single filesystem limitation.
It is also not counting towards any link count limits.&lt;/p&gt;
&lt;h3 id=&#34;rename-system-call&#34;&gt;
    &lt;a href=&#34;#rename-system-call&#34;&gt;
	Rename System Call
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;BSD introduces the &lt;code&gt;rename()&lt;/code&gt; system call, which previously needed to be implemented as a library function using calls to &lt;code&gt;unlink()&lt;/code&gt; and &lt;code&gt;link()&lt;/code&gt;.
Since this uses more than one system call, the operation is not atomic:
It is subject to partial execution, and it is subject to malicious interferences, because it is a multistep process.&lt;/p&gt;
&lt;h3 id=&#34;quotas&#34;&gt;
    &lt;a href=&#34;#quotas&#34;&gt;
	Quotas
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;BSD also introduces the idea of filesystem usage quotas:
These are soft and hard limits on the number of files and the amount of disk space that a user or a group can use.&lt;/p&gt;
&lt;p&gt;In order to implement them in a useful way, the behavior of the filesystem had to be modified:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It is now a privileged operation to change the owner of a file away from oneself.
Without that, it is possible to create a directory that is only accessible for oneself, and then gift all files in it to another user.
The files would then count against that user&amp;rsquo;s quota.&lt;/li&gt;
&lt;li&gt;Similarly, it is now no longer possible to change the group membership of files to just any group.
Instead, only groups from the user&amp;rsquo;s group set can be used.&lt;/li&gt;
&lt;li&gt;And finally, new directories and files inherit their group from their parent directory, not from a users primary group.
That way, project directories would contain files counting against a project&amp;rsquo;s quota, not a user&amp;rsquo;s primary group quota.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;advisory-locking&#34;&gt;
    &lt;a href=&#34;#advisory-locking&#34;&gt;
	Advisory Locking
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Advisory file locking is already introduced in 4.2BSD.
For this, the new &lt;code&gt;flock()&lt;/code&gt; syscall has been implemented.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Locks can be shared (read locks) or exclusive (write locks).&lt;/li&gt;
&lt;li&gt;They always apply to the entire file, and not to byte ranges.&lt;/li&gt;
&lt;li&gt;No deadlock detection is attempted.&lt;/li&gt;
&lt;li&gt;They are tied to a file descriptor.
So when a process dies, its file-handles are automatically closed, which also automatically releases all locks held.
This is very robust, until &lt;code&gt;dup()&lt;/code&gt; and &lt;code&gt;fork()&lt;/code&gt; are coming into play.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Posix later tried to improve on this, introducing a second, completely different system of locks, using &lt;code&gt;fcntl()&lt;/code&gt;.
This is flawed in different ways, but can do byte-ranges, and it implements some rudimentary deadlock detection.&lt;/p&gt;
&lt;p&gt;Kernels that implement both systems such as Linux now have two different,
incompatible file locking implementations that do not know of each other.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://loonytek.com/2015/01/15/advisory-file-locking-differences-between-posix-and-bsd-locks/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;This article&lt;/a&gt;

 discusses all of this some more,
and has example programs.&lt;/p&gt;
&lt;h2 id=&#34;performance&#34;&gt;
    &lt;a href=&#34;#performance&#34;&gt;
	Performance
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;The authors note the following advantages in their paper:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ls&lt;/code&gt; and &lt;code&gt;ls -l&lt;/code&gt; are fast, because the inodes of the files in a single directory are within the same cylinder group.
Hence, reading and listing a directory is very low on seeks, and on seek distance (except for subdirectories, which are guaranteed to be far away).
They measure a 8x speedup for directories without subdirectories.&lt;/li&gt;
&lt;li&gt;Utilization of the theoretical maximal bandwidth increased from 3% in the traditional filesystem to 22% or even 47%, depending on the controller hardware used.
The authors are very proud of the results because they have been achieved on an actual production system with real user production data being layouted,
and not on a synthetic benchmark layout. Throughput is stable over the lifetime of the filesystem, as its file population changes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This solves the main drivers for the improvements: Better throughput and a stable layout that does not degrade performance over time.&lt;/p&gt;
&lt;p&gt;Additionally, a number of quality-of-life enhancements have been made, enabling more comfortable working in groups, and unlocking new functionality.&lt;/p&gt;
&lt;p&gt;While Linux contains no BSD code, the ext2 filesystem is pretty much an implementation-blind rewrite of the BSD FFS for Linux,
recreating the features as described in the literature without using any BSD code.&lt;/p&gt;
&lt;p&gt;Both BSD FFS and Linux ext2 are still non-logging filesystems that require a filesystem check after a crash.
They also cannot deal well with directories with many entries, and deal only slightly better with deep directory hierarchies.
Additional changes are required to enable truly large filesystems in order to keep up with increasing storage sizes.&lt;/p&gt;
&lt;p&gt;Also, other limitations of more hidden nature still apply:
Several places in the filesystem code are guarded by locks that make scaling certain operations hard on systems with high concurrency.&lt;/p&gt;
&lt;p&gt;It would take another ten years, until 1994, for SGI&amp;rsquo;s XFS to tackle these things.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>50 years in filesystems: 1974</title>
      <link>https://blog.koehntopp.info/2023/05/05/50-years-in-filesystems-1974.html</link>
      <pubDate>Fri, 05 May 2023 12:13:14 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/05/05/50-years-in-filesystems-1974.html</guid>
      <description>&lt;p&gt;Progress is sometimes hard to see, especially when you have been part of it or otherwise lived through it.
Often, it is easier to see if you compare modern educational material, and the problems discussed with older material.
And then look for the research papers and sources that fueled the change.&lt;/p&gt;
&lt;p&gt;In Linux (and Unix in general), this is easy.&lt;/p&gt;
&lt;h1 id=&#34;1974---unix-v7-file-system&#34;&gt;
    &lt;a href=&#34;#1974---unix-v7-file-system&#34;&gt;
	1974 - Unix V7 File System
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;We find the Unix Version 7 Research Release in Diomidis Spinellis &lt;a href=&#34;https://github.com/dspinellis/unix-history-repo/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;unix-history-repo&lt;/code&gt;&lt;/a&gt;

.
If we are reading
&lt;a href=&#34;https://www.amazon.de/Design-UNIX-Operating-System-Prentice/dp/0132017997&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Design of the Unix Operating System&lt;/a&gt;


by Maurice J. Bach
&lt;a href=&#34;https://www.pdfdrive.com/the-design-of-the-unix-operating-system-maurice-bach-e25830714.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;,&lt;/a&gt;


we would want to look at the
&lt;a href=&#34;https://github.com/dspinellis/unix-history-repo/tree/Research-V7-Snapshot-Development&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Research V7 Snapshot&lt;/a&gt;


branch of that Repository.&lt;/p&gt;
&lt;h2 id=&#34;machines&#34;&gt;
    &lt;a href=&#34;#machines&#34;&gt;
	Machines
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;It is 1974.
Computers have a single &amp;ldquo;core&amp;rdquo;, the central processing unit.
In some computers, this is no longer a device with parts, such as boards for the arithmetic logic unit, registers, sequencers and microcode memory, but a single integrated chip.
The new devices are called microcomputers, as opposed to the older generation of minicomputers.
These new CPUs sometimes have thousands of transistors on a single chip.&lt;/p&gt;
&lt;h2 id=&#34;kernels&#34;&gt;
    &lt;a href=&#34;#kernels&#34;&gt;
	Kernels
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;In Unix, we are dealing with system resources as configured in a header file.
&lt;a href=&#34;https://github.com/dspinellis/unix-history-repo/blob/Research-V7-Snapshot-Development/usr/sys/h/param.h&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Default values&lt;/a&gt;


are shown here, and the data structures are arrays, with the values shown being the respective array sizes.
To change them, you edit the file, recompile and relink the kernel, and then reboot.&lt;/p&gt;
&lt;p&gt;We have a file system buffer cache using &lt;code&gt;NBUF&lt;/code&gt; (29) disk blocks of 512 bytes.
We have an inode array of &lt;code&gt;NINODE&lt;/code&gt; (200) entries, and we can mount up to &lt;code&gt;NMOUNT&lt;/code&gt; (8) filesystems concurrently.
A user can have &lt;code&gt;MAXUPRC&lt;/code&gt; (25) processes running, for a total of &lt;code&gt;NPROC&lt;/code&gt; (150) system processes.
Each process can have up to &lt;code&gt;NOFILE&lt;/code&gt; (20) files open.&lt;/p&gt;
&lt;p&gt;Reading Bach and the original V7 sources is interesting, despite the fact that things are completely outdated, because a lot of core concepts are much clearer,
and a lot of structures are a lot simpler.
Sometimes even archaic.
But this is what defines the behavior of Unix File Systems, to this day, because the accidental behavior of V7 Unix became immortalized in the POSIX standard,
and every file system after had to conform to it.
Check &lt;a href=&#34;https://blog.koehntopp.info/2018/11/29/but-is-it-atomic.html#source-dive-why-are-writes-atomic&#34;&gt;But Is It Atomic?&lt;/a&gt;

 for an example.&lt;/p&gt;
&lt;h1 id=&#34;core-concepts&#34;&gt;
    &lt;a href=&#34;#core-concepts&#34;&gt;
	Core Concepts
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;The basic concepts and structures of Unix Filesystems are from this time, and from this system.
Some of them exist even in modern systems.&lt;/p&gt;
&lt;p&gt;The disk is an array of blocks. It begins at block 0, and stretches to block n.
At the beginning of the filesystem we find the &lt;a href=&#34;https://github.com/dspinellis/unix-history-repo/blob/Research-V7-Snapshot-Development/usr/sys/h/filsys.h&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;superblock&lt;/a&gt;

.
It is located &lt;a href=&#34;https://github.com/dspinellis/unix-history-repo/blob/Research-V7-Snapshot-Development/usr/sys/h/param.h#L89&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;at block number 1&lt;/a&gt;

 of the filesystem.
The &lt;a href=&#34;https://github.com/dspinellis/unix-history-repo/blob/Research-V7-Snapshot-Development/usr/sys/sys/sys3.c#L128-L192&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;mount system call&lt;/a&gt;

 finds an empty &lt;a href=&#34;https://github.com/dspinellis/unix-history-repo/blob/Research-V7-Snapshot-Development/usr/sys/h/mount.h#L6-L11&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;mount&lt;/a&gt;

 structure, reads the superblock off disk and keeps it as part of the mount structure.&lt;/p&gt;
&lt;h2 id=&#34;inode&#34;&gt;
    &lt;a href=&#34;#inode&#34;&gt;
	Inode
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;The in-memory superblock has fields for an array of inodes (a &lt;code&gt;short&lt;/code&gt;) on disk.
An &lt;a href=&#34;https://github.com/dspinellis/unix-history-repo/blob/Research-V7-Snapshot-Development/usr/sys/h/ino.h&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;inode&lt;/a&gt;

 is a structure that describes a file as a variable length array of blocks, and some metadata.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-C&#34; data-lang=&#34;C&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dinode&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;kt&#34;&gt;unsigned&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;short&lt;/span&gt;	&lt;span class=&#34;n&#34;&gt;di_mode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;  &lt;span class=&#34;cm&#34;&gt;/* mode and type of file */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;kt&#34;&gt;short&lt;/span&gt;	&lt;span class=&#34;n&#34;&gt;di_nlink&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;    	      &lt;span class=&#34;cm&#34;&gt;/* number of links to file */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;kt&#34;&gt;short&lt;/span&gt;	&lt;span class=&#34;n&#34;&gt;di_uid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;      	      &lt;span class=&#34;cm&#34;&gt;/* owner&amp;#39;s user id */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;kt&#34;&gt;short&lt;/span&gt;	&lt;span class=&#34;n&#34;&gt;di_gid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;      	      &lt;span class=&#34;cm&#34;&gt;/* owner&amp;#39;s group id */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;kt&#34;&gt;off_t&lt;/span&gt;	&lt;span class=&#34;n&#34;&gt;di_size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;     	      &lt;span class=&#34;cm&#34;&gt;/* number of bytes in file */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;kt&#34;&gt;char&lt;/span&gt;  	&lt;span class=&#34;n&#34;&gt;di_addr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;40&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;	  &lt;span class=&#34;cm&#34;&gt;/* disk block addresses */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;kt&#34;&gt;time_t&lt;/span&gt;	&lt;span class=&#34;n&#34;&gt;di_atime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;   	  &lt;span class=&#34;cm&#34;&gt;/* time last accessed */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;kt&#34;&gt;time_t&lt;/span&gt;	&lt;span class=&#34;n&#34;&gt;di_mtime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;   	  &lt;span class=&#34;cm&#34;&gt;/* time last modified */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;kt&#34;&gt;time_t&lt;/span&gt;	&lt;span class=&#34;n&#34;&gt;di_ctime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;   	  &lt;span class=&#34;cm&#34;&gt;/* time created */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;};&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#define	INOPB	8	&lt;/span&gt;&lt;span class=&#34;cm&#34;&gt;/* 8 inodes per block */&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;&lt;span class=&#34;cm&#34;&gt;/*
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt; * the 40 address bytes:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt; *	39 used; 13 addresses
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt; *	of 3 bytes each.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt; */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;The inode as it appears on disk. 8 inodes fit into a 512-byte disk block, so they are aligned at 64 byte boundaries.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The inode array on the filesystem has a &lt;code&gt;short&lt;/code&gt; count, so there can be up to 65535 inodes in a filesystem.
As each file requires an inode, there can only be that many files per filesystem.&lt;/p&gt;
&lt;p&gt;Each file has some fixed properties:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(2 bytes) a &lt;code&gt;mode&lt;/code&gt; (the file type and access permissions combined).&lt;/li&gt;
&lt;li&gt;(2 bytes) a link count (&lt;code&gt;nlink&lt;/code&gt;), the number of names this file has.&lt;/li&gt;
&lt;li&gt;(2 bytes) a &lt;code&gt;uid&lt;/code&gt;, the owner.&lt;/li&gt;
&lt;li&gt;(2 bytes) a &lt;code&gt;gid&lt;/code&gt;, the owner&amp;rsquo;s group id.&lt;/li&gt;
&lt;li&gt;(4 bytes) a &lt;code&gt;size&lt;/code&gt;, the length of the file in bytes (defined as an &lt;code&gt;off_t&lt;/code&gt;, a &lt;code&gt;long&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;(40 bytes) an &lt;code&gt;addr&lt;/code&gt; array of disk block addresses&lt;/li&gt;
&lt;li&gt;(3x 4 bytes) three times, an &lt;code&gt;atime&lt;/code&gt; (access time), &lt;code&gt;mtime&lt;/code&gt; (modification time) and &lt;code&gt;ctime&lt;/code&gt; (supposedly create time, but really the time of the last inode change).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;for a total size of 64 bytes.&lt;/p&gt;
&lt;h2 id=&#34;bmap&#34;&gt;
    &lt;a href=&#34;#bmap&#34;&gt;
	bmap()
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;addr&lt;/code&gt; array contains 40 bytes, but it stores 13 disk block addresses, each using 3 bytes.
This is good for 24 bits, or 16 megablocks of 512 bytes, each, for a total filesystem size of 8M kilobytes, or 8 GB.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/rl02-front.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;


&lt;em&gt;Front panel of a PDP-11 RL02 disk drive, from &lt;a href=&#34;https://www.pdp-11.nl/peripherals/disk/rl-info.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pdp-11.nl&lt;/a&gt;

&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;For comparison, a &lt;a href=&#34;https://www.pdp-11.nl/peripherals/disk/rl-info.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDP-11 RL02K disk cartridge&lt;/a&gt;

 held 10.4 MB,
but the newer &lt;a href=&#34;https://lastin.dti.supsi.ch/VET/disks/RA92/EK-ORA90-UG.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RA92&lt;/a&gt;

 could store 1.5 GB.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;addr&lt;/code&gt; array is being used in the &lt;a href=&#34;https://github.com/dspinellis/unix-history-repo/blob/Research-V7-Snapshot-Development/usr/sys/sys/subr.c#L9-L120&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bmap() function&lt;/a&gt;

.
The function consumes an inode (&lt;code&gt;ip&lt;/code&gt;) and a logical block number &lt;code&gt;bn&lt;/code&gt; and returns a physical block number.
That is, it maps a block in a file to a block on a disk, hence the name.&lt;/p&gt;
&lt;p&gt;The first 10-block pointers are stored directly in the inode.
That is, to access for example block 0, &lt;code&gt;bmap()&lt;/code&gt; &lt;a href=&#34;https://github.com/dspinellis/unix-history-repo/blob/Research-V7-Snapshot-Development/usr/sys/sys/subr.c#L40&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;will look up&lt;/a&gt;

 &lt;code&gt;di_addr[0]&lt;/code&gt; in the inode and return this block number.&lt;/p&gt;
&lt;p&gt;Additional blocks are stored in an indirect block, and the indirect block is stored in the inode.
For even larger files, a double indirect block is allocated, and points to more indirect blocks, and finally very large files need even triple indirect blocks.&lt;/p&gt;
&lt;p&gt;The code &lt;a href=&#34;https://github.com/dspinellis/unix-history-repo/blob/Research-V7-Snapshot-Development/usr/sys/sys/subr.c#L60-L73&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;first determines the number of indirections&lt;/a&gt;

,
grab the &lt;a href=&#34;https://github.com/dspinellis/unix-history-repo/blob/Research-V7-Snapshot-Development/usr/sys/sys/subr.c#L78&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;appropriate indirect block&lt;/a&gt;

,
and then &lt;a href=&#34;https://github.com/dspinellis/unix-history-repo/blob/Research-V7-Snapshot-Development/usr/sys/sys/subr.c#L91-L112&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;resolve the indirection&lt;/a&gt;

 the appropriate number of times.&lt;/p&gt;
&lt;p&gt;This results in the following famous picture:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/1994/02/filestructure.gif&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Original Unix file structure with increasing numbers of indirect accesses for increasingly larger files.
This forms a compressed array, where short files can be accessed directly with data from the inode, whereas larger files are using increasingly indirect access.
For performance, it is crucial to keep indirect blocks in the file system buffer cache.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;How this scales is dependent on the block size (512 bytes back then, 4096 bytes these days), and the size of a block number in bytes (originally 3 bytes, later 4 or even 8 bytes).&lt;/p&gt;
&lt;h2 id=&#34;atomic-writes&#34;&gt;
    &lt;a href=&#34;#atomic-writes&#34;&gt;
	Atomic writes
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Writes to files happen under a lock, so they are always atomic.
This is true even for long writes, which span multiple block boundaries, and is discussed at length in
&lt;a href=&#34;https://blog.koehntopp.info/2018/11/29/but-is-it-atomic.html#source-dive-why-are-writes-atomic&#34;&gt;But Is It Atomic?&lt;/a&gt;

.&lt;/p&gt;
&lt;p&gt;This also means that even with multiple writer processes, on a single file there can be only ever one disk write active at any point in time.
This is very inconvenient for authors of database systems.&lt;/p&gt;
&lt;h2 id=&#34;naming-files&#34;&gt;
    &lt;a href=&#34;#naming-files&#34;&gt;
	Naming files
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;A directory is a file with a special type (directory), and a &lt;a href=&#34;https://github.com/dspinellis/unix-history-repo/blob/Research-V7-Snapshot-Development/usr/sys/h/dir.h&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;fixed record structure&lt;/a&gt;

.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-C&#34; data-lang=&#34;C&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#ifndef	DIRSIZ
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#define	DIRSIZ	14
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#endif
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;struct&lt;/span&gt;	&lt;span class=&#34;n&#34;&gt;direct&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;kt&#34;&gt;ino_t&lt;/span&gt;	&lt;span class=&#34;n&#34;&gt;d_ino&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;kt&#34;&gt;char&lt;/span&gt;	&lt;span class=&#34;n&#34;&gt;d_name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;DIRSIZ&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;};&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;A directory entry contains an inode number (an &lt;code&gt;unsigned int&lt;/code&gt;), and a filename which can be up to 14 bytes long. This fits 32 directory entries into a disk block, and 320 directory entries into the 10 disks blocks that can being referenced by the direct blocks of a directory file.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The lower filesystem is a sea of files.
Files have no names, only numbers.&lt;/p&gt;
&lt;p&gt;The upper filesystem uses a special type of file, with a simple 16-byte record structure,
to assign a name of up to 14 characters to a file.
A special function, &lt;code&gt;namei()&lt;/code&gt;
&lt;a href=&#34;https://github.com/dspinellis/unix-history-repo/blob/Research-V7-Snapshot-Development/usr/sys/sys/nami.c#L9-L200&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;converts a filename into an inode number&lt;/a&gt;

.&lt;/p&gt;
&lt;p&gt;Pathnames passed to &lt;code&gt;namei()&lt;/code&gt; are hierarchical:
they can contain &lt;code&gt;/&lt;/code&gt; as a path separator, and they are being terminated by &lt;code&gt;\0 (nul)&lt;/code&gt;.
&lt;a href=&#34;https://github.com/dspinellis/unix-history-repo/blob/Research-V7-Snapshot-Development/usr/sys/sys/nami.c#L37-L41&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Pathnames&lt;/a&gt;

 either start with &lt;code&gt;/&lt;/code&gt;,
in which case the traversal begins at the filesystem root, making the filename absolute.
Or they do not, in which case traversal starts at &lt;code&gt;u.u_cdir&lt;/code&gt;, the current directory.&lt;/p&gt;
&lt;p&gt;The function then consumes pathname component after component,
using the currently active directory and searching linearly for the name of the current component in that directory.
It ends when the last pathname component is found, or if at any stage a component is not found.
It also ends,
if at any point in time, for any directory in the path,
&lt;a href=&#34;https://github.com/dspinellis/unix-history-repo/blob/Research-V7-Snapshot-Development/usr/sys/sys/nami.c#L91&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;we have no x-permission&lt;/a&gt;

.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/dspinellis/unix-history-repo/blob/Research-V7-Snapshot-Development/usr/sys/sys/nami.c#L179&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Some entries are magical&lt;/a&gt;

:
They are mountpoints.
When we encounter them, we change from the directory entry of the current node and filesystem to the root inode of the mounted filesystem.
This makes all filesystems in Unix appear as a single tree, and &amp;ldquo;drives are changed&amp;rdquo; by simply going to a different directory.&lt;/p&gt;
&lt;p&gt;The function ultimately returns a pointer to the inode for the given pathname, creating (or deleting) the inode (and directory entry) if necessary and desired.
It is a centralized point for directory traversal and access permission checks.&lt;/p&gt;
&lt;h1 id=&#34;novel-ideas-and-limits&#34;&gt;
    &lt;a href=&#34;#novel-ideas-and-limits&#34;&gt;
	Novel ideas and Limits
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;This very early Unix filesystem has a number of very nice properties:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;It presents multiple filesystems as one single unified tree.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Files are structureless arrays of bytes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;These arrays are stored internally in a variable depth dynamic array, using a system of increasingly deeply nested indirect blocks.
This allows O(1) disk seeks.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Lower filesystem (creating files) and upper filesystem (structuring files into a tree) are clearly separated.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pathname traversal is the only way to get an inode, and along the way permissions are always checked.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There are very few characters in filenames that are special, &lt;code&gt;/&lt;/code&gt; and &lt;code&gt;\0 (nul)&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We also have clear limitations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Files can only have 16M blocks.&lt;/li&gt;
&lt;li&gt;Filesystems can only have 65535 inodes, which is very limited.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And there are a number of annoying limitations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;There can be only one writer active per file, which kills concurrency.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Directory lookups are linear scans, so they become very slow for large directories (more than 320 entries).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There is no system for mandatory file locking.
There are several systems for advisory file locking.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And a few quirks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;There is no &lt;code&gt;delete()&lt;/code&gt; system call.
We have &lt;code&gt;unlink()&lt;/code&gt;, which removes a file name,
and files that have zero names and zero open file handles are being automatically collected.
This has a few unusual consequences,
for example, disk space is only freed if a completely unlinked file is also completely closed.
Generations of Unix sysadmins have asked where their disk space is,
when a deleted log file in &lt;code&gt;/var/log&lt;/code&gt; was still kept open by some forgotten process.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Initially there is no &lt;code&gt;mkdir()&lt;/code&gt; and &lt;code&gt;rmdir()&lt;/code&gt; system call, which leads to exploitable race conditions.
This is fixed in later versions of Unix.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There are a few operations that are accidentally atomic (like the write(2) system call), or have been made atomic after they have been exploited (&lt;code&gt;mknod(2)&lt;/code&gt; and &lt;code&gt;mkdir(2)&lt;/code&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Structurally, it is annoying that the inode table and free maps for blocks and inodes are at the beginning of the filesystem, and disk space is allocated linearly from the front of the disk, too.
This leads to a seek intense structure, and enables filesystem fragmentation (in which files are being stored in non-adjacent blocks).&lt;/p&gt;
&lt;p&gt;Traversing a directory structure means reading a directories inode at the beginning of the disk,
going to the data blocks further back,
then reading the next inode of the next pathname component from the beginning of the disk,
and going back the data blocks in the back.
This goes back and forth, once for each pathname component, and is not necessarily fast.&lt;/p&gt;
&lt;h2 id=&#34;today-and-improvements&#34;&gt;
    &lt;a href=&#34;#today-and-improvements&#34;&gt;
	Today, and Improvements
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;The PDP-11 V7 Unix filesystem got a faithful reimplementation as the  &lt;code&gt;minix&lt;/code&gt; filesystem, with all its limitations.
In modern Linux, it has been removed from the kernel source tree because it is no longer useful.&lt;/p&gt;
&lt;p&gt;We will see in a later article about the BSD fast filesystem, how the data can be better layouted on disk,
how we can implement longer filenames, more inodes, and how we can speed things up a bit by taking physical properties of the disk into account.&lt;/p&gt;
&lt;p&gt;Only even newer filesystems will be dealing with linear directory lookup times, single writers or limited file metadata.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MySQL: SeveralNines Podcast with Kris</title>
      <link>https://blog.koehntopp.info/2023/04/04/mysql-sovereign-dbaas-decoded.html</link>
      <pubDate>Tue, 04 Apr 2023 12:13:14 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/04/04/mysql-sovereign-dbaas-decoded.html</guid>
      <description>&lt;p&gt;Back in October last year, I had been speaking to a few long-time friends at SeveralNines for a podcast.
The recording is now out, and you can listen to it at &lt;a href=&#34;https://www.buzzsprout.com/2094584&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this location&lt;/a&gt;

 or in the Podcast Player of your choice.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.buzzsprout.com/2094584/12080570-booking-com-pt-1-running-data-infrastructure-at-an-enterprise-scale&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Booking.com, Part 1 - Running data infrastructure at an Enterprise scale&lt;/a&gt;

&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.buzzsprout.com/2094584/12155962-booking-com-pt-2-how-booking-com-built-their-own-sovereign-dbaas-at-scale&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Booking.com, Part 2 - How Booking.com built their own Sovereign DBaaS at scale&lt;/a&gt;

&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>

