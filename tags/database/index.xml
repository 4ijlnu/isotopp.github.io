<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>database on Die wunderbare Welt von Isotopp</title>
    <link>https://blog.koehntopp.info/tags/database.html</link>
    <description>Recent content in database on Die wunderbare Welt von Isotopp</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 25 Feb 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://blog.koehntopp.info/tags/database/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>MySQL from Below</title>
      <link>https://blog.koehntopp.info/2021/02/25/mysql-from-below.html</link>
      <pubDate>Thu, 25 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2021/02/25/mysql-from-below.html</guid>
      <description>When you insert data into a database and run COMMIT you expect things to be there: Atomically, Consistent, Isolated and Durable , like Codd commanded us 40 years ago, but also quickly. There is a surprising amount of sophistication being poured into this, but since I do not want to shame MongoDB and Redis developers in this post, I am not going to talk about that much in this place.</description>
    </item>
    
    <item>
      <title>Validating storage</title>
      <link>https://blog.koehntopp.info/2021/02/24/validating-storage.html</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2021/02/24/validating-storage.html</guid>
      <description>Where I work, we try to run databases in a memory saturated way. That is, we try to provide so much memory that the working set of the database is memory resident, or in other words, the number of disk reads after an initial warmup is no longer dependent on the database load.
Workload Intelligence Analytics showing &amp;ldquo;IOPS over time&amp;rdquo; for a mixed read/write benchmark on Datera iSCSI.
We can validate and prove that with automated load testing: For each replication chain we single out a production host, and increase the hosts weight in the load balancer until the system load1 becomes critical.</description>
    </item>
    
    <item>
      <title>MySQL: Ecosystem fragmentation</title>
      <link>https://blog.koehntopp.info/2020/10/28/mysql-ecosystem-fragmentation.html</link>
      <pubDate>Wed, 28 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/10/28/mysql-ecosystem-fragmentation.html</guid>
      <description>Sometimes things change in a way that is hard to put a finger on, but I am doing this MySQL thing since 3.23, and commercially since 2005, and the environment is changing. These days, when you talk to people in need of MySQL, the first thing you have to ask them is &amp;ldquo;Which MySQL&amp;rdquo;. And by that I do not mean a version number in the first place.
The answer may be:</description>
    </item>
    
    <item>
      <title>An unexpected pool size increase</title>
      <link>https://blog.koehntopp.info/2020/10/07/an-unexpeced-pool-size-increase.html</link>
      <pubDate>Wed, 07 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/10/07/an-unexpeced-pool-size-increase.html</guid>
      <description>At work, replication chains have a single primary database node, to which you write, and then multiple replicas, in multiple AZs.
Here is what the one sample chain looks like in Orchestrator:
instance-918d is the current primary, in the blue AZ. Replicas in orange and green are in other AZs. Blue badges indicate multiple replicas, eg (38) means 38 machines.
When you talk to a database, you get two database handles:</description>
    </item>
    
    <item>
      <title>What are the problems with POSIX?</title>
      <link>https://blog.koehntopp.info/2020/10/05/what-are-the-problems-with-posix.html</link>
      <pubDate>Mon, 05 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/10/05/what-are-the-problems-with-posix.html</guid>
      <description>Every once in a while there is the IT news article that kind of triggers me. This time it was &amp;ldquo;Object-Storage-Protokoll könnte Posix ablösen&amp;rdquo; in german computer news site Golem . The article speaks about mmap(), NVMEoF and object storage and how it could revolutionize or complete object storages, but does not link to an original article, names no persons and no paper. Also, what do these things - mmap, NVMEoF, object storage and Posix, even have in common?</description>
    </item>
    
    <item>
      <title>MySQL: Import CSV, not using LOAD DATA</title>
      <link>https://blog.koehntopp.info/2020/09/28/mysql-import-csv-not-using-load-data.html</link>
      <pubDate>Mon, 28 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/09/28/mysql-import-csv-not-using-load-data.html</guid>
      <description>All over the Internet people are having trouble getting LOAD DATA and LOAD DATA LOCAL to work. Frankly, do not use them, and especially not the LOCAL variant. They are insecure, and even if you get them to work, they are limited and unlikely to do what you want. Write a small data load program as shown below.
Not using LOAD DATA LOCAL   The fine manual says :</description>
    </item>
    
    <item>
      <title>Importing account statements and building a data warehouse</title>
      <link>https://blog.koehntopp.info/2020/09/26/my-private-data-warehouse.html</link>
      <pubDate>Sat, 26 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/09/26/my-private-data-warehouse.html</guid>
      <description>This is an update and translation of a much older article , which I wrote in German Language back then. I was experimenting with importing the account statements from my German Sparkasse, which at that time were being made available as a CSV.
The initial data load   The data looked like this:
$ head -2 /home/kris/Documents/banking/umsatz-22758031-29122004.csv &amp;#34;Local Account&amp;#34;;&amp;#34;Book Date&amp;#34;;&amp;#34;Valuta Date&amp;#34;;&amp;#34;Transaction Type&amp;#34;; &amp;#34;Purpose&amp;#34;; &amp;#34;Remote Party&amp;#34;;&amp;#34;Remote Account&amp;#34;;&amp;#34;Bank Code&amp;#34;; &amp;#34;Amount&amp;#34;;&amp;#34;Currency&amp;#34;;&amp;#34;Info&amp;#34; &amp;#34;08154711&amp;#34;;&amp;#34;30.12&amp;#34;;&amp;#34;30.12.05&amp;#34;;&amp;#34;Direct Debit&amp;#34;; &amp;#34;DRP 08154711 040441777 INKL.</description>
    </item>
    
    <item>
      <title>MySQL: automatic partitions surely would be nice</title>
      <link>https://blog.koehntopp.info/2020/09/25/mysql-dynamic-partitions-suck.html</link>
      <pubDate>Fri, 25 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/09/25/mysql-dynamic-partitions-suck.html</guid>
      <description>In Deleting data we have been looking at a process that loads data into MySQL, leveraging partitions to make it easier and faster to later get rid of the data again. For this, we created three processes, a data loader process, and two observers - one for creating partitions, and one for deleting them.
The observer processes have been running ANALYZE TABLES and then polling INFORMATION_SCHEMA.PARTITIONS every 1/10th of a second to check if intervention is needed.</description>
    </item>
    
    <item>
      <title>MySQL: Deleting data</title>
      <link>https://blog.koehntopp.info/2020/09/24/mysql-deleting-data.html</link>
      <pubDate>Thu, 24 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/09/24/mysql-deleting-data.html</guid>
      <description>Completing the data lifecycle is often harder than originally expected: Deleting data can cost sometimes way more than inserting it in the first place. MySQL Partitions can offer a way out. We have an earlier post on the subject.
A sample table, and a problem statement   Let&amp;rsquo;s define a kind of log table, to which data is added with an auto_increment id value and some data.
#! /usr/bin/env python3 from time import sleep from random import randint from multiprocessing import Process import click import MySQLdb import MySQLdb.</description>
    </item>
    
    <item>
      <title>MySQL: Provisioning .mylogin.cnf</title>
      <link>https://blog.koehntopp.info/2020/09/23/mylogin-cnf.html</link>
      <pubDate>Wed, 23 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/09/23/mylogin-cnf.html</guid>
      <description>MySQL uses connection and config parameters from a number of possible sources. The easiest way to find out where it is looking for config files is to run
$ mysql --help | grep cnf order of preference, my.cnf, $MYSQL_TCP_PORT, /etc/my.cnf /etc/mysql/my.cnf /Users/kkoehntopp/homebrew/etc/my.cnf ~/.my.cnf As can be seen, my version of the MySQL client checks in this order
 /etc/my.cnf /etc/mysql/my.cnf /Users/kkoehntopp/homebrew/etc/my/cnf ~/.my.cnf  The cnf file is a file in dot-ini syntax, so you have [groups] and each group contains lines with key = value pairs.</description>
    </item>
    
    <item>
      <title>MySQL: ALTER TABLE for UUID</title>
      <link>https://blog.koehntopp.info/2020/09/22/alter-table-for-uuid.html</link>
      <pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/09/22/alter-table-for-uuid.html</guid>
      <description>A question to the internal #DBA channel at work: »Is it possible to change a column type from BIGINT to VARCHAR ? Will the numbers be converted into a string version of the number or will be it a byte-wise transition that will screw the values?«
Further asking yielded more information: »The use-case is to have strings, to have UUIDs.«
So we have two questions to answer:
 Is ALTER TABLE t CHANGE COLUMN c lossy?</description>
    </item>
    
    <item>
      <title>MySQL: Encoding fields for great profit.</title>
      <link>https://blog.koehntopp.info/2020/09/18/mysql-encoding-fields-for-great-profit.html</link>
      <pubDate>Fri, 18 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/09/18/mysql-encoding-fields-for-great-profit.html</guid>
      <description>Iterating schemas over time is not an uncommon thing. Often requirements emerge only after you have data, and then directed action is possible. Consequently, working on existing data, and structuring and cleaning it up is a common task.
In todays example we work with a log table that logged state transitions of things in freeform VARCHAR fields. After some time the log table grew quite sizeable, and the log strings are repeated rather often, contributing to the overall size of the table considerably.</description>
    </item>
    
    <item>
      <title>MySQL from a Developers Perspective</title>
      <link>https://blog.koehntopp.info/2020/09/07/mysql-from-a-developers-perspective.html</link>
      <pubDate>Mon, 07 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/09/07/mysql-from-a-developers-perspective.html</guid>
      <description>So this has turned into a small series, explaining how to work with MYSQL from a developers perspective. This post is intended as a directory for the individual articles. It will be amended and re-dated as necessary.
The code for the series is also available in isotopp/mysql-dev-examples on GitHub.
The Tag #mysqldev will reference all articles from this series.
  MySQL Transactions - the physical side . Looking at how MySQL InnoDB handles transactions on the physical media, enabling rollback and commit.</description>
    </item>
    
    <item>
      <title>MySQL: Generated Columns and virtual indexes</title>
      <link>https://blog.koehntopp.info/2020/09/07/mysql-generated-columns-and-virtual-indexes.html</link>
      <pubDate>Mon, 07 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/09/07/mysql-generated-columns-and-virtual-indexes.html</guid>
      <description>We have had a look at how MySQL 8 handles JSON recently, but with all those JSON functions and expressions it is clear that many JSON accesses cannot be fast. To grab data from a JSON column, you will use a lot of $-&amp;gt;&amp;gt;field expressions and similar, and without indexes nothing of this will be fast.
JSON cannot be indexed.
But MySQL 8 offers another feature that comes in handy: Generated columns and indexes on those.</description>
    </item>
    
    <item>
      <title>MySQL: Basic usage of the JSON data type</title>
      <link>https://blog.koehntopp.info/2020/09/04/mysql-json-data-type.html</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/09/04/mysql-json-data-type.html</guid>
      <description>MySQL 8 provides solid support for the JSON data type. The manual has an overview of the data type , a JSON function reference , an an overview on generated column indexes , and explains multi-values indexes .
Creating JSON columns   Creating JSON columns is easy: Make the column of the JSON data type, fill in valid JSON data.
mysql&amp;gt;createtablet(idintegernotnullprimarykeyauto_increment,jjson);QueryOK,0rowsaffected(0.11sec)mysql&amp;gt;insertintot(j)values-&amp;gt;(&amp;#39;null&amp;#39;),-&amp;gt;(&amp;#39;true&amp;#39;),-&amp;gt;(&amp;#39;false&amp;#39;),-&amp;gt;(&amp;#39;1&amp;#39;),-&amp;gt;(&amp;#39;&amp;#34;keks&amp;#34;&amp;#39;),-&amp;gt;(&amp;#39;[&amp;#34;eins&amp;#34;, &amp;#34;zwei&amp;#34;]&amp;#39;),-&amp;gt;(&amp;#39;{&amp;#34;eins&amp;#34;: &amp;#34;one&amp;#34;, &amp;#34;zwei&amp;#34;: &amp;#34;two&amp;#34;}&amp;#39;);QueryOK,5rowsaffected(0.02sec)mysql&amp;gt;selectjson_type(j)astype,json_valid(j)asvalid,isnull(j)assqlnull,j,idfromt;+---------+-------+---------+--------------------------------+----+ |type|valid|sqlnull|j|id|+---------+-------+---------+--------------------------------+----+ |NULL|NULL|1|NULL|1||NULL|1|0|null|2||BOOLEAN|1|0|true|3||BOOLEAN|1|0|false|4||INTEGER|1|0|1|5||STRING|1|0|&amp;#34;keks&amp;#34;|6||ARRAY|1|0|[&amp;#34;eins&amp;#34;,&amp;#34;zwei&amp;#34;]|7||OBJECT|1|0|{&amp;#34;eins&amp;#34;:&amp;#34;one&amp;#34;,&amp;#34;zwei&amp;#34;:&amp;#34;two&amp;#34;}|8|+---------+-------+---------+--------------------------------+----+ 8rowsinset(0.00sec)mysql&amp;gt;insertintot(j)values(&amp;#39;[&amp;#34;incomplete&amp;#34;, &amp;#34;array&amp;#34;, &amp;#34;closing bracket&amp;#34;&amp;#39;);ERROR3140(22032):InvalidJSONtext:&amp;#34;Missing a comma or &amp;#39;]&amp;#39; after an array element.</description>
    </item>
    
    <item>
      <title>MySQL: NULL is NULL</title>
      <link>https://blog.koehntopp.info/2020/08/25/null-is-null.html</link>
      <pubDate>Tue, 25 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/08/25/null-is-null.html</guid>
      <description>Question: Hey, I got a UNIQUE INDEX, but I can store multiple rows with the same value, NULL. That is surprising. Is that a bug?
 This is a rewrite of the same in German from 9 years ago .
 root@localhost[kris]&amp;gt;createtablet(ainteger,binteger,unique(a,b));QueryOK,0rowsaffected(0.09sec)root@localhost[kris]&amp;gt;insertintotvalues(1,2);QueryOK,1rowaffected(0.01sec)root@localhost[kris]&amp;gt;insertintotvalues(1,2);ERROR1062(23000):Duplicateentry&amp;#39;1-2&amp;#39;forkey&amp;#39;t.a&amp;#39;This does not work, as expected. But this does:
root@localhost[kris]&amp;gt;truncatetablet;QueryOK,0rowsaffected(0.16sec)root@localhost[kris]&amp;gt;insertintotvalues(1,NULL);QueryOK,1rowaffected(0.02sec)root@localhost[kris]&amp;gt;insertintotvalues(1,NULL);QueryOK,1rowaffected(0.03sec)root@localhost[kris]&amp;gt;select*fromt;+------+------+ |a|b|+------+------+ |1|NULL||1|NULL|+------+------+ 2rowsinset(0.00sec)Why is that?
This is usually where I point people at SQL for Smarties: Advanced SQL Programming .</description>
    </item>
    
    <item>
      <title>MySQL: Some Character Set Basics</title>
      <link>https://blog.koehntopp.info/2020/08/18/mysql-character-sets.html</link>
      <pubDate>Tue, 18 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/08/18/mysql-character-sets.html</guid>
      <description>This is the updated and english version of some older posts of mine in German. It is likely still incomplete, and will need information added to match current MySQL, but hopefully it is already useful.
Old source articles in German: 1 , 2 and 3 .
Some vocabulary   Symbol, Font, Encoding and Collation - what do they even mean?
A character set is a collection of symbols that belong together.</description>
    </item>
    
    <item>
      <title>MySQL Foreign Key Constraints and Locking</title>
      <link>https://blog.koehntopp.info/2020/08/04/mysql-foreign-key-constraints-and-locking.html</link>
      <pubDate>Tue, 04 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/08/04/mysql-foreign-key-constraints-and-locking.html</guid>
      <description>Since we now know how to look at the state of locking in a live database, let&amp;rsquo;s look at what happens when we run a normal insert or update and an insert or update with foreign key relationships defined, and compare.
We will be using the tables and structures from our previous examples, a simple 1:n relationship between a and b:
CREATETABLEa(a_idintNOTNULLAUTO_INCREMENT,PRIMARYKEY(a_id));INSERTINTOaVALUES(10),(20),(30),(40);CREATETABLEb(b_idintNOTNULLAUTO_INCREMENT,a_idintNOTNULL,PRIMARYKEY(b_id),KEY`a_id`(a_id),CONSTRAINTa_id_existsFOREIGNKEY(a_id)REFERENCESa(a_id)ONDELETERESTRICTONUPDATERESTRICT);INSERTINTObVALUES(10,10),(40,40);or the same definition for b without the constraint.</description>
    </item>
    
    <item>
      <title>MySQL Foreign Keys and Foreign Key Constraints</title>
      <link>https://blog.koehntopp.info/2020/08/03/mysql-foreign-keys-and-foreign-key-constraints.html</link>
      <pubDate>Mon, 03 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/08/03/mysql-foreign-keys-and-foreign-key-constraints.html</guid>
      <description>Foreign Keys are what links tables together and turns a set of tables into a model. Foreign Key Constraints are conditions that must be true for the content of the tables to be an internally consistent model. Foreign Key Constraints can be defined and enforced in InnoDB, but this comes at a considerable price, and for some it may hurt more than it is worth.
A very simple shop as a ER-model.</description>
    </item>
    
    <item>
      <title>MySQL Deadlocks with INSERT</title>
      <link>https://blog.koehntopp.info/2020/08/02/mysql-deadlocks-with-insert.html</link>
      <pubDate>Sun, 02 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/08/02/mysql-deadlocks-with-insert.html</guid>
      <description>Support Channel. &amp;ldquo;Hi, I am getting deadlocks in the database and they occur when I have to rollback the transactions but if we don&amp;rsquo;t have to roll back all transactions get executed.&amp;rdquo; Wait, what? After some back and forth it becomes clear that the Dev experiences deadlocks and has data:
mysql&amp;gt;pagerlessmysql&amp;gt;showengineinnodbstatus\G...MySQLthreadid142531,OSthreadhandle139990258222848,queryid4799571somehost.somedomainsomeuserupdateINSERTintosometable(identifier_id,currency,balance)VALUES(&amp;#39;d4e84cb1-4d56-4d67-9d16-1d548fd26b55&amp;#39;,&amp;#39;EUR&amp;#39;,&amp;#39;0&amp;#39;)***(2)HOLDSTHELOCK(S):RECORDLOCKSspaceid3523pageno1106463nbits224indexPRIMARYoftable`somedb`.`sometable`trxid9843342279lockmodeSlocksgapbeforerecand that is weird because of the lock mode S locks gap in the last line. We get the exact same statement with the exact same value on the second thread, but with lock mode X locks gap.</description>
    </item>
    
    <item>
      <title>MySQL: Locks and Deadlocks</title>
      <link>https://blog.koehntopp.info/2020/08/01/mysql-locks-and-deadlocks.html</link>
      <pubDate>Sat, 01 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/08/01/mysql-locks-and-deadlocks.html</guid>
      <description>In a previous article we wrote data to the database using atomic update statements, and then using transactions with SELECT ... FOR UPDATE. In this article we will look at what happens when we continue doing this, in a more complicated way. Source code for this article is also available on github.com .
A simple row lock   But first let&amp;rsquo;s do things manually: We create a table kris with an integer primary key column and a secondary unindexed data column.</description>
    </item>
    
    <item>
      <title>MySQL Transactions - writing data</title>
      <link>https://blog.koehntopp.info/2020/07/30/mysql-transactions-writing-data.html</link>
      <pubDate>Thu, 30 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/07/30/mysql-transactions-writing-data.html</guid>
      <description>Using the framework for testing we created in earlier articles, let&amp;rsquo;s try to modify some data. We are writing a small program that increments a counter. Our table looks like this, and contains 10 counters:
CREATETABLE`demo`(`id`bigintunsignedNOTNULLAUTO_INCREMENT,`counter`intNOTNULLDEFAULT&amp;#39;0&amp;#39;,UNIQUEKEY`id`(`id`))INSERTINTO`demo`VALUES(1,0);INSERTINTO`demo`VALUES(2,0);...INSERTINTO`demo`VALUES(10,0);We are using some very simple programming to increment a counter:
@sql.command() @click.option(&amp;#34;--name&amp;#34;, default=&amp;#34;demo&amp;#34;, help=&amp;#34;Table name to count in&amp;#34;) @click.option(&amp;#34;--id&amp;#34;, default=0, help=&amp;#34;Counter to use&amp;#34;) @click.option(&amp;#34;--count&amp;#34;, default=1000, help=&amp;#34;Number of increments&amp;#34;) def count(name, id, count): &amp;#34;&amp;#34;&amp;#34; Increment counter --id by --count many steps in table --name &amp;#34;&amp;#34;&amp;#34; for i in range(0, count): cmd = f&amp;#34;update {name}set counter=counter+1 where id = {id}&amp;#34; c = db.</description>
    </item>
    
    <item>
      <title>MySQL Transactions - the logical side</title>
      <link>https://blog.koehntopp.info/2020/07/29/mysql-transactions-the-logical-view.html</link>
      <pubDate>Wed, 29 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/07/29/mysql-transactions-the-logical-view.html</guid>
      <description>After having a look how MySQL handles transactions physically , let&amp;rsquo;s have a look at what is going on from a logical point of view.
We are using a test table called demo with an id and a counter field, both integer. In it we have 10 counters, all set to 0.
CREATETABLE`demo`(`id`bigintunsignedNOTNULLAUTO_INCREMENT,`counter`intNOTNULLDEFAULT&amp;#39;0&amp;#39;,UNIQUEKEY`id`(`id`))INSERTINTO`demo`VALUES(1,0);INSERTINTO`demo`VALUES(2,0);...INSERTINTO`demo`VALUES(10,0);In one session, we start a transaction and modify a counter value. We do not commit anything.
Session1&amp;gt;starttransactionreadwrite;Session1&amp;gt;updatedemosetcounter=10whereid=3;Isolation   In a second session, we check the data and notice a few things:</description>
    </item>
    
    <item>
      <title>MySQL Connection Scoped State</title>
      <link>https://blog.koehntopp.info/2020/07/28/mysql-connection-scoped-state.html</link>
      <pubDate>Tue, 28 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/07/28/mysql-connection-scoped-state.html</guid>
      <description>MySQL speaks its own proprietary protocol. It cannot be routed by a HTTP proxy, and a MySQL connection is entire unlike a HTTP connection. Specifically, a lot of state and configuration is tied to a MySQL connection, and it cannot be recovered on disconnect.
What state is tied to a connection?   Transactions   A disconnect implies a ROLLBACK. So if you are in a transaction, all changes to the database that you attempted are lost, rolled back, as if they never happened.</description>
    </item>
    
    <item>
      <title>MySQL Commit Size and Speed</title>
      <link>https://blog.koehntopp.info/2020/07/27/mysql-commit-size-and-speed.html</link>
      <pubDate>Mon, 27 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/07/27/mysql-commit-size-and-speed.html</guid>
      <description>When writing data to disk, for small transactions the cost of writing the commit out do disk dominates the execution time of the script. In order to show that, I wrote a little bit of Python.
The script creates a test table in a database and writes 10.000 rows of test data into it, in commit sizes of 1, 2, 4, &amp;hellip;, 1024 rows.
$ ./mysql.py --help Usage: mysql.py [OPTIONS] COMMAND [ARGS].</description>
    </item>
    
    <item>
      <title>MySQL Transactions - the physical side</title>
      <link>https://blog.koehntopp.info/2020/07/27/mysql-transactions.html</link>
      <pubDate>Mon, 27 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/07/27/mysql-transactions.html</guid>
      <description>So you talk to a database, doing transactions. What happens actually, behind the scenes? Let’s have a look.
There is a test table and we write data into it inside a transaction:
CREATETABLEt(idserial,datavarbinary(255))STARTTRANSACTIONREADWRITEINSERTINTOt(id,data)VALUES(NULL,RANDOM_BYTES(255))COMMITThe MySQL test instance we are talking to is running on a Linux machine, and otherwise idle to make observation easier. Also, we configured it with innodb_use_native_aio = false because observing actual physical asynchronous I/O and attributing it to the statement that caused it is really hard.</description>
    </item>
    
    <item>
      <title>Where do the JOINs go?</title>
      <link>https://blog.koehntopp.info/2020/06/10/where-do-the-joins-go.html</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/06/10/where-do-the-joins-go.html</guid>
      <description>I was asking on Twitter:
 Are you a Developer and understand (Micro-) Services? I am a database person and a bit simple, and I have a genuine Question:
When moving to a services architecture, where do the JOINs go?
I gave the following context:
 A simple shop
So you sell stuff, that is, you have an orders table o with an oid, which stores a customer id cid from a customers c table, and an article id aid, from an articles table a and a count cnt.</description>
    </item>
    
    <item>
      <title>Deleting data from MySQL</title>
      <link>https://blog.koehntopp.info/2020/05/13/deleting-data-from-mysql.html</link>
      <pubDate>Wed, 13 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/05/13/deleting-data-from-mysql.html</guid>
      <description>I have been pointed at the following question: »Has anyone ever used mySQL events to auto-delete rows from a table after set period? Wondering your experience of doing this.«
 There are two ends to this question:
 expiring data from a MySQL table doing this with the event scheduler  Mass-deleting data from InnoDB   You can of course delete data from a table using the SQL DELETE statement with an arbitrary WHERE-clause at any time:</description>
    </item>
    
    <item>
      <title>Data Access Programs and Pre-SQL systems</title>
      <link>https://blog.koehntopp.info/2020/05/01/data-access-programs.html</link>
      <pubDate>Fri, 01 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/05/01/data-access-programs.html</guid>
      <description>Let&amp;rsquo;s have a look at very old database systems. Things like dBase or compatible systems (&amp;ldquo;xBases&amp;rdquo;) allowed to manipulate record based files (with indexes) in a procedural way. What does that mean?
xBase   The system allows developers to create files that contain a well defined (fixed size) record structure, basically an array of struct on disk, often together with the definition of on-screen masks designed to show a single record and a (searchable) list of records.</description>
    </item>
    
    <item>
      <title>Some latency numbers illustrated</title>
      <link>https://blog.koehntopp.info/2020/02/28/some-latency-numbers-illustrated.html</link>
      <pubDate>Fri, 28 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/02/28/some-latency-numbers-illustrated.html</guid>
      <description>These images are older than time itself. I picked them up while working as a consultant for MySQL AB, but I do not know the source.
Here are some important latency numbers. A pixel is a nanosecond (nano = 10^-9, a billionth of a second, 1 billion events/s = 1 GHz):
And below is the HDD disk seek latency in full at the same scale. An uncached index access can result in up to 5 disk seeks, worst case.</description>
    </item>
    
    <item>
      <title>Some rules for primary keys</title>
      <link>https://blog.koehntopp.info/2020/01/28/some-rules-for-primary-keys.html</link>
      <pubDate>Tue, 28 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/01/28/some-rules-for-primary-keys.html</guid>
      <description>On Twitter, @CaptainEyesight asked a question:
 »Database architecture question: For deleting records, instead of a DELETE, UPDATE the id to the negative (i.e. 1 becomes -1) and then add AND id &amp;gt; 0 to every query. Great idea? or Greatest idea?«
I was honestly a bit confused, because this idea is so weird that I took this question for a joke. But then I decided that this is a case for XKCD 1053 : »You are one of today&amp;rsquo;s lucky 10.</description>
    </item>
    
    <item>
      <title>Filling disk space fast</title>
      <link>https://blog.koehntopp.info/2019/11/11/filling-disk-space-fast.html</link>
      <pubDate>Mon, 11 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2019/11/11/filling-disk-space-fast.html</guid>
      <description>Some of the databases at work are a tad on the large side, in the high 2-digit terabytes of size. Copying these to new machines at the moment takes a rather long time, multiple days, up to a week. Speeding it up pays twice, because with shorter copy times there is also less binlog to catch up.
I have been looking into disk copy speeds in order to better understand the limits.</description>
    </item>
    
    <item>
      <title>MySQL Does Disk I/O</title>
      <link>https://blog.koehntopp.info/2019/09/27/mysql-does-disk-io.html</link>
      <pubDate>Fri, 27 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2019/09/27/mysql-does-disk-io.html</guid>
      <description>We had a discussion at work about MySQL doing Disk I/O to a NVME disk, and if it is valid to turn off the doublewrite buffer when using XFS.
TL;DR: It&amp;rsquo;s not, you can turn off the doublewrite buffer only on filesystems that never do in-place updates (ZFS, btrfs), or that have their own doublewrite buffer (ext4 with journal=data). A flash layer underneath the actual filesystem is likely not going to help you without additional measures.</description>
    </item>
    
    <item>
      <title>On cache problems, and what they mean for the future</title>
      <link>https://blog.koehntopp.info/2017/06/23/on-cache-problems-and-what-they-mean-for-the-future.html</link>
      <pubDate>Fri, 23 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2017/06/23/on-cache-problems-and-what-they-mean-for-the-future.html</guid>
      <description>This is a disk utilization graph on a heavily loaded Graphite box. In this case, a Dell with a MegaRAID, but that actually does not matter too much.
Go-carbon was lagging and buffering on the box, because the SSD was running at its IOPS limit. At 18:10, the write-back cache and the &amp;ldquo;intelligent read-ahead&amp;rdquo; are being disabled, that is, the MegaRAID is being force-dumbed down to a regular non-smart controller. The effect is stunning.</description>
    </item>
    
    <item>
      <title>Load, Load Testing and Benchmarking</title>
      <link>https://blog.koehntopp.info/2017/02/16/load-load-testing-and-benchmarking.html</link>
      <pubDate>Thu, 16 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2017/02/16/load-load-testing-and-benchmarking.html</guid>
      <description>(This article also available in german language .)
So you have a new system and want to know what the load limits are. For that you want to run a benchmark.
Basic Benchmarking   The main plan looks like this:
The basic idea: Find a box, offer load, see what happens, learn.
You grab a box and find a method to generate load. Eventually the box will be fully loaded and you will notice this somehow.</description>
    </item>
    
    <item>
      <title>House und Heisenberg revisited</title>
      <link>https://blog.koehntopp.info/2012/09/25/house-und-heisenberg-revisited.html</link>
      <pubDate>Tue, 25 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2012/09/25/house-und-heisenberg-revisited.html</guid>
      <description>Ich habe heute an dem Problem weiter geforscht und wir haben etabliert, dass die Ursache nicht der Quelltext des betreffenden Diamond-Collectors sein kann.
Auf allen betroffenen Kisten habe ich dann gesehen, daß die entsprechenden Queries gegen Performance-Schema ein
mysql&amp;gt;select\*fromperformance_schema.threads;Emptyset(0.01sec)zurück liefern.
Weitere Untersuchung stellt heraus: P_S ist aber an. Jedoch:
mysql&amp;gt;select\*fromperformance_schema.setup_instruments;Emptyset(0.03sec)mysql&amp;gt;select\*fromperformance_schema.setup_timers;Emptyset(0.01sec)mysql&amp;gt;select\*fromperformance_schema.setup_consumers;Emptyset(0.02sec)und das bleibt auch so, sogar über Server-Restarts hinweg. Warum ist das so?
# cd /mysql/\*/data/performance_schema/ # ls -l total 1840 -rw-rw---- 1 mysql mysql 8624 Oct 6 2011 cond_instances.</description>
    </item>
    
    <item>
      <title>Der Herr House und der Herr Heisenberg haben Replication Delay</title>
      <link>https://blog.koehntopp.info/2012/09/24/der-herr-house-und-der-herr-heisenberg-haben-replication-delay.html</link>
      <pubDate>Mon, 24 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2012/09/24/der-herr-house-und-der-herr-heisenberg-haben-replication-delay.html</guid>
      <description>Heute erreicht mich eine Mail, in der ein DBA sich über steigende Replication Delay in einer bestimmten Replikationshierarchie beschwert.
Das ist schlecht, denn die betreffende Hierarchie ist wichtig. Also die &amp;lsquo;Wenn die nicht geht schlafen Leute unter Brücken&amp;rsquo;-Art von wichtig.
Die Theorie war, daß die Änderungsrate in dieser Hierarchie so hoch ist, daß die Schreiblast von MySQL Replikation, die ja Single Threaded ist, nicht mehr bewältigt werden kann. Für diese Theorie sprach nach dem ersten Augenschein, daß alle betroffenen Kisten keine lokalen Platten hatten, sondern auf einem Filer lagen, und Filer sterben wegen der hohen Kommunikationslatenz im SAN bei uns in der Regel weit vor lokalen Platten, wenn es um Replikation geht: Filer sind mehr so beim parallelen Schreiben mit mehreren Threads gut.</description>
    </item>
    
    <item>
      <title>Zu Besuch bei Redis</title>
      <link>https://blog.koehntopp.info/2012/09/23/zu-besuch-bei-redis.html</link>
      <pubDate>Sun, 23 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2012/09/23/zu-besuch-bei-redis.html</guid>
      <description>&lt;p&gt;Hier ist eine wichtige Zahl: Ein Coredump von einem MySQL auf einer Maschine
mit knapp unter 200G Speicher dauert 15 Minuten.  Auf SSD.  Auf eine
Festplatte dauert der gleiche Coredump dann knapp über 30 Minuten.&lt;/p&gt;
&lt;p&gt;Warum ist das eine wichtige Zahl?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Load, Load Testing und Benchmarks</title>
      <link>https://blog.koehntopp.info/2012/08/28/load-load-testing-und-benchmarks.html</link>
      <pubDate>Tue, 28 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2012/08/28/load-load-testing-und-benchmarks.html</guid>
      <description>(Diesen Artikel gibt es auch in englischer Sprache .)
So. Du willst also wissen, was genau die Leistungsgrenzen Deines Systems sind. Und dazu möchtest Du einen Lasttest fahren, um Ergebnisse zu ermitteln.
Die Grundidee Deines Plans sieht so aus:
Du nimmt Deine Kiste und findest eine Methode, um Last zu generieren. Dann wirst Du schon merken, wie weit das geht und wann die Kiste ausgelastet ist.
Der erste Fehler: Den Lastgenerator auf der zu testenden Kiste laufen lassen.</description>
    </item>
    
    <item>
      <title>Grundsätze verteilter Datenbanken</title>
      <link>https://blog.koehntopp.info/2012/03/15/grunds-tze-verteilter-datenbanken.html</link>
      <pubDate>Thu, 15 Mar 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2012/03/15/grunds-tze-verteilter-datenbanken.html</guid>
      <description>Wonka&amp;gt; Die Toppoint z.B. wird vermutlich nie was haben, was in nennenswerte Last-Regionen kommt, aber ich will - akademisches Interesse und so - schon wissen, wie man das da am besten täte. Was mich auch für die Toppoint interessiert: irgendeine Sorte Redundant Array of Inexpensive Databases :)
Lalufu&amp;gt; MySQL mit Replication? Alternativ mit DRBD?
Isotopp&amp;gt; Mit DRBD. Nicht mit Replikation.
Wonka&amp;gt; Lalufu: Hm, Master-Master-Replication geht ja nur mit Zweien. Wenn man nun mehr als das haben will, kann man zwar Ringe bauen, aber nur einfach verkettete.</description>
    </item>
    
    <item>
      <title>NULL is NULL</title>
      <link>https://blog.koehntopp.info/2011/11/04/null-is-null.html</link>
      <pubDate>Fri, 04 Nov 2011 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2011/11/04/null-is-null.html</guid>
      <description>Q&amp;gt; Sag mal, NULL zählt nicht bei einem UNIQUE INDEX? Zum Beispiel ein UNIQUE INDEX auf (a,b) und dann
ab1212Das geht nicht, da Duplikate Key. Aber
ab1NULL1NULLwird zugelassen.
Kris&amp;gt; Du kaufst bitte mal SQL für Smarties: Advanced SQL Programming und ißt das dann auf.
mysql&amp;gt;select*fromt;+----+------+ |id|d|+----+------+ |1|NULL||2|2||3|3||4|NULL|+----+------+ 4rowsinset(0.00sec)mysql&amp;gt;selectcount(*)asa,count(d)asb,count(coalesce(d,0))ascfromt;+---+---+---+ |a|b|c|+---+---+---+ |4|2|4|+---+---+---+ 1rowinset(0.00sec)mysql&amp;gt;selectd,coalesce(d,0)asdcfromt;+------+------+ |d|dc|+------+------+ |NULL|0||2|2||3|3||NULL|0|+------+------+ 4rowsinset(0.00sec)Kris&amp;gt; Und außerdem
mysql&amp;gt;select0=0,1=1,0=1,NULL=0,NULL=1,NULL=NULL;+-----+-----+-----+--------+--------+-----------+ |0=0|1=1|0=1|NULL=0|NULL=1|NULL=NULL|+-----+-----+-----+--------+--------+-----------+ |1|1|0|NULL|NULL|NULL|+-----+-----+-----+--------+--------+-----------+ 1rowinset(0.00sec)Q&amp;gt; Ah, es liegt also daran, daß NULL kein Wert ist, sondern einfach NICHTS.</description>
    </item>
    
    <item>
      <title>Checkpoint Blues</title>
      <link>https://blog.koehntopp.info/2011/09/19/checkpoint-blues.html</link>
      <pubDate>Mon, 19 Sep 2011 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2011/09/19/checkpoint-blues.html</guid>
      <description>Wer dies und dies gelesen hat, versteht mehr.
InnoDB ist eine Storage Engine, die mit Hilfe von MVCC Transaktionen implementiert. Transaktionen zu implementieren bedeutet, daß man in der Lage ist, mehrere Änderungen zusammenzufassen und als eine Einheit als gültig zu markieren oder zurück zu nehmen. Damit das Ganze trotzdem schnell ist, muß man ein wenig herumtricksen.
Angenommen, wir wollen eine Spalte in einer Zeile in der Tabelle t ändern:
UPDATEtSETx=17WHEREid=3Dann muß InnoDB das zunächst einmal in eine Zeilennummer in einer Speicherseite übersetzen: InnoDB speichert Daten in Seiten von 16 KB (Defaultgröße) ab, und macht allen I/O in Richtung Tablespace immer nur in ganzen Seiten.</description>
    </item>
    
    <item>
      <title>Neue Releases im Datenbankland</title>
      <link>https://blog.koehntopp.info/2011/09/13/neue-releases-im-datenbankland.html</link>
      <pubDate>Tue, 13 Sep 2011 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2011/09/13/neue-releases-im-datenbankland.html</guid>
      <description>MongoDB 2.0 ist draußen, und implementiert eine Reihe interessanter neuer Dinge, die ich anderswo gerne hätte, insbesondere im Bereich Replica Sets .
Postgres hat das Release 9.1 draußen. Die versprochene synchrone Replikation ist jetzt verfügbar, sie ist grob vergleichbar mit der Semisynchronen Replikation in MySQL 5.5. Ein wesentlicher Unterschied ist, daß man bei Postgres einzelne, bestimmte Server als synchrone Slaves benennen kann, während MySQL nur garantiert, daß es mindestens einen (wechselnden) Slave gibt, der synchron repliziert hat.</description>
    </item>
    
    <item>
      <title>NoSQL and No Security </title>
      <link>https://blog.koehntopp.info/2011/08/10/nosql-and-no-security.html</link>
      <pubDate>Wed, 10 Aug 2011 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2011/08/10/nosql-and-no-security.html</guid>
      <description>Drüben bei Securosis arbeitet man die Black Hat 2011 unter dem Titel NoSQL and No Security auf. Es geht um die Beobachtung, daß die meisten NoSQL-Datenbanken nicht nur keinerlei Authentication haben (hat jemand so verstrahltes Zeugs schon mal in einer PCI Zone deployed?), sondern außerdem viele von ihnen auch anfällig für Server-Side JavaScript Injection (SSJI) sind.
Das soll heißen, daß die Abfragesprache der Wahl bei vielen dieser Dinge Javascript ist, daß im Datenbankserver interpretiert wird.</description>
    </item>
    
    <item>
      <title>MySQL Undo Log</title>
      <link>https://blog.koehntopp.info/2011/04/28/mysql-undo-log.html</link>
      <pubDate>Thu, 28 Apr 2011 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2011/04/28/mysql-undo-log.html</guid>
      <description>&amp;ldquo;Kris, kannst Du bitte mal gucken?&amp;rdquo;
Seit heute morgen, 10:00 Uhr, wächst das Undo Log immer weiter an.
Immer wenn InnoDB Daten schreibt wird die alte Version einer Zeile aus der Tabelle in das Undo-Log verschoben, also physikalisch von der ibd-Datei der Tabelle in die ibdata1 im Datadir von MySQL. In der Tabelle wird in der veränderten Zeile ein Zeiger von der neuen Version auf die alte Version der Zeile im Undo-Log installiert, der Roll(back)-Pointer.</description>
    </item>
    
    <item>
      <title>Zusammenfassung &#39;Schemaless&#39;</title>
      <link>https://blog.koehntopp.info/2011/04/20/zusammenfassung-schemaless.html</link>
      <pubDate>Wed, 20 Apr 2011 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2011/04/20/zusammenfassung-schemaless.html</guid>
      <description>Die Antwort: ALTER TABLE vs. Schemaless   ALTER TABLE in MySQL nervt. Das tut es in erster Linie, weil es die Tabellen, die es verändert, mit einem exklusiven Lock (Write Lock) belegt, während es die Änderung durchführt, und weil es die Änderung durch Umkopieren der Daten und Indices durchführt, was bei einer großen bestehenden Datenmenge doch recht lange dauern kann.
Es gibt inzwischen eine Reihe von Verbesserungen in MySQL 5.</description>
    </item>
    
    <item>
      <title>Schemaless?</title>
      <link>https://blog.koehntopp.info/2011/04/19/schemaless.html</link>
      <pubDate>Tue, 19 Apr 2011 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2011/04/19/schemaless.html</guid>
      <description>Die Frage:   Ich brauche einmal Hilfe. Von Euch. Ich verstehe nämlich ein Konzept nicht. Es geht um den Begriff &amp;ldquo;Schemaless&amp;rdquo;, der im Zusammenhang mit einigen NoSQL-Datenbanken verwendet wird.
Ich kann verstehen, daß für einige Leute ein ALTER TABLE wie in MySQL ein Problem ist, weil es Tabellen während der Schemaänderung lockt. Da ALTER TABLE in vielen Fällen die Daten zur Durchführung der Änderung umkopieren muß, kann dieses Lock entsprechend lange bestehen bleiben, wenn die Daten nur hinreichend groß sind.</description>
    </item>
    
    <item>
      <title>Ein paar Gedanken zum Thema NoSQL</title>
      <link>https://blog.koehntopp.info/2010/11/05/ein-paar-gedanken-zum-thema-nosql.html</link>
      <pubDate>Fri, 05 Nov 2010 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2010/11/05/ein-paar-gedanken-zum-thema-nosql.html</guid>
      <description>Beim Durchstöbern der verschiedenen NoSQL-Datenspeicher stellt sich mir die Frage, wieso man das alles überhaupt will. Genauer: Was genau ist das Problem, das man mit NoSQL lösen möchte?
Diejenigen Leute, die NoSQL-Lösungen einsetzen, haben in der Regel die Schwierigkeit, daß ihre Datenmenge größer wird, als man auf einer einzelnen Maschine mit der geforderten Servicequalität handhaben kann.
Im Webbereich sind die Anforderungen für interaktives Browsen oft so, daß man die gewünschten Antwortzeiten nur dann erreichen kann, wenn die dabei verwendeten Datenbanken ihre Daten und Indices zum allergrößten Teil im RAM halten können.</description>
    </item>
    
    <item>
      <title>Red vs Blue at Oracle, und ein paar Gedanken zu Postgres</title>
      <link>https://blog.koehntopp.info/2010/11/04/red-vs-blue-at-oracle-und-ein-paar-gedanken-zu-postgres.html</link>
      <pubDate>Thu, 04 Nov 2010 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2010/11/04/red-vs-blue-at-oracle-und-ein-paar-gedanken-zu-postgres.html</guid>
      <description>Ich schrieb :
 heretic666 schrieb am 4. November 2010 12:11
&amp;hellip;das man nicht auch wahlweise mit PostgreSQL oder MS SQL erschlagen kann?
Mir fällt da im Moment kein Punkt ein&amp;hellip;
 Postgres ist ein Repräsentant der klassischen Datenbanken und fällt in dieselbe Kategorie wie Oracle, MS SQL oder DB/2. MySQL ist eine Datenbank, die sich in vielen Punkten an den Erfordernissen des Webs orientiert und ganz andere Schwerpunkte als Postgres oder Oracle setzt.</description>
    </item>
    
    <item>
      <title>Verteilte Datenbanken: Der Sonderfall Filialsysteme</title>
      <link>https://blog.koehntopp.info/2010/08/18/verteilte-datenbanken-der-sonderfall-filialsysteme.html</link>
      <pubDate>Wed, 18 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2010/08/18/verteilte-datenbanken-der-sonderfall-filialsysteme.html</guid>
      <description>In einem Kommentar zu Master-Master schrieb ich:
 Für den von Dir genannten Sonderfall der Filialsysteme habe ich noch einen deutschen Artikel in der Warteschlange, ich muß nur Zeit finden ihn zu schreiben.
 Normalerweise sieht MySQL Replikation so aus:
MySQL Replikation - Architekturübersicht
Master Binlog   Auf dem Master ist mit der Konfigurationsanweisung log_bin das Binlog aktiviert.
Das Binlog loggt bei Statement Based Replication (SBR) alle Anweisungen, die Daten verändern (also quasi alles außer SELECT).</description>
    </item>
    
    <item>
      <title>Die relationale Datenbank wird 40.</title>
      <link>https://blog.koehntopp.info/2010/06/08/die-relationale-datenbank-wird-40.html</link>
      <pubDate>Tue, 08 Jun 2010 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2010/06/08/die-relationale-datenbank-wird-40.html</guid>
      <description>Nicht nur wird PHP im Juni 15 Jahre alt, sondern ein anderer, älterer Begleiter von PHP feiert ebenfalls ein Jubiläum:
Im Juni 1970 erschien in den Communications of the ACM der Artikel &amp;ldquo;A Relational Model of Data for Large Shared Data Banks &amp;rdquo; von E.F.Codd. Dieser Artikel ist die theoretische Grundlage für das, was später SQL und relationale Datenbanken werden sollte.
Seitdem MySQL und PHP vor 15 Jahren ausgezogen sind, das Web zu revolutionieren, ist SQL eine Haushaltssprache geworden - es ist inzwischen echt schwierig, Webspace zu kaufen, bei dem man nicht auch Zugriff auf eine MySQL-Datenbank hat, und entsprechend gehen HTML-, PHP- und SQL-Kenntnisse inzwischen einher.</description>
    </item>
    
    <item>
      <title>Ein paar Gedanken zu Zeitreihendaten</title>
      <link>https://blog.koehntopp.info/2009/10/28/ein-paar-gedanken-zu-zeitreihendaten.html</link>
      <pubDate>Wed, 28 Oct 2009 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2009/10/28/ein-paar-gedanken-zu-zeitreihendaten.html</guid>
      <description>Ich sitze hier auf der Open Source Monitoring Conference und unterhalte mich mit ein paar Nagios bzw. Icinga Entwicklern. Dabei hörte ich einen Haufen Flüche über NDO - Nagios Data Out. Ich schaue mir gerade die Dokumentation zum NDO Schema an und stelle fest, daß die Ideen hier auf eine Weise viele Fehler teilen, die auch dem MySQL Enterprise Manager Schema zugrunde liegen (Noch, das MEM-Team bastelt das grad um).</description>
    </item>
    
    <item>
      <title>Ein paar Gedanken zu Foreign Key Constraints</title>
      <link>https://blog.koehntopp.info/2009/10/20/ein-paar-gedanken-zu-foreign-key-constraints.html</link>
      <pubDate>Tue, 20 Oct 2009 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2009/10/20/ein-paar-gedanken-zu-foreign-key-constraints.html</guid>
      <description>Ich lese gerade SQLite Foreign Key Support und ich muß sagen, ich kann mir ein leichtes Grinsen nicht verkneifen.
Also, ich finds ja gut, daß SQLite die Option für Foreign Key Constraints implementiert und ich finds sogar noch besser, daß mit DEFERRABLE INITIALLY DEFERRED sogar die einzig sinnvolle Weise das zu tun bereitgestellt wird, aber ich frag mich schon, wozu das gut sein soll.
Foreign Keys   Aber von vorne.</description>
    </item>
    
    <item>
      <title>Zehn Zentimeter</title>
      <link>https://blog.koehntopp.info/2007/08/11/zehn-zentimeter.html</link>
      <pubDate>Sat, 11 Aug 2007 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2007/08/11/zehn-zentimeter.html</guid>
      <description>Kristian, wenn Du über Performance redest, dann redest Du immer von verteilten, asynchronen Systemen . Verteilte, asynchrone Systeme sind doof, schwer zu programmieren und laufen der Theorie zuwider, die ich an der Uni gelernt habe. Ich warte glaube ich lieber auf schnellere Prozessoren.
 Viel Spaß beim Warten. Godot wird Dir Deine neue CPU bestimmt bald bringen.
Ein Gigahertz ist ein Takt pro Nanosekunde. Bei Lichtgeschwindigkeit kommt das Signal in einer Nanosekunde in etwa 30cm weit.</description>
    </item>
    
    <item>
      <title>Kris vs. 2xMSA 30</title>
      <link>https://blog.koehntopp.info/2006/10/04/kris-vs-2xmsa-30.html</link>
      <pubDate>Wed, 04 Oct 2006 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2006/10/04/kris-vs-2xmsa-30.html</guid>
      <description>&amp;lt;Ein MSA-30 Array mit 14 Platten.
Liebes Tagebuch!
Heute bin ich gegen eine HP 585 und zwei MSA 30 angetreten und ich bin mir nicht ganz sicher, wer gewonnen hat. Aber laß mich von vorne erzählen.
Wie Du weißt, liebes Tagebuch, berechnet sich die Anzahl der Zugriffe, die man von einer einzelnen Platte pro Sekunde erwarten kann, wie folgt: 1000 ms/(Average Seek Time in ms + Rotational Delay in ms + Transfer Time in ms).</description>
    </item>
    
    <item>
      <title>Dateisysteme und Datenbanken</title>
      <link>https://blog.koehntopp.info/2004/06/06/dateisysteme-und-datenbanken.html</link>
      <pubDate>Sun, 06 Jun 2004 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2004/06/06/dateisysteme-und-datenbanken.html</guid>
      <description>Der Artikel Filesysteme sind Datenbanken von Matthias Leisi regt mich an, hier mal ein paar Sachen aufzuschreiben, die ich schon länger vor mir her kullere.
Die meisten Unix-Dateisysteme trennen eine &amp;ldquo;Gruppiere Blocks in Dateien&amp;rdquo;-Ebene (Blockverwaltung) und die &amp;ldquo;Gruppiere Dateien in Hierarchien&amp;rdquo;-Ebene (Namensraumverwaltung) voneinander. Die Blockverwaltung ist relativ gut verstanden und der I/O-Layer von Datenbanken überlegen. Die durch WinFS ausgelöste Diskussion findet stattdessen im Bereich Namensraumverwaltung statt.
Blockverwaltung und die Überlegenheit der Filesystem API   Die Ebene der Blockverwaltung bei Dateisystemen ist sehr hoch optimiert und muß akzeptable Performance unter extrem variablen Benutzungspatterns abliefern können.</description>
    </item>
    
  </channel>
</rss>
