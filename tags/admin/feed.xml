<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>admin on Die wunderbare Welt von Isotopp</title>
    <link>https://blog.koehntopp.info/tags/admin.html</link>
    <description>Recent content in admin on Die wunderbare Welt von Isotopp</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 08 Nov 2021 16:46:21 +0000</lastBuildDate><atom:link href="https://blog.koehntopp.info/tags/admin/feed.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Der Managementansatz zum Thema Sicherheit...</title>
      <link>https://blog.koehntopp.info/2011/01/04/der-managementansatz-zum-thema-sicherheit.html</link>
      <pubDate>Tue, 04 Jan 2011 14:58:51 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2011/01/04/der-managementansatz-zum-thema-sicherheit.html</guid>
      <description>&lt;p&gt;In der aktuellen KES findet sich der Artikel &lt;em&gt;Epische Macht&lt;/em&gt; (
&lt;a href=&#34;http://www.kes.info/aktuell/akheft/artikel1.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keine stabile URL&lt;/a&gt;

, da der
Archivzugang mit den stabilen URLs paßwortgeschützt und nur für Abonnenten
ist).&lt;/p&gt;
&lt;p&gt;Der Artikel konzentriert sich auf die Machtfülle von Systemadministratoren,
und prägt das Wort &amp;ldquo;Machtumsetzungsgeschwindigkeit&amp;rdquo; in Bezug auf
Systemadministratoren. Damit will der Autor (Stephen Feldke) darauf abheben,
daß Root-Arbeiter besonders schnell besonders viel Schaden gemessen in Mio
Euro/Minute anrichten können. Der Autor zieht Parallelen zu Prokura- und
Budget-Regelungen, bei denen man bei bestimmten Transaktionen absichtlich
mehr als eine Unterschrift für eine Entscheidung fordert, um Prozesse
künstlich zu verlangsamen und Mehr-Augen-Prinzipien zu erzwingen.&lt;/p&gt;
&lt;p&gt;Der Autor schlägt eine EPIS-Zertifizierung (&amp;ldquo;Extrem Privilegierte
IT-Spezialisten&amp;rdquo;) für Sysadmins vor, die in kritischen Infrastrukturen nach
BSI-Definition arbeiten (&amp;ldquo;volkswirtschaftlich oder gesellschaftlich
besonders wichtige Institutionen, die für die Sicherheit und Stabilität
eines Landes essenziell sind (u. a. Großbanken und Energieunternehmen sowie
deren Dienstleister)&amp;quot;) . Für EPIS soll nach den Vorstellungen des Artikels
eine &amp;ldquo;Zuverlässigkeits- beziehungsweise Sicherheitsüberprüfung als
Pflichtmaßnahme der Risikovorsorge (möglicherweise sogar per Gesetz)
vorgesehen&amp;rdquo; werden. &amp;ldquo;Die hierfür notwendige Validierung bezieht sich dabei
weniger auf die fachliche Kompetenz als vielmehr auf die persönliche
Zuverlässigkeit und Integrität.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Der Artikel hat mir beim Lesen die ganze Zeit ein Lächeln auf das Gesicht
gezaubert.&lt;/p&gt;
&lt;p&gt;IT im allgemeinen und insbesondere der Markt für fähige Sysadmins ist ja
sowieso schon in vielerlei Hinsicht ein Arbeitnehmermarkt. Verknappt man
diesen Bestand durch EPIS-Requirements noch weiter, ist das für die
Arbeitnehmer ein wichtiger Punkt, durch den sie ihren Wert noch weiter
steigern können.&lt;/p&gt;
&lt;p&gt;Andererseits ist die Maßnahme offensichtlich witzlos, oder der Autor lebt in
einem komplett anderen Universum als ich.&lt;/p&gt;
&lt;p&gt;In meiner Welt kenne ich Unternehmen, die gar keine Rechenzentren und
Rechner mehr haben, sondern komplett aus der Cloud laufen. In meiner Welt
versuchen Unternehmen ihre Agilität zu erhöhen und mehrere Rollouts von Code
pro Tag zu realisieren. In meiner Welt haben Unternehmen hunderte offener
Stellen im Bereich IT. In meiner Welt versuchen Unternehmen ihren
Systembetrieb zu automatisieren und hunderte oder tausende von Rechnern
automatisch zu administrieren.&lt;/p&gt;
&lt;p&gt;In dieser Welt ist eine EPIS-Zertifizierung Augenwischerei.&lt;/p&gt;
&lt;p&gt;Sie erhöht den Organisationswiderstand gegen Prozeßveränderungen und
schwächt damit die Anpassungsfähigkeit des Unternehmens an Veränderungen des
Umfeldes. Sie bringt keine meßbare Verbesserung der Sicherheit, solange man
nicht auch im Bereich der Feature-Entwickler und im Bereich der
Infrastrukturentwickler die Prozesse mächtig aufbläst - E4 bis E6 lassen
grüßen und damit geht jedwede mühsam erarbeitete Agilität verloren.&lt;/p&gt;
&lt;p&gt;Irgendwie kommt mir da der Wind der 90er Jahre aus dem Heft entgegen. Kann
das sein?&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Wieso zehn Prozent?</title>
      <link>https://blog.koehntopp.info/2010/05/16/wieso-zehn-prozent.html</link>
      <pubDate>Sun, 16 May 2010 08:11:32 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2010/05/16/wieso-zehn-prozent.html</guid>
      <description>&lt;p&gt;In &lt;a href=&#34;http://erichsieht.wordpress.com/2010/05/15/sicherheitsmetrik/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sicherheitsmetrik&lt;/a&gt;


heißt es als Antwort auf meinen Artikel
&lt;a href=&#34;https://blog.koehntopp.info/2010/05/14/denic-erkl-rt-sich.html&#34;&gt;DENIC erklärt sich&lt;/a&gt;

:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Wir IT-Akademiker forschen gerne an Fragen herum, die einen vagen
Relitätsbezug haben, die man aber in der Praxis pragmatisch handhabt. Nach
ein paar Jahren haben wir die Lösungen der Pragmatiker formal dokumentiert
und wissenschaftlich nachgewiesen, was die Kollegen immer schon wussten,
nämlich dass das so tatsächlich funktioniert…. Die zehn Prozent sind
formal betrachtet völlig willkürlich gewählt, tatsächlich aber wohl ein
Erfahrungswert, der sich aus informellen Beobachtungen typischer Vorgänge
ergibt. So etwas würde ein Wissenschaftler nie zulassen.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Die zehn Prozent sind natürlich nicht willkürlich gewählt, sondern
sorgfältig ermessen.&lt;/p&gt;
&lt;p&gt;Dem Ganzen liegt eine andere Anekdote zugrunde, die die Denkweise eines
Sysadmins verdeutlicht - am Ende geht es darum, Risiken für Menschen
intuitiv handhabbar zu präsentieren (anstatt sie mit einem Regelwerk zu
überschütten).&lt;/p&gt;
&lt;h3 id=&#34;persönliche-betroffenheit-führt-zu-persönlicher-verantwortung&#34;&gt;
    &lt;a href=&#34;#pers%c3%b6nliche-betroffenheit-f%c3%bchrt-zu-pers%c3%b6nlicher-verantwortung&#34;&gt;
	Persönliche Betroffenheit führt zu persönlicher Verantwortung
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;web.de war eine geldreiche Arbeitsumgebung. Mit 150 Mio Euro auf der Bank
und ohne Schulden agiert eine Firma in Projekten nicht kostengetrieben,
sondern erlösgetrieben.&lt;/p&gt;
&lt;p&gt;Es ist eine Umgebung, in der man Großes bewirken kann, aber es ist auch eine
Umgebung, in der manche Projekteigentümer und Projektleiter nachlässig
werden. Das ist so, denn in so einer Umgebungs sind Kosten alleine eben kein
ausreichender Motivator, um bestehende Probleme anzugehen statt neue
Projekte zu beginnen - die Firma lebt von Velocity, also der Geschwindigkeit
der Innovation anstatt von Effizienz, denn Gewinn wird mit dem Wachstum des
Marktes gemacht statt der Konkurrenz Anteile abzunehmen (&lt;a href=&#34;http://en.wikipedia.org/wiki/Cynefin&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cynefin
Marktreife&lt;/a&gt;

 in den Quadranten Complex
und Complicated).&lt;/p&gt;
&lt;p&gt;So kommt es, daß in solchen Umgebungen manchmal Systeme im Einsatz sind, die
die für den Betrieb notwendige Stabilität nicht von sich aus mitbringen,
sondern bei der die Stabilität durch permanente Arbeit des Operatings
erzeugt wird.&lt;/p&gt;
&lt;p&gt;Will sagen, man hat Software mit Memory Leaks oder Race Conditions oder
anderen schwer zu findenden Fehlern, die mit einer gewissen
Eintrittswahrscheinlichkeit versehen sind. Der Betrieb erkennt die mit
Sicherheit &lt;em&gt;irgendwann&lt;/em&gt; eintretende Fehlersituation vorher und behebt das
Problem durch, äh, vorbeugende Wartung. Also durch das Herausnehmen einer
Komponente aus dem Loadbalancer und einen Neustart des betreffenden Systems
mit anschließender Reintegration oder vergleichbare Maßnahmen.&lt;/p&gt;
&lt;p&gt;Die zur Fehlersuche und Behebung notwendigen Stunden Entwicklerzeit will
niemand gutwillig bereitstellen, da es andere laufende Projekte verzögern
würde, also Velocity kosten würde. Und eine tatsächliche Aufwandsschätzung
ist bei Heisenbugs sowieso immer schwierig, da der Aufwand in der Regel in
Instrumentation und Warten besteht, solange der Fehler nicht mit
vernünftigem Aufwand im Labor provoizierbar ist. Man kann also nicht sagen
&amp;lsquo;Es wird circa 4 Stunden dauern, diesen Bug zu fixen&amp;rsquo;, weil man ihn
überhaupt erst mal beobachten muß.&lt;/p&gt;
&lt;p&gt;Wenn nun Kosten im Operating kein Instrument sind mit denen man seine
Projektleitung zur Bereitstellung von Ressourcen motivieren kann, dann ist
die erprobte Strategie der Managementmotivation im Operating eine, die ich
gerne mit &amp;ldquo;Teile die Schmerzen&amp;rdquo; beschrieben möchte.&lt;/p&gt;
&lt;p&gt;Zum Beispiel setzt man den Projekteigentümer auf dieselbe Alerting-Methode
wie den Sysadmin, der am Ende Sonntag nachts um 4 Uhr wegen eines Alarms die
vorbeugende Wartung durchführen muß. Die Begründung ist, daß der
Projekteigentümer bei einem System dieser Wichtigkeitsstufe ja über Ausfälle
informiert sein muß. Er muß schließlich bereit stehen, um als Entscheider
die notwendigen Anweisungen zu geben wenn etwas schiefgeht - so etwas
wichtiges kann man ja auf keinem Fall einem einfachen Operator überlassen.&lt;/p&gt;
&lt;p&gt;Wenn wir nun also einen jungen Projektverantwortlichen haben, bei dem das
Handy Sonntag nachts um vier die Frau und das 6 Monate alte Kind weckt, dann
ist diese Person nach einigen Wochen unmittelbaren Alerting-Erlebens sehr
viel zugänglicher, wenn auf auf einem Montagsmeeting der Vorschlag gemacht
wird, endlich einmal eine Hand voll Entwicklerstunden in die Verbesserung
der Stabilität dieses vergleichsweise wackeligen Systems zu stecken. Das
Interesse ergibt sich hier dann nicht aus den Projektkosten, sondern aus
persönlicher Betroffenheit.&lt;/p&gt;
&lt;h3 id=&#34;wieviel-risiko-ist-vertretbar&#34;&gt;
    &lt;a href=&#34;#wieviel-risiko-ist-vertretbar&#34;&gt;
	Wieviel Risiko ist vertretbar?
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Das ist derselbe Mechanismus, der auch unter den Admins selbst am Werk ist.
Sie machen Bereitschaft und sie bekommen Alarmmeldungen, Tag und Nacht.
Admins haben ein natürliches Interesse an den Schranken von Alarmen, denn es
sind diese Einstellungen der Sensitivität des Überwachungssystemen, nach
denen sich die Qualität ihres Nachtschlafs und das Klima in ihren Familien
bemißt. Admins wollen nicht von unnötigen Alarmen gestört werden, sie wollen
also keine false positives.&lt;/p&gt;
&lt;p&gt;Noch schlimmer sind aber false negatives, also Alarme die hätten gesendet
werden sollen, aber nicht gesendet wurden. Denn diese kosten nicht nur den
Bonus, sondern auch auf Wochen hinaus das Familien- und Arbeitsklima. In
einem funktionierenden Admin-Team - jedem funktionierenden Admin-Team -  mit
einem gut eingestellten Monitoring kann man also darauf vertrauen, daß
gerade eben so viele Alarme zu viel gesendet werden, daß die Meldungen des
Alarmierungssystems noch vertrauenswürdig sind.&lt;/p&gt;
&lt;p&gt;Die Schwellwerte im System ergeben sich empirisch unter dieser Strategie:
Überwachungssysteme werden erschaffen und messen Daten, generieren darauf
basierend Alarme - in der Regel viel zu viele Alarme.&lt;/p&gt;
&lt;p&gt;Ein gutes Admin-Team wird die meisten dieser Alarme ignorieren. Es wird
außerdem regelmäßig die ignorierten und beiseite geschobenen Alarme
auswerten, um daraufhin das Monitoring anzupassen, damit die Schwellwerte
realistischer werden. Die neuen Schwellwerte werden immer noch zu sensibel
sein, aber näher an realistischen Werten. Das Verfahren wird in der Regel
nicht formalisiert durchgeführt
(&lt;a href=&#34;http://en.wikipedia.org/wiki/Capability_Maturity_Model#Levels_of_the_Capability_Maturity_Model&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Capability Maturity&lt;/a&gt;


Rating 1 für den Prozeß: &amp;lsquo;individual heroics&amp;rsquo;), ist aber im Verhalten
wahrscheinlich einem inversen TCP Slow Start ähnlich (Man kann das natürlich
modellieren, aber mir sind keine formalen Papiere zum Thema
&amp;lsquo;Tuningalgorithmen für Monitoringsysteme&amp;rsquo; bekannt).&lt;/p&gt;
&lt;h3 id=&#34;risiken-menschengerecht-erlebbar-machen---shared-spaces-statt-regelsysteme&#34;&gt;
    &lt;a href=&#34;#risiken-menschengerecht-erlebbar-machen---shared-spaces-statt-regelsysteme&#34;&gt;
	Risiken menschengerecht erlebbar machen - Shared Spaces statt Regelsysteme
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Das Verhalten, das dem ganzen Zugrunde liegt, ist natürlich
&lt;a href=&#34;http://de.wikipedia.org/wiki/Risikokompensation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Risikokompensation&lt;/a&gt;

 und die ist in Grenzen
&lt;a href=&#34;http://www.sciencedirect.com/science?_ob=ArticleURL&amp;amp;_udi=B6VN8-4TK2PPX-1&amp;amp;_user=10&amp;amp;_coverDate=01%2F31%2F2009&amp;amp;_rdoc=1&amp;amp;_fmt=high&amp;amp;_orig=search&amp;amp;_sort=d&amp;amp;_docanchor=&amp;amp;view=c&amp;amp;_acct=C000050221&amp;amp;_version=1&amp;amp;_urlVersion=0&amp;amp;_userid=10&amp;amp;md5=0328819c455478dbdeed463b371a7f5e&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;modellierbar&lt;/a&gt;

.&lt;/p&gt;
&lt;p&gt;Menschen versuchen, ihr Verhalten so zu optimieren, daß sie ein System
möglichst voll &amp;lsquo;ausfahren&amp;rsquo;, seine Ressourcen also ausnutzen. Das heißt im
Verkehr zum Beispiel, daß sie ein Auto schneller fahren oder enger
überholen, wenn das Auto sich sicherer anfühlt oder eine bessere Lenkung
oder Bremsen bekommt. Der lenkende Mensch wird dabei versuchen, das gefühlte
Risiko stabil zu halten, indem er höhere Wagnisse eingeht.&lt;/p&gt;
&lt;p&gt;Man kann das umgekehrt nutzen, um mehr Sicherheit zu erzeugen, indem man
Menschen Risiken spüren läßt und Systeme baut, die sich linear und stetig
verhalten, also um Risiken für Menschen gut vorhersagbar und erlebbar
machen. Im Verkehr nennt man dieses Konzept
&lt;a href=&#34;http://de.wikipedia.org/wiki/Shared_Space#Risikobewertung&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Shared Space&lt;/a&gt;


und man kann es auch in der IT anwenden.&lt;/p&gt;
&lt;p&gt;Shared Space funktioniert eben nicht, indem man einfach die Verkehrszeichen
in einem Ort alle abmontiert und alle Bürgersteige planiert. Es gibt eine
Reihe von Vorraussetzungen, die alle zusammen erfüllt sein müssen, damit man
ein System hat, indem Menschen Risiken wahrnehmen und erkennen können und in
denen sie aktiv agieren, um diese zu vermeiden.&lt;/p&gt;
&lt;h4 id=&#34;visibility-und-predictability&#34;&gt;
    &lt;a href=&#34;#visibility-und-predictability&#34;&gt;
	Visibility (und Predictability)
    &lt;/a&gt;
&lt;/h4&gt;
&lt;p&gt;Eine ist zum Beispiel, daß man es mit einem System zutun hat, das linear
(oder logarithmisch) und stetig ist, bei dem also dem großen Knall eine
Reihe von kleineren, mit zunehmendem Risiko schlimmer werdenden Warnsignalen
auftreten - Menschen machen diese Annahme implizit, auch dann, wenn sie es
mit Systemen zu tun haben, die weder linear noch stetig sind. Baut man ein
System, bei dem Totalversagen nicht vorher von harmlosen Warnsignalen
angekündigt wird, oder bei dem das Versagensrisiko in einer Weise ansteigt
die von Menschen nicht intuitiv modellierbar ist, dann hat man ein System
das massenweise Leute umbringt. Die Gefahrensituation muß also für den
Menschen im Vorfeld erkennbar und vorhersehrbar sein - aktive und passive
&lt;strong&gt;Visibility&lt;/strong&gt;, sehen und gesehen werden, muß gegeben sein.&lt;/p&gt;
&lt;p&gt;In einem Shared Space-Verkehrsgebiet bedeutet das zum Beispiel, daß man
einige Kreuzungen umbauen muß, damit sie einsehbar werden oder andere
Gebiete so umbauen muß, daß die entzerrt werden, voneinander abhängige
Gefahrenquellen also entkoppelt werden und so auftreten, daß sie als
aufeinanderfolgende separate Ereignisse abgehandelt werden, statt die
Verkehrsteilnehmer mit zu vielen um Aufmerksamkeit konkurrierenden
Situationen gleichzeitig zu überfordern.&lt;/p&gt;
&lt;p&gt;In einer Produktionsumgebung in der IT bedeutet dies, daß man Systeme bauen
muß, die &amp;lsquo;sanft&amp;rsquo; versagen und rechtzeitig vorher erkennbare Warnsignale
generieren. Und daß man ein Monitoring haben muß, das ist der Lage ist,
solche Warnungen zu visualisieren. Am Besten auch eines, das allgemein
wahrgenommen wird - also Monitore mit Displays an wichtigen Stellen im
Betrieb.&lt;/p&gt;
&lt;h4 id=&#34;education&#34;&gt;
    &lt;a href=&#34;#education&#34;&gt;
	Education
    &lt;/a&gt;
&lt;/h4&gt;
&lt;p&gt;Eine andere Vorraussetzung ist, daß die Menschen in der Lage sein müssen,
die Gefahrensituationen erkennen und bewerten zu können. Shared Spaces
funktionieren also nur in einem Umfeld, in dem es eine passende
&lt;strong&gt;Ausbildung&lt;/strong&gt; gibt.&lt;/p&gt;
&lt;p&gt;Im Verkehr bedeutet das, daß Verkehrserziehung, Fahrausbildung und Awareness
auf dem richtigen Niveau sein müssen, damit den Verkehrsteilnehmern das
erwartete Verhalten, Handlungsmöglichkeiten und typisches Verhaltensfehler
bekannt sind, so daß sie mit vergleichbaren Erwartungen und gut trainierten
Sicherheitsreflexen in den Verkehr gehen.&lt;/p&gt;
&lt;p&gt;In einer Produktionsumgebung bedeutet das, daß den verantwortlichen
Mitarbeitern die Systeme, die sie fahren sollen, bekannt sind, sodaß sie ein
Modell des Systems im Kopf haben, das den betrieblichen Realitäten
entspricht, daß ihnen Diagnose- und Eingriffsmöglichkeiten bekannt sind und
daß sie Zugriff auf Eskalationsmöglichkeiten in der Systementwicklung haben,
wenn ein Fehler die Möglichkeiten des Operatings übersteigt.&lt;/p&gt;
&lt;h4 id=&#34;empowerment&#34;&gt;
    &lt;a href=&#34;#empowerment&#34;&gt;
	Empowerment
    &lt;/a&gt;
&lt;/h4&gt;
&lt;p&gt;Und die dritte Vorraussetzung ist, daß die Menschen in einem System die
Möglichkeit haben, Verantwortung zu übernehmen und ad-hoc vor Ort Regeln
aufzustellen oder Situationen verbindlich zu klären - das ist
&lt;strong&gt;Ermächtigung&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Im Verkehr bedeutet das, daß man Zeichen entfernt, die Entscheidungen des
Autofahrers überstimmen. Ampeln und Vorfahrtszeichen kommen weg, denn sie
bestimmen über den Kopf des Fahrzeugführers hinweg &amp;lsquo;Du mußt halten&amp;rsquo; oder &amp;lsquo;Du
kannst fahren&amp;rsquo;. Stattdessen ist der Fahrzeugführer jetzt verantwortlich,
sein Fahrzeug berührungsfrei durch den Verkehr zu bewegen und er muß jede
Halte- und Fahrentscheidung selbst und in letzter Verantwortung treffen. Das
kann er, denn er hat die notwendige Visibility - er wird gesehen und kann
sehen. Und er hat die notwendige Ausbildung.&lt;/p&gt;
&lt;p&gt;In einer Produktionsumgebung in der IT sieht es genau so aus - statt dem
Admins und Entwicklern einen Kubikmeter ITIL V3 Handbuch an den Kopf zu
werfen und zu sagen: &amp;ldquo;Implementiert das!&amp;rdquo; gibt man ihnen die Verantwortung
für den Betrieb und sagt: &amp;ldquo;Haltet das am Laufen! Was braucht Ihr dazu?&amp;rdquo;.
Mitarbeiter mit der passenden Ausbildung und der passenden Visibility sind
dazu in der Lage, das zu regeln, wenn man sie entsprechend ermächtigt.&lt;/p&gt;
&lt;p&gt;Die natürliche Risikoanpassung wird dann dazu führen, daß sie selbst die für
den Betrieb notwendigen Regeln und Absprachen ad-hoc treffen.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DENIC erklärt sich</title>
      <link>https://blog.koehntopp.info/2010/05/14/denic-erkl-rt-sich.html</link>
      <pubDate>Fri, 14 May 2010 15:14:05 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2010/05/14/denic-erkl-rt-sich.html</guid>
      <description>&lt;p&gt;Gestern ab halb zwei ging es los: Immer mehr DE-Domains waren nicht mehr
erreichbar. Schlimmer noch, anstatt keine Antwort zu liefern lieferten die
Nameserver für die Domain &amp;ldquo;de&amp;rdquo; die Antwort &amp;lsquo;Diese Domain gibt es nicht!&amp;rsquo;.
Das bedeutete eine ganze Reihe von Problemen - zum Beispiel ging Mail an
diese Domains mit &amp;lsquo;Unzustellbar wegen unbekannter Domain&amp;rsquo; an den Absender
zurück, anstatt bis zum Ende der Störung liegen zu bleiben.&lt;/p&gt;
&lt;p&gt;Was ging schief? In einer Mail auf
&lt;a href=&#34;http://www.denic.de/denic-im-dialog/mailinglisten/public-l.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;public-l&lt;/a&gt;

 hat die DENIC-Pressestelle
&lt;a href=&#34;http://www.denic.de/denic-im-dialog/mailinglisten/public-l.html?url=msg04454.xml&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;eine Erklärung veröffentlicht&lt;/a&gt;

:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Hintergrund dafür war, dass im Rahmen der regelmäßigen 2-stündigen
Aktualisierung der Nameservicedaten auf 12 der 16 Servicestandorte durch
einen unterbrochenen Kopiervorgang die Verteilung einer nicht
vollständigen Aktualisierung (sog. Zonendatei) angestoßen wurde&amp;hellip;.&lt;/p&gt;
&lt;p&gt;Zwar sollte auch dieser Vorgang abgesichert sein, der
Sicherungsmechanismus hat den Fehler allerdings nicht korrekt ausgewertet,
so dass im Effekt der Kopierfehler nicht entdeckt und der
Weiterverarbeitungsprozess nicht angehalten wurde.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Eine Zone ist DNS-Speak für eine Konfigurationsdatei für einen DNS-Server
und enthält in der Regel die Daten einer Domain. Die Zonendatei für DE ist
nun wie man sich leicht vorstellen kann besonders groß, da sie die
Konfigurations- und Delegationsdaten für alle DE-Domains enthält. Sie wird
aus einer Datenbank neu generiert und dann an die Nameserver verteilt, die
die DE-Domain betreiben. Dieser Verteilvorgang wurde nach Übertragung von
ca. einem Drittel der Daten unterbrochen und das Checkscript hat auf den
Fehler nicht korrekt reagiert und die Verarbeitung der Datei nicht
abgebrochen.&lt;/p&gt;
&lt;p&gt;In einem früheren Leben habe ich bei einem Kieler Provider gearbeitet und
auch dort hatten wir eine Reihe von Scripten, die Konfigurationsdateien aus
Datenbanken generiert haben. Neben anderen Integritätstests hatte wir in
diesen Scripten in der Regel auch eine Prüfung drin, die festgestellt hat,
wie sehr sich die Anzahl der Datensätze im Vergleich zum vorhergehenden Run
geändert hatte. Wenn die Fluktuation bei mehr als 10% lag, hat das Script
die Datei &lt;strong&gt;neben&lt;/strong&gt; der alten Datei installiert, aber nicht live geschaltet,
sondern eine Mail an die Admins geschickt, damit die sich das Ding mal
ansehen und es manuell live nehmen. Das hat uns mehr als einmal den Hintern
gerettet.&lt;/p&gt;
&lt;p&gt;Solche Sicherungen kann ich jedem Scripter von Admin-Diensten nur empfehlen!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Clue Bat</title>
      <link>https://blog.koehntopp.info/2008/09/18/the-clue-bat.html</link>
      <pubDate>Thu, 18 Sep 2008 10:10:55 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2008/09/18/the-clue-bat.html</guid>
      <description>&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/helpdesk_duty.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Scenes from the Amsterdam Office: Dennis, the maintainer of the local
&lt;a href=&#34;https://en.wikipedia.org/wiki/BOFH&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;BOFH&lt;/a&gt;


mailing list, performing helpdesk duty.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/support_tool.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Support Tool&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Wieviel Load darf es denn sein?</title>
      <link>https://blog.koehntopp.info/2005/06/24/wieviel-load-darf-es-denn-sein.html</link>
      <pubDate>Fri, 24 Jun 2005 08:47:16 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2005/06/24/wieviel-load-darf-es-denn-sein.html</guid>
      <description>&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/load-beispiel.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;In
&lt;a href=&#34;http://webhostingtech.de/2106/677.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wann ist die Serverload zu hoch?&lt;/a&gt;


fragt Reimer:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Die Frage, ob ein Serverload von n zu hoch sei, höre ich häufig.
Die Antworten sind jedoch ebenso unterschiedlich.
So wird häufig die Zahl 1,00 als normaler Wert gehandelt, aber genau so fallen Zahlen wie 5,00 und 8,00 etc.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In Linux und Unix gibt es einige Zahlen, mit denen man die CPU-Auslastung des Systems ausdrücken kann.
Da ist erst einmal die momentane CPU-Auslastung in Prozent, wie sie von &lt;code&gt;top&lt;/code&gt; und anderen Tools angezeigt wird:&lt;/p&gt;
&lt;p&gt;Diese Zahl gibt detailliert Auskunft darüber, wie die CPU &lt;em&gt;in diesem Moment&lt;/em&gt; ihre Zeit verbringt:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;go&#34;&gt;top - 10:49:36 up 11:53,  4 users,  load average: 2.71, 2.33, 2.20
&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;Tasks: 109 total,   3 running, 106 sleeping,   0 stopped,   0 zombie
&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;Cpu(s): 31.4% us,  8.9% sy,  0.0% ni, 47.5% id,  0.0% wa, 10.2% hi,  2.0% si
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Die Zahl &lt;code&gt;id&lt;/code&gt; ist die Idle-Zeit, die ungenutzte Zeit der CPU.
Die anderen Zahlen sagen detailliert, wie die CPU ihre Zeit verbringt: &lt;code&gt;us&lt;/code&gt; (User-Time) ist Zeit, die im Programm verbracht wird, und &lt;code&gt;sy&lt;/code&gt; (System-Time) die Zeit, die vom Kernel im Auftrag dieses Programmes verbraucht wird.
&lt;code&gt;ni&lt;/code&gt; (Nice-Time) ist Zeit, die von herunter priorisierten Prozessen sinnvoll verbraucht wird.
Alle drei Zeiten zusammen sind sinnvoll genutzte Arbeitszeit.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;wa&lt;/code&gt; (Wait-Time) ist I/O-Wait, also Zeit, die der Rechner auf das Eintreffen von Daten von der Platte oder dem Netzwerk wartet.
&lt;code&gt;hi&lt;/code&gt; und &lt;code&gt;si&lt;/code&gt; (Hard- und Soft Interrupt) sind Zeiten, die das System mit der Bearbeitung von Interrupts zubringt, also in Gerätetreibern und Timer-Routinen.&lt;/p&gt;
&lt;p&gt;Die Loadzahlen geben die mittlere Länge der Run-Queue über eine Minute (erste Zahl), fünf Minuten (zweite Zahl) und 15 Minuten (dritte Zahl) an.
Die Zahl sagt, wie viele Prozessoren das System im Schnitt auslasten könnte.
Wenn also die Load 1 ist, ist ein Einprozessorsystem so in etwa ausgelastet, eine Enterprise 10000 mit 64 CPUs in einer Domain ist bei einer Load von 64 gut ausgelastet.&lt;/p&gt;
&lt;p&gt;Die Load auf meinem System ist derzeit so:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/load-beispiel.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Für Auslastungsabschätzungen ist die blaue Fläche aussagekräftig, denn sie stellt die 15 Minuten-Load dar.
Diese Zahl ist relativ unempfindlich gegen lokale Lastspitzen und daher ein besseres Maß für die Auslastung (im Gegensatz zur Elastizität) des Systems.
Meine Maschine läuft derzeit tagsüber mit einer Load von ca. 0.8, ist also mit einem Prozessor zu etwa 80 % voll.
Zu einzelnen Zeitpunkten (nachts um 4:15 Uhr, wenn das News-Expire läuft), wird die Ideal-Last von 1 deutlich überschritten.
Das ist zu diesem Zeitpunkt aber nicht schlimm.&lt;/p&gt;
&lt;p&gt;Die Spitzenlasten (rote Kurve: 1 Minuten-Load, und davon das Maximum) halten sich außer um 4:15 Uhr im Rahmen, die Maschine kommt nicht nennenswert über Load 2 hinaus.
Die Kiste hat also nicht mehr allzu viel Reserven, ist aber auch noch nicht überlastet.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>

