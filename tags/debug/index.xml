<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>debug on Die wunderbare Welt von Isotopp</title>
    <link>https://blog.koehntopp.info/tags/debug.html</link>
    <description>Recent content in debug on Die wunderbare Welt von Isotopp</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 07 Jun 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://blog.koehntopp.info/tags/debug/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Fixing &#34;ip netns&#34; for docker</title>
      <link>https://blog.koehntopp.info/2020/06/07/fixing-ip-netns-for-docker.html</link>
      <pubDate>Sun, 07 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/06/07/fixing-ip-netns-for-docker.html</guid>
      <description>So I want to monitor my Jitsi Videobridge to get some useful statistics. The instructions say to enable Videobridge statistics and then grab stuff from port 8080.
Ok, I think I did that, but it did not work. Time to dig into the container network config.
And while I have a lot of network namespaces, they are unknown to ip netns, as can be seen when asking for a list. When we define a network namespace with ip netns, it will symlink the assigned name from /var/run/netns/&amp;lt;name&amp;gt; to /proc/&amp;lt;pid&amp;gt;/ns/net of the process that leads that namespace.</description>
    </item>
    
    <item>
      <title>House und Heisenberg revisited</title>
      <link>https://blog.koehntopp.info/2012/09/25/house-und-heisenberg-revisited.html</link>
      <pubDate>Tue, 25 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2012/09/25/house-und-heisenberg-revisited.html</guid>
      <description>Ich habe heute an dem Problem weiter geforscht und wir haben etabliert, dass die Ursache nicht der Quelltext des betreffenden Diamond-Collectors sein kann.
Auf allen betroffenen Kisten habe ich dann gesehen, daß die entsprechenden Queries gegen Performance-Schema ein
mysql&amp;gt;select\*fromperformance_schema.threads;Emptyset(0.01sec)zurück liefern.
Weitere Untersuchung stellt heraus: P_S ist aber an. Jedoch:
mysql&amp;gt;select\*fromperformance_schema.setup_instruments;Emptyset(0.03sec)mysql&amp;gt;select\*fromperformance_schema.setup_timers;Emptyset(0.01sec)mysql&amp;gt;select\*fromperformance_schema.setup_consumers;Emptyset(0.02sec)und das bleibt auch so, sogar über Server-Restarts hinweg. Warum ist das so?
# cd /mysql/\*/data/performance_schema/ # ls -l total 1840 -rw-rw---- 1 mysql mysql 8624 Oct 6 2011 cond_instances.</description>
    </item>
    
    <item>
      <title>Der Herr House und der Herr Heisenberg haben Replication Delay</title>
      <link>https://blog.koehntopp.info/2012/09/24/der-herr-house-und-der-herr-heisenberg-haben-replication-delay.html</link>
      <pubDate>Mon, 24 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2012/09/24/der-herr-house-und-der-herr-heisenberg-haben-replication-delay.html</guid>
      <description>Heute erreicht mich eine Mail, in der ein DBA sich über steigende Replication Delay in einer bestimmten Replikationshierarchie beschwert.
Das ist schlecht, denn die betreffende Hierarchie ist wichtig. Also die &amp;lsquo;Wenn die nicht geht schlafen Leute unter Brücken&amp;rsquo;-Art von wichtig.
Die Theorie war, daß die Änderungsrate in dieser Hierarchie so hoch ist, daß die Schreiblast von MySQL Replikation, die ja Single Threaded ist, nicht mehr bewältigt werden kann. Für diese Theorie sprach nach dem ersten Augenschein, daß alle betroffenen Kisten keine lokalen Platten hatten, sondern auf einem Filer lagen, und Filer sterben wegen der hohen Kommunikationslatenz im SAN bei uns in der Regel weit vor lokalen Platten, wenn es um Replikation geht: Filer sind mehr so beim parallelen Schreiben mit mehreren Threads gut.</description>
    </item>
    
    <item>
      <title>MySQL vs. Gigabit Network</title>
      <link>https://blog.koehntopp.info/2012/08/22/mysql-vs-gigabit-network.html</link>
      <pubDate>Wed, 22 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2012/08/22/mysql-vs-gigabit-network.html</guid>
      <description>Wir generieren eine neue Art von Materialized View mit dem bekannten Generator-Setup:
Das neue Setup unterscheidet sich in der Logik von denen, die wir bisher verwendet haben, und so kommt es beim Testlauf zu einem ungewöhnlichen und unerwarteten Ereignis:
Um 14:30: Ein Gigabit-Netzwerk mit 125 MB/sec ausgelastet.
Bei einem Probelauf gehen die Alarme los, weil der Gigabit-Netzwerkstrang zur Datenbank mit 125 MB/sec (Ein Gigabit/sec) vollständig ausgelastet ist. Wie man sehen kann, ist die Datenbank zu diesem Zeitpunkt nicht besonders beschäftigt:</description>
    </item>
    
    <item>
      <title>MySQL hakt...</title>
      <link>https://blog.koehntopp.info/2012/08/21/mysql-hakt.html</link>
      <pubDate>Tue, 21 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2012/08/21/mysql-hakt.html</guid>
      <description>&amp;ldquo;Hey, Kris! Wir haben zwischen 16:20 und 17:20 CEST einen Lasttest durchgeführt und kurz vor 17:00 Uhr einen unerklärlichen Spike und einen Leistungsabfall festgestellt. Kannst Du mal gucken?&amp;rdquo;
Klar kann ich. Wo ich arbeite machen wir etwas, das wir Testing in Production nennen.
Für Lasttests bedeutet das, daß wir einzelne Systeme im Loadbalancer so lange relativ höher gewichten bis sie Probleme bekommen und umfallen. Zur Kontrolle legen wir mit Apache Siege eine Reihe von Sensor-Requests in das zu testende System, nicht zur Lastgenerierung, sondern um zu sehen, wann die Latenz nach oben geht, also um Sättigung des zu testenden Systems zu bemerken bevor es Fehler zu generieren beginnt.</description>
    </item>
    
  </channel>
</rss>
