<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>cloud on Die wunderbare Welt von Isotopp</title>
    <link>https://blog.koehntopp.info/tags/cloud.html</link>
    <description>Recent content in cloud on Die wunderbare Welt von Isotopp</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 08 Nov 2021 19:16:49 +0000</lastBuildDate><atom:link href="https://blog.koehntopp.info/tags/cloud/feed.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Rechenzentren und ihren Stromverbrauch regulieren</title>
      <link>https://blog.koehntopp.info/2020/11/01/rechenzentren-und-ihren-stromverbrauch-regulieren.html</link>
      <pubDate>Sun, 01 Nov 2020 13:04:46 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/11/01/rechenzentren-und-ihren-stromverbrauch-regulieren.html</guid>
      <description>&lt;p&gt;Es gibt ein Interview mit Stefan Ramesohl vom Umweltministerium (des Bundes) in Netzpolitik.org: &amp;ldquo;&lt;a href=&#34;https://netzpolitik.org/2020/interview-zur-umweltpolitischen-digitalagenda-warum-niemand-weiss-wie-viele-rechenzentren-es-in-europa-gibt/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Warum niemand weiß, wie viele Rechenzentren es in Europa gibt&lt;/a&gt;

&amp;rdquo;. Im Wesentlichen hat das Umweltministerium angesagt, daß es auf europäischer Ebene Rechenzentren erfassen und katalogisieren will, um in einem zweiten Schritt den Energieverbrauch von Rechenzentren zu regulieren.&lt;/p&gt;
&lt;p&gt;Das ist sehr spannend, denn derzeit gibt es keine Übersicht über Rechenzentren in Europa, und tatsächlich sind einige Rechenzentrumsbetreiber sehr paranoid, was den genauen Standort ihrer Hardware angeht und wieviel und welche Hardware darin ist oder was diese tut. Das ist zwar lächerlich - es ist sehr schwierig eine Energiesenke wie ein Rechenzentrum und ihre Abwärme zu verstecken - aber auch ein sehr sensitives Thema.&lt;/p&gt;
&lt;h2 id=&#34;eine-leseliste&#34;&gt;
    &lt;a href=&#34;#eine-leseliste&#34;&gt;
	Eine Leseliste
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;In dem Interview gibt es ein paar Dinge, die Anmerkungen verdienen, aber bevor es los geht noch die anderen Artikel in diesem Blog als Links:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.koehntopp.info/2017/07/19/threads-vs-watts.html&#34;&gt;Threads vs. Watts&lt;/a&gt;

: Ich habe einen Dell R630 mit zwei Xeon 6132 CPUs getestet, und deren Energieverbrauch unter Last gemessen. Die Resultate sind repräsentativ für die ganze Klasse von Rechnern, die eine Art Arbeitspferd im modernen Rechenzentrum sind. Der Hauptpunkt: 50% der maximalen Energieaufnahme werden bereits bei 20% Auslastung aufgenommen.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.koehntopp.info/2018/02/21/a-journey-to-open-compute.html&#34;&gt;A Journey to Open Compute&lt;/a&gt;

: Mit Open Compute hat Facebook die Energieaufnahme eines Rechners in Idle auf 50% eines herkömmlichen Rechners senken können, und unter Volllast auf 80%. Das wird ermöglicht, indem man Rechner, Rack und Raum nach einer gemeinsamen Spezifikation baut und optimiert. Der Open Compute Standard ist jetzt eine offene Spezifikation, aber wegen der Abhängigkeiten zwischen Raum, Rack und Rechner lohnt sich das alles nur, wenn man ein &lt;a href=&#34;https://en.wikipedia.org/wiki/Big_Tech#GAFAM_or_FAAMG&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GAFAM&lt;/a&gt;

-type Hyperscaler ist.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.koehntopp.info/2017/11/07/power-budgets-for-computing-resources-portable-and-stationary.html&#34;&gt;Power budgets for computing resources - portable and stationary&lt;/a&gt;

 listet generell die Zusammenhänge zwischen Rechnen, Batterieverbrauch und Abwärme auf.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.koehntopp.info/2019/10/05/data-centers-and-energy.html&#34;&gt;Data Centers and Energy&lt;/a&gt;

: Wenn man Netflix schaut, wird Energie verbraucht. Wo und wieviel? Wir reden über Endgeräte (die nur wenige Watt brauchen), über Open Compute in Rechenzentren und über Energieverbrauch im Netzwerk, speziell auf der letzten Meile. Letzterer variiert enorm: 5G braucht sehr viel Energie, (V)DSL ist ebenfalls sehr aufwendig, und Glasfaser nicht - sie ist leicht eine Zehnerpotenz günstiger.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.koehntopp.info/2019/12/28/streaming-and-energy.html&#34;&gt;Streaming and Energy&lt;/a&gt;

 und &lt;a href=&#34;https://blog.koehntopp.info/2020/03/19/netflix-does-not-bring-down-the-internet.html&#34;&gt;Netflix does not bring down the Internet&lt;/a&gt;

: Speziell Videostreaming funktioniert schon sehr optimiert: Videos werden in Edge Data Centers gespeichert und nicht neu codiert, sie werden in der niedrigsten sinnvollen Auflösung geliefert und die Decodierung erfolgt mit spezieller Hardware, damit die Batterie im Endgerät länger hält. All das braucht weniger Energie als angenommen.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.koehntopp.info/2020/06/08/cloud-and-energy.html&#34;&gt;Cloud and Energy&lt;/a&gt;

: Das Uptime Institut sagt: &amp;ldquo;Data center energy efficiency gains have flattened out&amp;rdquo; (und sieht einen durchschnittlichen PUE von 1.58). Uptime sagt im selben Text aber auch, daß neuere und größere Facilities mit Open Compute &lt;em&gt;signifikant&lt;/em&gt; bessere PUE haben. Der einfachste Weg zur Verbesserung von PUE für die meisten Firmen ist, ihre Workloads in die Cloud zu verlagern (und dynamisch zu skalieren). Das hat bei korrekter Durchführung neben Energieffizienz auch noch jede Menge andere Vorteile, die sich aus einem gelungenen Outsourcing ergeben.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;hyperscaler-rechenzentren-sind-viel-energieeffizienter&#34;&gt;
    &lt;a href=&#34;#hyperscaler-rechenzentren-sind-viel-energieeffizienter&#34;&gt;
	Hyperscaler-Rechenzentren sind viel energieeffizienter
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Auf Twitter ging ich auf &lt;a href=&#34;https://twitter.com/isotopp/status/1322857383929012224&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;das Interview ein&lt;/a&gt;

:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Netzpolitik.org:&lt;/em&gt; Diese großen Player können ja kein Interesse an staatlicher Regulierung haben, sondern werden versuchen, eine branchenweite Selbstverpflichtung herbeizuführen.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Eher nicht. Als &lt;a href=&#34;https://en.wikipedia.org/wiki/Big_Tech#GAFAM_or_FAAMG&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GAFAM&lt;/a&gt;

 wäre man sinnvollerweise für mehr Regulierung, denn das käme effektiv einem Cloud-Zwang gleich.&lt;/p&gt;
&lt;p&gt;Wie oben bereits dargestellt, hat GAFAM bereits Rechenzentren, die sehr viel effizienter mit der Energie umgehen als normale Rechenzentren es tun. Das ist so, weil diese Rechenzentren Raum, Rack und Rechner als ein System designed haben und weil die Betreiber als Hyperscaler es sich leisten können, solche Rechenzentren nach Maß zu designen, bauen zu lassen und zu optimieren.&lt;/p&gt;
&lt;p&gt;Während also ein traditionelles Rechenzentrum Rechner für eine Million Watt betreibt und dafür um die 600.000W an Kühlung und anderer Sekundärenergie aufbringen muß (Power Utilization Efficiency, PUE 1.6), können die am Besten optimierten Google-Rechenzentren eine Million Watt an Rechnern mit 60.000W Sekundärenergie betreiben (PUE 1.06).&lt;/p&gt;
&lt;p&gt;Ein effektiver PUE von &amp;lt;1.2 ist par für die Hyperscaler-Cloud.&lt;/p&gt;
&lt;p&gt;Ein kleinerer Rechenzentrums-Nutzer füllt nicht ein ganzes RZ mit Rechnern, läßt also nicht nach Maß bauen, sondern mietet existierenden RZ-Space, der prinzipbedingt nicht gut geeignet ist für Open Compute (OCP). Existierende RZ-Space ist generisch, er muß jede Art von IT-Equiment aufnehmen können und ist daher oft Überkühlt, der Airflow ist nicht optimiert und hat auf diese Weise mindestens dreimal mehr Overhead als RZ-Space, den Hyperscaler nach Maß bauen (PUE &amp;lt;1.2 vs. PUE ~ 1.6). Noch kleinere Benutzer füllen nur einzelne Räume oder haben Raumabschnitte (&amp;ldquo;Cages&amp;rdquo;), teilen also die Kühlung mit anderen Nutzern.&lt;/p&gt;
&lt;p&gt;Hyperscaler bauen nicht nur ein RZ, sondern tun das in Serie, und iterieren dabei das Design. Sie lassen auch Rechner und Rechnerkonzepte wie OCP entwickeln, und stimmen dabei das Design des RZ auf das Design von Rack und Rechner ab - daher kommt die energetische Überlegenheit von OCP.&lt;/p&gt;
&lt;p&gt;Dazu kommt, wie oben auch dargestellt, daß ein ausgelasteter Rechner energieeffizienter ist als einer, der teilweise vor sich hin idled. Ein Dell R630 verbraucht bereits 50% seiner maximalen Energie bei 20% Auslastung.&lt;/p&gt;
&lt;p&gt;Maschinen auszulasten und Workloads dynamisch zu skalieren ist etwas, für das &amp;ldquo;die Cloud&amp;rdquo;, also die API-gesteuerten Rechenzentren der Hyperscaler, gebaut worden sind. Hyperscale Clouds haben &amp;ldquo;sellable cores per provisioned cores&amp;rdquo; als eine zentrale Optimierungsmetrik, sie wollen ausgelastete Rechner, weil das die Einnahmen definiert.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2017/07/watt-thread.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Watts per Thread (Dell R630, Dual Xeon 6132)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Wie dem auch sei: Aus energetischer Sicht ist Auslastung wichtig, weil die Watts zur Aktivierung des n-ten Rechenkerns asymptotisch günstiger sind. Das ist so, weil die Idle-Energieaufnahme der Maschine und des ganzen Rechenzentrums drumherum sich so amortisiert.&lt;/p&gt;
&lt;p&gt;Außerdem: Wenn man es sich leisten kann, Hyperthreading zu aktivieren (Wegen der diversen Intel-Caching-Bugs der letzten Jahre ist das oft ein Sicherheitsrisiko), dann sind die Hyperthreads energetisch betrachtet nahezu kostenfrei. Integer- und Stringprocessing-Workloads können Hypterthreads als nahezu vollwertige zweite CPU betrachten, Fließkomma-intensive Workloads nicht.&lt;/p&gt;
&lt;p&gt;Webshops sind, wenn sie richtig gebaut worden sind, String- und Integer-Anwendungen und sehr wenig Fließkomma-intensiv, könnten also von Hyperthreading voll profitieren. Die Anzahl der nutzbaren Cores verdoppelt sich rechnerisch und ist bei Webshop fast vollständig realisierbar - ein Webshop mit einer fast reinen Integer/String Workload kann von den 56 rechnerischen Kernen einer Dual-6132 eine Load von deutlich über 40 stabil verarbeiten.&lt;/p&gt;
&lt;h2 id=&#34;kosten-und-energie&#34;&gt;
    &lt;a href=&#34;#kosten-und-energie&#34;&gt;
	Kosten und Energie
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Über eine Nutzungsdauer von fünf Jahren gerechnet machen Energiekosten in etwa die Hälfte der Gesamtkosten eines Rechners aus - für einen Hyperscaler ist das ein so intensiver Kostenfaktor, daß sie aus wirtschaftlichen Gründen seit mehr als 15 Jahren intensiv die Energieaufnahme ihrer Rechenzentren in allen Punkten optimieren.&lt;/p&gt;
&lt;p&gt;Das ist der primäre Grund für das Open Compute Projekt (OCP) und die Bauweise der Hyperscaler-Rechenzentren. Für Hyperscaler lohnt dies, weil das der Kernbereich ihres wirtschaftlichen Handelns ist.&lt;/p&gt;
&lt;p&gt;Dazu kommt, wie in der Leseliste dargestellt, daß alle Hyperscaler (bis auf Amazon) bereits 100% graugrün sind, also zu großen Teilen bereits auf tatsächlich regenerativer Energie laufen und den Rest mit Zertifikaten kompensieren, und obendrein sehr nah in der Zukunft liegende Ziele haben, was komplett grünen Betrieb &lt;em&gt;und&lt;/em&gt; Überkompensation angeht. Speziell Google ist ein sehr großer Investor in Wind- und Solarkraftanlagen, Netflix überkompensiert bereits jetzt, ist also Carbon-Negative.&lt;/p&gt;
&lt;p&gt;Für ein Firma, für die der Betrieb und die Skalierung von Rechenzentren und ihrer Hardware nicht der Kern ihres wirtschaftlichen Handelns ist, ist es ausgeschlossen hier mitzuhalten.&lt;/p&gt;
&lt;p&gt;Oder wie Ramesohl es formuliert:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Es ist einfach so, dass eine gewisse Skalierung zu großen Vorteilen führt, die dann wiederum über eine Wettbewerbsfähigkeit im Markt die Marktposition stärkt und damit den Marktanteil erhöht. Das ist ein selbstverstärkender Effekt. Hinzu kommt, dass diese Akteure in der Lage waren, zu investieren und sich damit ein technologisches Know-how aufzubauen, was wiederum im Umkehrschluss ihre Marktposition stärkt.&lt;/p&gt;
&lt;p&gt;Das ist richtig, dass gerade bei den großen Playern entsprechende selbstdefinierte Nachhaltigkeitsziele vorliegen. Das sind teilweise sehr ambitionierte Pläne, die versuchen, die Emissionen, die im Laufe der Unternehmensgeschichte bisher aufgelaufen sind, rückwirkend zu kompensieren.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;bandbreite-und-energie&#34;&gt;
    &lt;a href=&#34;#bandbreite-und-energie&#34;&gt;
	Bandbreite und Energie
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Ramesohl sagt auch:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Da geht es um die Frage, ob jede Internetwerbung eine Autoplay-Funktion braucht, also abspielt, wenn ich nur über die Seite scrolle. Das erzeugt nämlich ein enormes Datenvolumen. Oder die Frage, ob alles standardmäßig in höchster Auflösung gestreamt werden muss, wenn es auf einem kleinen Bildschirm angeschaut wird.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Dahinter steht die Fehlmeinung, daß eine Netzwerkinfrastruktur mehr Energie benötigt, wenn Daten übertragen werden. Das ist nicht der Fall.&lt;/p&gt;
&lt;p&gt;So wie eine Festplatte oder RAM nicht schwerer werden oder mehr Energie verbrauchen, wenn Daten darin gespeichert werden, so braucht ein kabelgebundenener Netzwerklink nicht (wesentlich) mehr Energie, wenn Daten übertragen werden.&lt;/p&gt;
&lt;p&gt;RAM und Festplatten brauchen (mehr) Energie, wenn Daten &lt;em&gt;geändert&lt;/em&gt; werden, also Bits gekippt werden.&lt;/p&gt;
&lt;p&gt;Und kabelgebundenene Netzwerkinfrastruktur überträgt immer Daten (Trägersignale), auf die die Nutzlast dann aufmoduliert wird. Das wiederum braucht im Vergleich zur Grundlast des Netzes (das Senden des Trägers) kaum Energie. Anders sieht es bei Funkverbindungen, also Datenübertragung via Mobilfunknetz aus, dort wird der Sender komplett abgeschaltet, wenn er nicht gebraucht wird, um das Spektrum frei zu halten.&lt;/p&gt;
&lt;p&gt;Speziell bei Glasfaser ist es so, daß man die Bandbreite zudem mit nur wenig mehr Energieaufwand um Größenordnungen hochdrehen kann, wenn man will - durch den Austausch der Laser kann dasselbe Medium in der Kapazität verzehnfacht oder verhundertfacht werden ohne signifikat mehr Energie zu verbrauchen.&lt;/p&gt;
&lt;h2 id=&#34;was-tun-wir-mit-all-dem-compute&#34;&gt;
    &lt;a href=&#34;#was-tun-wir-mit-all-dem-compute&#34;&gt;
	Was tun wir mit all dem Compute
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Am Ende ist es eventuell eine gute Idee, nicht nur genauer hin zu schauen, wo Rechenzentren stehen und wie sie designed sind, sondern was mit den Megawatts gemacht wird, die dort verwendet werden. Auf diese Weise bekommen wir eventuell Bitcoin weg gebombt. Das wäre schon einmal sehr wichtig, denn hier wird Energie in der Größenordnung ganzer Staaten in sinnlosen Berechnungen (&amp;ldquo;Proof of Work&amp;rdquo;) verheizt. Und nein, das kann man nicht ändern, PoW kann nicht sinnvolles berechnen.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>IT modernisieren und konsolidieren</title>
      <link>https://blog.koehntopp.info/2020/10/05/it-modernisieren-und-konsolidieren.html</link>
      <pubDate>Mon, 05 Oct 2020 21:52:04 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2020/10/05/it-modernisieren-und-konsolidieren.html</guid>
      <description>&lt;p&gt;Ich schrieb in einem &lt;a href=&#34;https://twitter.com/isotopp/status/1313084134168944640&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Twitter Thread&lt;/a&gt;

 über &lt;a href=&#34;https://blog.koehntopp.info/2020/10/05/what-are-the-problems-with-posix.html&#34;&gt;Posix Dateisysteme vs. Object Stores&lt;/a&gt;

:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;UNIX FS ist 1974.
BSD FFS ist 1984.
XFS ist 1994.
ZFS (und Btrfs und Wafl) sind LFS, also 2004.
Object Storages, LSM, &amp;ldquo;RocksDB&amp;rdquo; ist ca. 2014, um den Takt zu halten.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;und wurde gefragt: &amp;ldquo;Was kommt 2024&amp;rdquo;. Meine halb spöttische, halb ernst gemeinte Antwort war:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Irrelevant.&lt;/p&gt;
&lt;p&gt;2024 läuft Dein Code serverless bei einem professionellen Betreiber und vom lokalen System und dem lokalen Dateisystem kriegst Du nix mehr zu sehen außer einer monatlichen Rechnung.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;rein-in-die-cloud&#34;&gt;
    &lt;a href=&#34;#rein-in-die-cloud&#34;&gt;
	Rein in die Cloud
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Selbst wenn es kein &amp;ldquo;serverless&amp;rdquo; ist, sondern eine VM oder ein Container: Wir haben dazu gelernt, und sind besser geworden. Deswegen sind aber auch unsere Standards und Anforderungen gestiegen und wir brauchen bessere Umgebungen.&lt;/p&gt;
&lt;p&gt;Die Prozesse und die Technik lokal so aufzusetzen, daß man weiterhin compliant bleibt mit SOX, PCI und PII ist eine ganze Menge Arbeit, die nicht zur Kern-Mission der meisten Unternehmen gehört. Es ist auch ein Investment, das besser in geschäftsrelevante Bereiche ginge. Techniken und Infrastruktur bereit zu stellen, die in einem Amazon-like Environment &amp;ldquo;so da&amp;rdquo; ist wird immer schwieriger und teurer werden.&lt;/p&gt;
&lt;h3 id=&#34;ein-paar-selbstverständlichkeiten&#34;&gt;
    &lt;a href=&#34;#ein-paar-selbstverst%c3%a4ndlichkeiten&#34;&gt;
	Ein paar Selbstverständlichkeiten
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Auf der Minimum-Liste für alle stehen inzwischen Dinge wie&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Single Sign On und Identity Management (SSO und IAM)&lt;/li&gt;
&lt;li&gt;Rollenbasierte Access Controls (RBAC)&lt;/li&gt;
&lt;li&gt;eine PKI&lt;/li&gt;
&lt;li&gt;Encryption at Rest und Encryption in Flight&lt;/li&gt;
&lt;li&gt;Administrator Roles mit Segregation of Duties&lt;/li&gt;
&lt;li&gt;Mandatory Access Controls and Privilege Limits&lt;/li&gt;
&lt;li&gt;Audit Trails&lt;/li&gt;
&lt;li&gt;Complance und Audit von all dem&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Und das ist schon mehr Arbeit als man als Firma mit einem eigenen RZ-Betrieb selbst leisten und erfinden kann. Es ist auch etwas, das so nicht fertig kaufbar und als Produkt installierbar ist, weil es eben nicht nur Technik ist, sondern auch Prozeß und Kultur.&lt;/p&gt;
&lt;p&gt;Es sind aber alles Dinge, die man als Technik in einem AWS Environment oder einer anderen großen Cloud per Default bekommt und zu der es dann auch Unterweisungen gibt, die einem Best Practices und funktionierende Prozesse nahe bringen.&lt;/p&gt;
&lt;p&gt;Dazu kommen dann Dienste, die in einem eigenen Rechenzentrum mühevoll oder teuer zu schaffen sind, die man aber in einer großen Cloud testweise oder produktiv dazu nehmen kann, ohne eigenen Aufwand zu treiben.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Geocoder&lt;/li&gt;
&lt;li&gt;Spracherkennung&lt;/li&gt;
&lt;li&gt;Bilderkennung&lt;/li&gt;
&lt;li&gt;Integration in eine skalierbare Big Data Umgebung&lt;/li&gt;
&lt;li&gt;Integration von Eventprozessoren&lt;/li&gt;
&lt;li&gt;Event Driven Execution (&amp;ldquo;Step Functions&amp;rdquo;), die es auch Nicht-Codern erlauben, Anwendungen durch Zusammenklebeben von -aaS Diensten zu schaffen.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Aber das sind nur Beispiele aus hunderten von Diensten&amp;hellip;&lt;/p&gt;
&lt;h3 id=&#34;nicht-die-mission-der-meisten-betriebe&#34;&gt;
    &lt;a href=&#34;#nicht-die-mission-der-meisten-betriebe&#34;&gt;
	Nicht die Mission der meisten Betriebe
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Das ist etwas, das einer traditionellen RZ-IT nicht zugänglich ist, und das auch unverhältnismäßig viel Kapital, Investment und Personal binden würde, würde man es selbst lokal entwickeln. Schon so etwas simples wie RDS funktioniert besser und automatischer als alle selbstgestrickten DevOps Managementscripte für Datenbanken, die man selbst haben kann.&lt;/p&gt;
&lt;p&gt;Druck kommt nicht nur aus dem Management und aus der Compliance, sondern auch von unten: Die aktuelle Generation von Entwicklern hat nie mit einem lokalen RZ gearbeitet, sondern ist in AWS groß geworden. Sie setzt die Qualität der Implementierung und die Prozesse von Amazon als gegeben und als Maßstab voraus. Sie setzt die Leichtigkeit von Operations und Observability voraus, die für eine Cloud-Umgebung typisch sind.&lt;/p&gt;
&lt;p&gt;Deswegen ist die Zukunft von 2024 mindestens hybrid. Aber effektiv wird kein Betrieb mit einem lokalen Rechenzentrum und reinen IaaS-Angeboten noch groß Stiche holen.&lt;/p&gt;
&lt;p&gt;Das ist einer der Gründe, warum Europa als Technologieraum zunehmend abgehängt ist. Nicht nur viele Politiker und Entscheider verstehen nicht mehr, was in den letzten 10 Jahren passiert ist, sondern auch viele Sysadmins &amp;ldquo;on the ground&amp;rdquo; haben die Veränderung des Entwicklerbetriebes in den letzten 10 Jahren grundlegend verpaßt und können nicht erkennen, welche Gestaltungsdrücke gerade auf ihrer Umgebung lasten.&lt;/p&gt;
&lt;p&gt;Das sehen wir nicht nur in der &amp;ldquo;deutsche Schulen in COVID&amp;rdquo; Videokonferenzdiskussion, sondern auch in der ganzen Klasse von BOFH-Bemerkungen, die aus dem Sysadmin Lager oft kommt. Ich habe dazu vor über fünf Jahren schon einmal was gemacht: &lt;a href=&#34;https://www.slideshare.net/isotopp/go-away-or-i-will-replace-you-with-a-little-shell-script#2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides: Go away or I will replace you with a very small Shell script - ein paar Gedanken zum Thema Devops&lt;/a&gt;

 (&lt;a href=&#34;https://media.ccc.de/v/froscon2015-1500-go_away_or_i_will_replace_you_with_a_very_little_shell_script&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Video von der Froscon Version&lt;/a&gt;

).&lt;/p&gt;
&lt;p&gt;Die Frage ist nicht, wie ein lokales Rechenzentrum Rechner betreibt und bereitstellt - das ist ein gelöstes Problem. Sondern welche Dienste sie darauf fertig im Angebot haben, ob diese Dienste mit aktuellen Standard und Anforderungen in Compliance sind, ob sie eine API haben, und sie mit lokalem Tooling integrierbar sind.&lt;/p&gt;
&lt;h3 id=&#34;integration-und-bildung-von-untereinander-abhängigen-systemen&#34;&gt;
    &lt;a href=&#34;#integration-und-bildung-von-untereinander-abh%c3%a4ngigen-systemen&#34;&gt;
	Integration und Bildung von untereinander abhängigen Systemen
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Wir sind dabei, von individuellen, frei stehenden und trennbaren Teilen zu integrierten Systemen zu gehen. Das hat Vorteile, weil so Prozesse entstehen und eingeübt werden, die meßbar Qualität verbessern und - wichtiger noch - automatisieren.&lt;/p&gt;
&lt;p&gt;Das ist nicht nur im Bereich Betrieb mit der Cloud so, sondern ist ein größerer Trend, der auch in der Software-Entwicklung sichtbar wird: Entwickler arbeiten nicht mehr mit vi im leeren Editor, sondern haben in der Regel Sprachen mit umfangreichen Bibliotheken und Integrationen im Betrieb. Das hat Folgen.&lt;/p&gt;
&lt;p&gt;In der Entwicklung: Wenn es keinen JetBrains-Editor für die Sprache gibt, wenn sie von gitlab und github nicht erkannt und ausgewertet wird, wenn sie keinen Dependency-Manager und keine CI/CD Integration hat, dann ist eine moderne Programmiersprache - Entschuldigung - Plattform - Entschuldigung - Ökosystem nicht vollständig und nicht mehr konkurrenzfähig.&lt;/p&gt;
&lt;p&gt;Wenn eine Sprache nicht von einschlägigen Security- und Audit-Werkzeugen unterstützt wird, wenn sie nicht &lt;a href=&#34;https://www.sonarqube.org/features/multi-languages/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bei SonarQube&lt;/a&gt;

 oder ähnlichen auf der Liste steht, wenn sie nicht von Valgrind, Fuzzern und anderen Werkzeugen unterstützt wird, dann hat eine moderne Programmierumgebung in einem Enterprise-Umfeld zunehmend Schwierigkeiten, die steigenden Compliance-Anforderungen im Bereich Software-Entwicklung und Qualitätssicherung zu erfüllen.&lt;/p&gt;
&lt;p&gt;Im Betrieb: Ohne Identity, PKI, SSO, RBAC, Segregation of Duties, Encryption überall, Auditing und enforceable maximum permissions hast Du Compliance Probleme oder wirst sie bald haben. Und ohne eine API für alles, Tooling für diese API, Infrastructure als Code, Codified Practices wie CI/CD hast Du keine attraktive und effektive Entwicklungsumgebung für Deine eigenen Leute.&lt;/p&gt;
&lt;p&gt;Das sind aber Gedanken und Entwicklungen, die in Deutschland an Politik und an Teilen der &amp;ldquo;Informatikschaffenden&amp;rdquo; vorbei gegangen sind, oder belächelt worden sind.&lt;/p&gt;
&lt;h2 id=&#34;raus-aus-der-cloud&#34;&gt;
    &lt;a href=&#34;#raus-aus-der-cloud&#34;&gt;
	Raus aus der Cloud
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Offensichtlich sind Server Wurst. Die Frage ist mehr, was da drauf läuft, welche Dienste und Integrationen bestehen. Das ist mit einem IT-Team von 4-5 Leuten vor Ort nicht sinnvoll zu schaffen, sondern im günstigsten Fall ein blankes IaaS, nicht unbedingt von der guten und vertrauenswürdigen Sorte.&lt;/p&gt;
&lt;p&gt;Schau Dir an, was zum Beispiel Scaleway oder OVH macht, oder 1und1 in Deutschland. Das sind fitte Teams, die eine Menge weg schaffen. Aber deren Clouds sind relativ dienstfreie IaaS-Clouds mit ein wenig Object Storage, und alle größeren Dinge mußt Du Dir selbst auf deren IaaS ansibilisieren.&lt;/p&gt;
&lt;p&gt;Das ist aber der Stand von 2010, nicht 2020. In 2020 ist ein Cloudkunde hinter Diensten her, damit er die nicht selbst betreiben muß.&lt;/p&gt;
&lt;p&gt;Es ist ja nicht nur unwürdig, HPE deren defekte iLOs und kaputte Festplatten-Firmware zu debuggen, sondern man will sich auch einfach ein MySQL oder Postgres klicken können. Oder gar einfach &amp;ldquo;einen KV Storage benutzen&amp;rdquo; und Dein Zeugs in ein Dynamo kippen und Dich gar nicht mehr um Instanzgrößen kümmern müssen, sondern nur noch für Storage und Zugriff nach Verbrauch bezahlen.&lt;/p&gt;
&lt;p&gt;Und an dieser Stelle kommt wieder die Politik durch.&lt;/p&gt;
&lt;h3 id=&#34;arbeitsteilung-beruht-auf-vertrauen-vertrauen-kommt-aus-transparenz-und-verläßlichkeit&#34;&gt;
    &lt;a href=&#34;#arbeitsteilung-beruht-auf-vertrauen-vertrauen-kommt-aus-transparenz-und-verl%c3%a4%c3%9flichkeit&#34;&gt;
	Arbeitsteilung beruht auf Vertrauen. Vertrauen kommt aus Transparenz und Verläßlichkeit
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Das funktioniert mit den Diensten nämlich ganz wunderbar in der &amp;ldquo;Arbeitsteiligen Gesellschaft™&amp;rdquo; - wir nennen so etwas Zivilisation. Nur, wenn wir zivilisiert, verantwortungsvoll und vertrauensvoll miteinander umgehen, dann kann man sich selbst die Arbeit mit den ganzen Diensten schenken und jemand anders beauftragen.&lt;/p&gt;
&lt;p&gt;Dazu sind bestimmte gesellschaftlichen Bedingungen notwendig, die zu schaffen sind. Wir brauchen ein System von Checks und Balances, internationalen Verträgen und Business Practices, und dann ein System von Kontrollen und &lt;em&gt;Vertrauen in die Wirksamkeit dieser Kontrollen&lt;/em&gt;, damit wir zivilisiert cloudcomputen können.&lt;/p&gt;
&lt;p&gt;Wenn Du aber einzelne Nation States hast, die technisch gesehen als Attacker da stehen (&amp;ldquo;Nation State Attacker&amp;rdquo;, &amp;ldquo;NSA&amp;rdquo;) und sich das auch so vorbehalten, dann ruiniert das die Geschäftsgrundlage für die arbeitsteilige Gesellschaft, mithin die Zivilisation selbst.&lt;/p&gt;
&lt;p&gt;Wenn Du einzelne Anbieter hast, die über die Verarbeitung und Nutzung der Daten nicht transparent sind, oder man den von ihnen vorgezeigten Audits kein Vertrauen schenken kann, dann &amp;hellip; genau dasselbe.&lt;/p&gt;
&lt;p&gt;Und wenn Du eine Politik hast, die ein Klima schafft, in der das Verständnis dieser Tatsachen geleugnet oder ignoriert wird, dann ruiniert das dieses Konzept schon.&lt;/p&gt;
&lt;p&gt;Das ist genau das, was Gestalten wie Trump, BoJo aber auch von Storch zerstören, wenn sie Isolationismus, Staatswilkür und Ignoranz gegenüber internationaler Ordnung demonstrieren. Das ist aber auch das, was Gestalten wie Audi Scheuer und sein Meister, Imperator Seehofer vernichten, denn solche vorgelebte Unfähigkeit und Korruption saugen der Zivilisation das Rückenmark aus. Das ist dann das, was zu Dingen wie Wirecard führt, zum Dieselskandal und zu Situationen, bei denen ein Volkswagen-Compliancemanager bei der Dokumentation illegaler Geschäftspraktiken auf eine Weise zu Tode kommt, die in jede Netflix-Mafiaserie gepaßt hätte.&lt;/p&gt;
&lt;p&gt;In so einem Umfeld ist eine Auslagerung der IT an Dritte für Unternehmen ein bedenkenswertes Risiko statt eine Erleichterung.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Verschlüsselt Dropbox überhaupt?</title>
      <link>https://blog.koehntopp.info/2011/04/26/verschl-sselt-dropbox-berhaupt.html</link>
      <pubDate>Tue, 26 Apr 2011 17:32:36 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2011/04/26/verschl-sselt-dropbox-berhaupt.html</guid>
      <description>&lt;p&gt;Dropbox ist in den letzten Tagen und Wochen ein wenig seltsam in die
Schlagzeilen geraten.&lt;/p&gt;
&lt;p&gt;Da ist einmal der Artikel von Derek Newton:
&lt;a href=&#34;http://dereknewton.com/2011/04/dropbox-authentication-static-host-ids/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dropbox Authentication: Insecure by design&lt;/a&gt;

:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;After some testing (modification of data within the config table, etc) it
became clear that the Dropbox client uses only the host_id to
authenticate. Here’s the problem: the config.db file is completely
portable and is &lt;em&gt;not&lt;/em&gt; tied to the system in any way. This means that if
you gain access to a person’s config.db file (or just the host_id), you
gain complete access to the person’s Dropbox until such time that the
person removes the host from the list of linked devices via the Dropbox
web interface.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Dann ist da die Änderung der TOS, die vorher ein wenig irreführend
formuliert waren: Vorher konnte man die TOS so lesen, daß die
Dropbox-Dateien auf den Dropbox-Servern verschlüsselt gespeichert werden und
Dropbox selber keine Kopien dieser Schüssel hatte. Das ist natürlich nicht
der Fall: Für den Betreiber ist das alles Klartext, wenn er denn nur will.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://blog.dropbox.com/?p=735&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Und er will&lt;/a&gt;

:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We may disclose to parties outside Dropbox files stored in your Dropbox
and information about you that we collect when we have a good faith belief
that disclosure is reasonably necessary to (a) comply with a law,
regulation or compulsory legal request; (b) protect the safety of any
person from death or serious bodily injury; (c) prevent fraud or abuse of
Dropbox or its users; or (d) to protect Dropbox’s property rights. If we
provide your Dropbox files to a law enforcement agency as set forth above,
we will remove Dropbox’s encryption from the files before providing them
to law enforcement. However, Dropbox will not be able to decrypt any files
that you encrypted prior to storing them on Dropbox.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Und schließlich nun:
&lt;a href=&#34;http://www.techdirt.com/articles/20110425/15541514030/dropbox-tries-to-kill-off-open-source-project-with-dmca-takedown.shtml&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dropbox Tries To Kill Off Open Source Project With DMCA Takedown&lt;/a&gt;

.
Diese Geschichte ist recht interessant, denn sie beleuchtet eine
Inkonsistenz in den Behauptungen von Dropbox - und hat mit der
Verschüsselung aus dem vorhergehenden Fall zu tun.&lt;/p&gt;
&lt;p&gt;Dropbox speichert Dateien. Die meisten Leute haben Dateien, die auch andere
Leute haben. Das ist schon deswegen so, weil ein guter Teil von Dropbox sich
ja um Kollaboration, also das Teilen von Dateien miteinander dreht. Das
können Unterlagen einer Wohnungseigentümergemeinschaft betreffend eine
Dachsanierung sein, oder halt ein paar MP3-Dateien.&lt;/p&gt;
&lt;p&gt;Wenn man nun also eine Datei auf Dropbox hoch lädt, dann berechnet der
Client eine Prüfsumme und lädt erst einmal diese hoch.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/sascha_lobo_singt.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Abkürzung beim Datei-Upload, wenn die Datei schon bei einem anderen
Dropbox-Kunden liegt.&lt;/p&gt;
&lt;p&gt;Existiert eine Datei mit dieser Prüfsumme, dem passenden Datum und Namen
schon auf den Servern von Dropbox, dann muß Dropbox die Datei selber gar
nicht mehr bekommen, denn Dropbox hat ja bereits passende Daten. Es genügt
also serverseitig, die Datei auf dem Dropbox-Server für diesen Kunden
sichtbar zu machen. Das ist schnell, spart Bandbreite und für Dropbox spart
es Speicherplatz. Genau genommen macht es Dropbox wahrscheinlich überhaupt
erst rentabel, denn andernfalls würde viel zu viel Plattenplatz verbraucht
werden.&lt;/p&gt;
&lt;p&gt;Die Werkzeuge von Drittanbietern, gegen die Dropbox dort vorgeht, tun nun
folgendes: Sie &amp;lsquo;wissen&amp;rsquo; Prüfsummen und senden diese Prüfsummen an die
Dropbox-Server, ohne daß der Anwender diese Dateien auf seiner lokalen
Platte hat - der Client behauptet also, die Daten zu haben und zeigt eine
Prüfsumme vor, hat die Daten in Wahrheit aber gar nicht.&lt;/p&gt;
&lt;p&gt;Dropbox macht diese Dateien dann für den Benutzer dieses Tools sichtbar,
wenn Dropbox diese Datei überhaupt in irgendeinem Useraccount hat. Man kann
also eine Datei-Prüfsumme etwa eines MP3-Verzeichnisses twittern, und jeder
kann mit diesem Tool und der Prüfsumme, die er über Twitter erhalten hat,
dann diese MP3s in seine Dropbox importieren und sie sich dann runterladen.
Klar, daß Dropbox das doof findet.&lt;/p&gt;
&lt;p&gt;Das wäre technisch relativ leicht korrigierbar: Dropbox kennt ja die Datei,
und ihre Länge. Dropbox kann also den Client nach einem Sample der Daten
oder einer zweiten Prüfsumme über ein Sample der Daten fragen, und dabei das
Sample aus der ganzen Datei über einen variablen, zufällig bestimmten
Bereich legen. Wenn ich also behaupte, das Album &amp;ldquo;Sascha Lobo singt&amp;rdquo; zu
haben und die Prüfsumme dafür vorzeige, dann gibt Dropbox mir die Dateien
erst, wenn ich die Prüfsumme über die Bytes von Offset 4826267 bis
4826267+4096  dieser Datei berechnet habe. Wenn Du das machst, wird
stattdessen die Prüfsumme über einen anderen Bereich verlangt. Auf diese
Weise kann Dropbox leicht prüfen, ob der Client wirklich im Besitz der Daten
ist, die er behauptet zu haben.&lt;/p&gt;
&lt;p&gt;Nun sollte einmal das Denken einsetzen. Ich erzeuge also eine Datei mit den
Inhalt &amp;ldquo;Hallo, Welt!&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Wenn &lt;strong&gt;ich&lt;/strong&gt; diese Datei mit meinem Key verschlüssele, dann sieht die Datei so aus:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;go&#34;&gt;KK:~ kris$ openssl enc -e -k g33k -aes-128-cbc -base64 -in /dev/stdin
&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;Hello, World!
&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;U2FsdGVkX19isizbD981L7EOV+1Ou8O4xhBMQqDo3nw=
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Wenn &lt;strong&gt;Du&lt;/strong&gt; das machst, dann ist der Inhalt der Datei offensichtlich anders:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;go&#34;&gt;KK:~ kris$ openssl enc -e -k s3cr3t -aes-128-cbc -base64 -in /dev/stdin
&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;Hello, World!
&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;U2FsdGVkX18Fqrwp51fq8Y23MBas01+z4gJBdFs+vWE=
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Beide Dateien haben offensichtlich unterschiedliche Prüfsummen, wenn man
verschlüsselten Content betrachtet. Die Prüfsumme muß also über den
unverschlüsselten Content berechnet werden, damit das vergleichbar wird. Für
den Client ist das leicht, da die Daten ja auf meiner und Deiner Platte für
den Client unverschlüsselt vorliegen.&lt;/p&gt;
&lt;p&gt;Danach stellt mir Dropbox die Datei auf dem Server zur Verfügung, wenn ich
die passende Prüfsumme vorzeigen kann. Ich kann die Datein dann runterladen,
mit meinem Schlüssel verschlüsselt. Das heißt, die Daten, die angeblich
verschlüsselt auf dem Dropbox Server liegen, können mit meinem und mit
Deinem Schlüssel verschlüsselt runtergeladen werden. Dropbox speichert die
Daten physikalisch auch nur einmal, um Speicherplatz zu sparen, denn sonst
hätten sie tausende Kopien von &amp;ldquo;Sascha Lobo singt&amp;rdquo; auf dem Server liegen,
die alle Platz wegnehmen. Naja, ok, Dutzende.&lt;/p&gt;
&lt;p&gt;Wahrscheinlicher ist also, daß Dropbox die Daten auf ihren Servern gar nicht
verschlüsselt, oder alle Daten mit einem einzigen globalen &amp;ldquo;Dropbox&amp;rdquo;-Key
verschlüsselt oder etwas ähnlich simples. Für die Kommunikation wird dann
eine Transportverschlüsselung über den Content gebraten, also für mich mein
Key und für Dich Dein Key.&lt;/p&gt;
&lt;p&gt;Dropbox hat also die Wahl zwischen Dateideduplikation und effizienten
Uploads auf der einen Seite und Datensicherheit durch Verschlüsselung auf
der anderen Seite. Klar, wo businessmodelltechnisch die Präferenzen liegen.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>

